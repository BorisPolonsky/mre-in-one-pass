a large database . Traditional information retrieval techniques use a histogram of keywords as the document representation but oral communication may offer additional indices such as the time and is shown on a large database of TV shows . Emotions and other indices	USAGE	12	12	H01-1001.7	5	7	H01-1001.5	USAGE	18	19	H01-1001.9	23	23	H01-1001.10	PART_WHOLE	36	37	H01-1001.15	34	34	H01-1001.14
funding the development of a distributed message-passing infrastructure for dialogue systems which all Communicator participants are	MODEL-FEATURE	5	7	H01-1017.4	9	10	H01-1017.5
Lincoln Laboratory ) . The CCLINC Korean-to-English translation system consists of two core modules , language understanding and generation ( i ) Robust efficient parsing of Korean ( a verb final language with overt case markers , relatively free word order ( ii ) High quality translation via word sense disambiguation and accurate word order generation	PART_WHOLE	12	13	H01-1041.4	5	8	H01-1041.3	USAGE	24	24	H01-1041.8	26	26	H01-1041.9	MODEL-FEATURE	33	35	H01-1041.11	29	31	H01-1041.10	USAGE	48	50	H01-1041.15	46	46	H01-1041.14
test the efficacy of applying automated evaluation techniques , originally devised for the evaluation of human language learners , to the output of machine translation ( MT experiments , looks at the intelligibility of MT output . A language learning experiment	USAGE	5	7	H01-1042.1	21	21	H01-1042.3	MODEL-FEATURE	32	32	H01-1042.10	34	35	H01-1042.11
sources . We integrate a spoken language understanding system with intelligent mobile agents that mediate between users and	PART_WHOLE	10	12	H01-1049.4	5	8	H01-1049.3
. We find that simple interpolation methods , like log-linear and linear interpolation , improve the performance but fall short of the word string and selects the word string with the best performance ( typically , word or word strings , where each word string has been obtained by using a different LM . Actually , the oracle acts like a dynamic combiner with hard decisions using the reference . We provide experimental results show the need for a dynamic language model combination to improve the performance further . We suggest a The method amounts to tagging LMs with confidence measures and picking the best hypothesis corresponding to the LM with the best confidence .	RESULT	5	6	H01-1058.2	16	16	H01-1058.4	RESULT	27	28	H01-1058.9	32	32	H01-1058.10	RESULT	52	52	H01-1058.14	43	44	H01-1058.13	USAGE	68	68	H01-1058.18	61	62	H01-1058.16	RESULT	79	82	H01-1058.19	86	86	H01-1058.20	MODEL-FEATURE	99	100	H01-1058.25	97	97	H01-1058.24	MODEL-FEATURE	113	113	H01-1058.28	109	109	H01-1058.27
approach employing n-gram models and error-correction rules for Thai key prediction and Thai-English language identification . also proposes rule-reduction algorithm applying mutual information to reduce the error-correction rules . Our algorithm reported more than 99 % accuracy in both language identification and key prediction .	USAGE	5	6	H01-1070.2	8	10	H01-1070.3	USAGE	21	22	H01-1070.6	26	27	H01-1070.7	RESULT	39	40	H01-1070.9	36	36	H01-1070.8
potentially large list of possible sentence plans for a given text-plan input . Second , the sentence-plan-ranker plan . The SPR uses ranking rules automatically learned from training data . We show that the SPR learns to select a sentence plan whose rating on average is only 5 % worse than the top human-ranked sentence plan .	MODEL-FEATURE	5	6	N01-1003.12	10	11	N01-1003.13	USAGE	27	28	N01-1003.19	22	23	N01-1003.18	COMPARE	39	40	N01-1003.21	52	55	N01-1003.22
and segment contiguity on the retrieval performance of a translation memory system . We take a selection of both bag-of-words and segment order-sensitive string comparison methods , and run each over both character- and word-segmented data , in combination with a datasets , we find that indexing according to simple character bigrams produces a retrieval accuracy superior in their optimum configuration , bag-of-words methods are shown to be equivalent to segment order-sensitive methods in terms of retrieval accuracy	RESULT	9	11	P01-1004.5	5	6	P01-1004.4	USAGE	19	25	P01-1004.6	32	35	P01-1004.7	USAGE	50	51	P01-1004.12	46	46	P01-1004.11	COMPARE	62	63	P01-1004.16	70	72	P01-1004.17
The theoretical study of the range concatenation grammar [ RCG ] formalism has revealed many attractive properties which may be used in NLP . In particular , range concatenation languages [ RCL ] can be parsed in polynomial time and many classical grammatical formalisms an equivalent RCG , any tree adjoining grammar can be parsed in O ( n6 ) time . In this paper , we study a parsing technique whose purpose is to improve the practical efficiency of RCL parsers . The non-deterministic parsing choices L are directed by a guide which uses the shared derivation forest output by a prior RCL parser for a suitable superset of L . The results of a	USAGE	5	11	P01-1007.1	22	22	P01-1007.2	MODEL-FEATURE	37	38	P01-1007.4	27	32	P01-1007.3	MODEL-FEATURE	56	60	P01-1007.11	49	51	P01-1007.10	USAGE	69	70	P01-1007.12	80	81	P01-1007.13	USAGE	96	98	P01-1007.18	92	92	P01-1007.17	USAGE	103	104	P01-1007.19	108	110	P01-1007.20
from a Parallel Corpus While paraphrasing is critical both for interpretation and generation of natural language , current systems use manual paraphrases . We present an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple	USAGE	5	5	P01-1008.1	10	15	P01-1008.2	USAGE	26	28	P01-1008.4	30	32	P01-1008.5
Retrieval This paper presents a formal analysis for a large class of words called alternative markers , which includes other ( . I show that the performance of a search engine can be improved dramatically by incorporating an approximation of the formal analysis that is compatible with the approach is that as the operational semantics of natural language applications improve , even larger improvements	TOPIC	5	6	P01-1009.1	14	15	P01-1009.3	RESULT	41	42	P01-1009.14	26	26	P01-1009.12	PART_WHOLE	53	54	P01-1009.17	56	58	P01-1009.18
sensitive logic , and a learning algorithm from structured data ( based on a typing-algorithm	USAGE	8	9	P01-1047.11	5	6	P01-1047.10
fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches . In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments . We show that the trainable sentence planner performs better than the rule-based systems and the baselines , and	MODEL-FEATURE	5	5	P01-1056.3	7	7	P01-1056.4	COMPARE	10	11	P01-1056.5	15	19	P01-1056.6	USAGE	28	30	P01-1056.7	33	35	P01-1056.8	COMPARE	46	48	P01-1056.13	53	54	P01-1056.14
centering on the construction of statistical models of WH-questions . These models , which are built from shallow linguistic features of questions , are employed to predict on different aspects of the predictive performance of our models , including the influence of various training and testing factors on predictive performance , and examine the relationships	MODEL-FEATURE	5	6	P01-1070.2	8	8	P01-1070.3	MODEL-FEATURE	17	19	P01-1070.5	21	21	P01-1070.6	RESULT	36	36	P01-1070.9	32	33	P01-1070.8	RESULT	43	46	P01-1070.10	48	49	P01-1070.11
paper describes a method for utterance classification that does not require manual transcription of training data . The can be achieved using conventional word-trigram recognition requiring manual transcription . In our method , unsupervised training is first used to train a phone n-gram model for a particular domain ; the output of recognition with this model is then passed to a phone-string classifier . The classification accuracy of	USAGE	11	12	N03-1001.2	5	6	N03-1001.1	USAGE	26	27	N03-1001.8	23	24	N03-1001.7	USAGE	33	34	N03-1001.9	41	43	N03-1001.10	USAGE	61	62	N03-1001.15	50	50	N03-1001.12
processing , we developed a multi-strategy and multi-source approach to question answering which is based on combining the results from different answering agents searching for answers in multiple corpora . The answering agents adopt fundamentally different strategies , one utilizing primarily knowledge-based mechanisms and the other adopting statistical evaluating the effectiveness of our answer resolution algorithm show a 35.0 % relative improvement over our baseline system in the number of questions	USAGE	21	22	N03-1004.5	5	11	N03-1004.4	PART_WHOLE	25	25	N03-1004.6	28	28	N03-1004.7	USAGE	41	42	N03-1004.9	31	32	N03-1004.8	COMPARE	53	55	N03-1004.14	64	65	N03-1004.15
system to the task of scoring alternative speech recognition hypotheses ( SRH ) in terms of their semantic classifies 73.2 % in a German corpus of 2.284 SRHs as either coherent or incoherent	USAGE	5	5	N03-1012.4	7	12	N03-1012.5	PART_WHOLE	27	27	N03-1012.12	23	24	N03-1012.11
understand better and explain why phrase-based models outperform word-based models . Our empirical results , through relatively simple means : heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations . Surprisingly , learning phrases than three words and learning phrases from high-accuracy word-level alignment models does not have a strong	COMPARE	5	6	N03-1017.4	8	9	N03-1017.5	USAGE	26	27	N03-1017.9	20	21	N03-1017.7	MODEL-FEATURE	29	30	N03-1017.10	32	33	N03-1017.11	PART_WHOLE	44	44	N03-1017.14	46	49	N03-1017.15
an OCR system . The model is designed for use in error correction , with a focus on post-processing the output of black-box OCR systems in present an implementation of the model based on finite-state models , demonstrate the model 's ability to significantly reduce character and word error rate , and provide evaluation results involving automatic extraction of translation lexicons from printed text .	USAGE	5	5	N03-1018.6	11	12	N03-1018.7	USAGE	18	18	N03-1018.8	20	20	N03-1018.9	USAGE	34	35	N03-1018.13	31	31	N03-1018.12	RESULT	39	39	N03-1018.14	45	49	N03-1018.15	USAGE	56	57	N03-1018.16	62	63	N03-1018.18
We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars ( LFG ) to the domain of sentence . Our system incorporates a linguistic parser/generator for LFG , a transfer component for parse reduction operating on packed parse forests , and a maximum-entropy model for stochastic output selection . Furthermore , we propose sentence condensation systems . An experimental evaluation of summarization quality shows a close correlation is state-of-the-art , with guaranteed grammaticality of the system output due to the use of	USAGE	5	10	N03-1026.1	12	16	N03-1026.2	USAGE	27	28	N03-1026.4	30	30	N03-1026.5	USAGE	33	34	N03-1026.6	36	37	N03-1026.7	USAGE	49	51	N03-1026.10	46	47	N03-1026.9	TOPIC	62	63	N03-1026.14	65	65	N03-1026.15	MODEL-FEATURE	76	76	N03-1026.20	79	80	N03-1026.21
iii ) effective use of priors in conditional loglinear models , and ( iv ) ideas together , the resulting tagger gives a 97.24 % accuracy on the Penn Treebank WSJ	USAGE	5	5	N03-1033.6	7	9	N03-1033.7	RESULT	20	20	N03-1033.9	25	25	N03-1033.10
using Class-Dependent Mixtures Sources of training data suitable for language modeling of conversational speech are limited data can be supplemented with text from the web filtered to match the style	USAGE	5	6	N03-2003.1	9	10	N03-2003.2	PART_WHOLE	21	21	N03-2003.5	24	24	N03-2003.6
In order to boost the translation quality of EBMT based on a small-sized bilingual	RESULT	8	8	N03-2006.2	5	6	N03-2006.1
for learning morphology by identifying hubs in an automaton . For our purposes ,	PART_WHOLE	5	5	N03-2015.3	8	8	N03-2015.4
Cohesion Constraint We present a syntax-based constraint for word alignment , known as the cohesion	USAGE	5	6	N03-2017.1	8	9	N03-2017.2
Using Concept-based Seeds A novel bootstrapping approach to Named Entity ( NE ) tagging using concept-based seeds and successive few common noun or pronoun seeds that correspond to the concept for the targeted NE , successive learners . First , decision list is used to learn the parsing-based NE rules . Then , a Hidden Markov Model is trained on a corpus automatically tagged by the first	USAGE	5	6	N03-2025.1	8	13	N03-2025.2	MODEL-FEATURE	24	24	N03-2025.7	29	29	N03-2025.8	USAGE	47	49	N03-2025.14	40	41	N03-2025.13	USAGE	54	56	N03-2025.15	61	61	N03-2025.16
paper , we describe a phrase-based unigram model for statistical machine translation that uses a much simpler . During training , the blocks are learned from source interval projections using an underlying word alignment We show experimental results on block selection criteria based on unigram counts and phrase length .	USAGE	5	7	N03-2036.1	9	11	N03-2036.2	PART_WHOLE	22	22	N03-2036.12	26	28	N03-2036.13	USAGE	44	44	N03-2036.16	39	41	N03-2036.15
, we propose a novel Cooperative Model for natural language understanding in a dialogue system .	USAGE	5	6	N03-3010.1	8	10	N03-3010.2
Architecture for Question Answering The JAVELIN system integrates a flexible , planning-based architecture with a variety of language demonstration will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus . The operation of the in depth through browsing the repository of data objects created by the system during	PART_WHOLE	11	12	N03-4010.2	5	6	N03-4010.1	USAGE	23	23	N03-4010.6	25	25	N03-4010.7	PART_WHOLE	31	32	N03-4010.8	36	37	N03-4010.9	PART_WHOLE	50	51	N03-4010.11	48	48	N03-4010.10
a novel , customizable : IE paradigm that takes advantage of predicate-argument structures . We also introduce a	USAGE	11	12	P03-1002.2	5	6	P03-1002.1
Data This paper proposes the Hierarchical Directed Acyclic Graph ( HDAG ) Kernel for structured natural language data . The HDAG Kernel directly of the number of common attribute sequences of the HDAGs . We applied the proposed the experiments demonstrate that the HDAG Kernel is superior to other kernel functions and baseline methods .	USAGE	5	12	P03-1005.1	14	17	P03-1005.2	MODEL-FEATURE	28	29	P03-1005.7	32	32	P03-1005.8	COMPARE	43	44	P03-1005.13	49	50	P03-1005.14
utility of clustering in inducing semantic verb classes from undisambiguated corpus data . We describe a new approach which involves clustering subcategorization frame ( SCF ) distributions using the Information Bottleneck and nearest neighbour methods . accounts for the effect of polysemy on the clusters , offering us a good	MODEL-FEATURE	5	7	P03-1009.2	10	11	P03-1009.3	USAGE	29	30	P03-1009.5	21	25	P03-1009.4	MODEL-FEATURE	41	41	P03-1009.9	44	44	P03-1009.10
Spoken Dialogue We apply a decision tree based approach to pronoun resolution in spoken dialogue . Our system deals with pronouns with NP- and non-NP-antecedents . We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising	USAGE	5	8	P03-1022.1	10	11	P03-1022.2	MODEL-FEATURE	22	24	P03-1022.5	20	20	P03-1022.4	USAGE	34	35	P03-1022.7	37	38	P03-1022.8
a core technology for the Topic Detection and Tracking tasks of new event detection . In this paper we	PART_WHOLE	5	9	P03-1030.2	11	13	P03-1030.3
Systems This paper concerns the discourse understanding process in spoken dialogue systems . This process enables the user utterances based on the context of a dialogue . Since multiple candidates for the understanding result can be obtained for user utterance due to the ambiguity of speech understanding , it is not appropriate utterance . By holding multiple candidates for understanding results and resolving the ambiguity resolving this ambiguity based on statistical information obtained from dialogue corpora . Unlike conventional methods that sufficiently and that holding multiple candidates for understanding results is effective .	USAGE	5	7	P03-1031.1	9	11	P03-1031.2	MODEL-FEATURE	22	22	P03-1031.4	25	25	P03-1031.5	USAGE	29	29	P03-1031.6	32	32	P03-1031.7	MODEL-FEATURE	43	43	P03-1031.9	45	46	P03-1031.10	USAGE	57	57	P03-1031.13	59	59	P03-1031.14	MODEL-FEATURE	70	71	P03-1031.19	74	75	P03-1031.20	USAGE	86	86	P03-1031.23	88	88	P03-1031.24
Dialogue Systems We address appropriate user modeling in order to generate cooperative responses to each user in spoken hastiness . Moreover , the models are automatically derived by decision tree learning using real dialogue data collected accuracy for all dimensions . Dialogue strategies based on the user modeling are implemented in Kyoto city	USAGE	5	6	P03-1033.1	11	12	P03-1033.2	MODEL-FEATURE	28	30	P03-1033.15	23	23	P03-1033.14	USAGE	46	47	P03-1033.19	41	42	P03-1033.18
Corpus This paper presents an unsupervised learning approach to building a non-English ( Arabic ) stemmer . The stemming model is based on statistical machine translation and it uses an English approach is applicable to any language that needs affix removal . Our resource-frugal approach results in 87.5 % agreement with a state of the to an unsupervised component . Task-based evaluation using Arabic information retrieval indicates an improvement of 22-38	USAGE	5	7	P03-1050.1	11	15	P03-1050.2	USAGE	23	25	P03-1050.4	18	19	P03-1050.3	MODEL-FEATURE	39	40	P03-1050.16	36	36	P03-1050.15	RESULT	43	44	P03-1050.17	49	49	P03-1050.18	USAGE	63	65	P03-1050.25	60	61	P03-1050.24
is seeded by a small manually segmented Arabic corpus and uses it to bootstrap an unsupervised algorithm to build the Arabic word segmenter from a large unsegmented Arabic corpus . The algorithm uses a to determine the most probable morpheme sequence for a given input . The language model is initially estimated from a small manually segmented corpus of about 110,000 words . algorithm for automatically acquiring new stems from a 155 million word unsegmented corpus , and re-estimate the model parameters with the expanded vocabulary and training corpus . The resulting Arabic word segmentation system achieves around 97 % exact match accuracy on a test corpus containing 28,449 word tokens . We believe this is one can create a small manually segmented corpus of the language of interest .	USAGE	5	8	P03-1051.8	15	16	P03-1051.9	USAGE	26	28	P03-1051.11	20	22	P03-1051.10	MODEL-FEATURE	39	40	P03-1051.13	44	44	P03-1051.14	MODEL-FEATURE	47	48	P03-1051.15	55	57	P03-1051.16	PART_WHOLE	68	68	P03-1051.21	74	75	P03-1051.23	USAGE	80	81	P03-1051.24	85	85	P03-1051.25	RESULT	92	95	P03-1051.27	100	102	P03-1051.28	PART_WHOLE	109	110	P03-1051.30	105	106	P03-1051.29	MODEL-FEATURE	121	123	P03-1051.32	126	126	P03-1051.33
Study A central problem of word sense disambiguation ( WSD ) is the lack of manually sense-tagged data required for supervised learning . an approach to automatically acquire sense-tagged training data from English-Chinese parallel corpora , which are then used importance of the issue of domain dependence in evaluating WSD programs .	USAGE	15	17	P03-1058.2	5	10	P03-1058.1	MODEL-FEATURE	28	30	P03-1058.4	32	34	P03-1058.5	MODEL-FEATURE	45	46	P03-1058.13	49	50	P03-1058.14
construction of a large , semantically annotated corpus resource as reliable basis for the large-scale acquisition of word-semantic information , e.g . the construction the problems of vagueness and ambiguity in semantic annotation .	USAGE	5	7	P03-1068.1	15	18	P03-1068.2	MODEL-FEATURE	29	29	P03-1068.9	31	32	P03-1068.10
gaze , head nods and attentional focus in the context of a direction-giving task . The distribution of nonverbal results , we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state .	MODEL-FEATURE	5	6	P03-1070.9	12	13	P03-1070.10	USAGE	27	31	P03-1070.15	24	24	P03-1070.14
demonstrate that an approximation of HPSG produces a more effective CFG filter than that of LTAG . We also investigate the	COMPARE	5	5	P03-2036.4	15	15	P03-2036.6
to estimate the number of analogies among the sentences that it contains . We	MODEL-FEATURE	5	5	C04-1106.5	8	8	C04-1106.6
of Coherence in Student Essays CriterionSM Online Essay Evaluation Service includes a capability that labels sentences in student writing with essay-based discourse elements ( by evaluating multiple aspects of coherence in essays . This system identifies features of sentences based on semantic similarity measures and discourse structure . A support vector machine uses these features to capture breakdowns in coherence relatedness between discourse elements . Intra-sentential quality is evaluated with rule-based heuristics . Results indicate that the	USAGE	5	9	N04-1024.1	18	18	N04-1024.3	MODEL-FEATURE	29	29	N04-1024.7	31	31	N04-1024.8	MODEL-FEATURE	36	36	N04-1024.9	38	38	N04-1024.10	USAGE	54	54	N04-1024.14	49	51	N04-1024.13	TOPIC	70	71	N04-1024.19	65	66	N04-1024.18
paper , we use the information redundancy in multilingual input to correct errors in machine summarization , where the input documents are in Arabic , and the output summary is in English . Typically , information that different ways to realize that information in English . We demonstrate how errors	MODEL-FEATURE	5	6	H05-1005.1	8	9	H05-1005.2	MODEL-FEATURE	23	23	H05-1005.7	20	20	H05-1005.6	MODEL-FEATURE	31	31	H05-1005.9	28	28	H05-1005.8	MODEL-FEATURE	44	44	H05-1005.16	42	42	H05-1005.15
Translation This paper presents a maximum entropy word alignment algorithm for Arabic-English based on supervised training data . We demonstrate that it and that a mixture of supervised and unsupervised methods yields superior performance . The probabilistic model used in the alignment directly models the link decisions	USAGE	14	16	H05-1012.3	5	9	H05-1012.1	RESULT	27	30	H05-1012.6	33	33	H05-1012.7	USAGE	36	37	H05-1012.8	41	41	H05-1012.9
phrases This paper presents a phrase-based statistical machine translation method , based on non-contiguous phrases , i.e . phrases with A method for producing such phrases from a word-aligned corpora is proposed . A statistical translation model is also presented that deals such phrases , as well as a training method based on the maximization of translation accuracy , as measured with the NIST evaluation metric . Translations are produced by means of a beam-search decoder . Experimental results are presented	USAGE	13	14	H05-1095.2	5	9	H05-1095.1	PART_WHOLE	25	25	H05-1095.4	28	29	H05-1095.5	USAGE	34	36	H05-1095.6	43	43	H05-1095.7	USAGE	56	57	H05-1095.9	49	50	H05-1095.8	USAGE	74	75	H05-1095.12	67	67	H05-1095.11
Following recent developments in the automatic evaluation of machine translation and document summarization , we 2004 QA tracks indicate that rankings produced by our metric correlate highly with official rankings , and that POURPRE outperforms	USAGE	5	6	H05-1117.1	8	9	H05-1117.2	COMPARE	20	20	H05-1117.8	28	29	H05-1117.9
a method for identifying systematic patterns in translation data using part-of-speech tag sequences . used by developers to explore patterns in machine translation output .	PART_WHOLE	5	5	H05-2007.1	7	8	H05-2007.2	PART_WHOLE	19	19	H05-2007.8	21	23	H05-2007.9
good at predicting the right translation of the words in source language sentences . Surprisingly however , the WSD accuracy of SMT models has never been evaluated and to the contrary , current SMT models do have limitations in comparison with dedicated WSD models , and that SMT should	MODEL-FEATURE	5	5	I05-2021.12	8	8	I05-2021.13	RESULT	21	22	I05-2021.17	19	19	I05-2021.16	COMPARE	33	34	I05-2021.23	42	43	I05-2021.24
evaluations have shown , that SMT gives competitive results to rule-based translation systems , requiring significantly less development	COMPARE	5	5	I05-2048.3	10	12	I05-2048.4
our recent work on harvesting English-Chinese bitexts of the laws of Hong Kong from the Web and aligning them to the foundation for exploring and harvesting English-Chinese bitexts in a larger volume from the Web .	PART_WHOLE	5	6	I05-4010.1	15	15	I05-4010.2	PART_WHOLE	26	27	I05-4010.11	34	34	I05-4010.12
Semantic Equivalence The task of machine translation ( MT ) evaluation is closely related to the task of sentence-level semantic equivalence classification . This paper investigates the utility of applying standard MT evaluation methods ( BLEU , NIST , WER and PER ) to building classifiers to predict semantic equivalence and We also introduce a novel classification method based on PER which leverages part of speech information of the words contributing to the word matches . Our results show that MT evaluation techniques are able to produce useful features for paraphrase classification and to lesser extent entailment . Our technique gives a substantial improvement in paraphrase classification accuracy over all of the other	COMPARE	5	10	I05-5003.1	18	21	I05-5003.2	USAGE	31	42	I05-5003.3	45	45	I05-5003.4	USAGE	60	60	I05-5003.8	56	57	I05-5003.7	MODEL-FEATURE	63	66	I05-5003.9	69	69	I05-5003.10	RESULT	80	82	I05-5003.13	88	88	I05-5003.14	RESULT	99	99	I05-5003.17	105	107	I05-5003.18
a method that automatically generates paraphrase sets from seed sentences to be used as reference ) the amount of internal lexical and syntactical variation in a set of paraphrases : slightly superior to that method thus seem adequate as reference sets to be used for MT evaluation .	PART_WHOLE	5	5	I05-5008.1	8	9	I05-5008.2	MODEL-FEATURE	20	23	I05-5008.14	28	28	I05-5008.15	USAGE	39	40	I05-5008.18	45	46	I05-5008.19
Referents This paper proposes an annotating scheme that encodes honorifics ( respectful words ) . of the referents . This referential information is vital for resolving zero pronouns and improving machine translation outputs . Annotating honorifics is a predicate with honorifics , assigning ranks to referents of the predicate , calibrating	MODEL-FEATURE	5	6	I05-6011.1	9	9	I05-6011.2	RESULT	20	21	I05-6011.6	30	32	I05-6011.8	MODEL-FEATURE	43	43	I05-6011.12	45	45	I05-6011.13
parser produces a set of candidate parses for each input sentence , with associated probabilities that initial ranking , using additional features of the tree as evidence . The strength define a derivation or a generative model which takes these features into account . We introduce task , based on the boosting approach to ranking problems described in Freund et al apply the boosting method to parsing the Wall Street Journal treebank . The method combined the original model . The new model achieved 89.75 % F-measure , a 13 % relative which takes advantage of the sparsity of the feature space in the parsing data . Experiments show significant efficiency efficiency - to work on feature selection methods within log-linear ( maximum-entropy ) models . Although the experiments in	MODEL-FEATURE	5	6	J05-1003.3	10	10	J05-1003.4	MODEL-FEATURE	21	21	J05-1003.10	24	24	J05-1003.11	USAGE	40	40	J05-1003.17	35	36	J05-1003.16	USAGE	51	52	J05-1003.19	54	55	J05-1003.20	USAGE	66	66	J05-1003.22	68	71	J05-1003.23	RESULT	82	82	J05-1003.29	86	86	J05-1003.30	MODEL-FEATURE	97	101	J05-1003.34	104	105	J05-1003.35	PART_WHOLE	116	118	J05-1003.38	120	124	J05-1003.39
present a novel method for discovering parallel sentences in comparable , non-parallel corpora . We train a maximum this approach , we extract parallel data from large Chinese , Arabic , and English non-parallel newspaper corpora . We evaluate the quality also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus ( 100,000 words ) and	USAGE	5	7	J05-4003.1	9	12	J05-4003.2	PART_WHOLE	23	24	J05-4003.6	27	35	J05-4003.7	USAGE	59	60	J05-4003.11	46	47	J05-4003.10
retrieval times for looking up phrase translations in our suffix array-based data structure . We show how sampling	PART_WHOLE	5	6	P05-1032.9	9	12	P05-1032.10
statistical machine translation that combines syntactic information in the source language with recent advances in phrasal parallel corpus , project the source dependency parse onto the target sentence , extract dependency treelet translation	MODEL-FEATURE	5	6	P05-1034.2	9	10	P05-1034.3	MODEL-FEATURE	21	23	P05-1034.11	27	27	P05-1034.12
assumption . Using a state-of-the-art Chinese word sense disambiguation model to choose translation candidates for a typical IBM statistical system , we find that word sense disambiguation does not yield significantly better translation quality than the statistical machine translation	USAGE	5	9	P05-1048.4	12	13	P05-1048.5	RESULT	24	26	P05-1048.7	32	33	P05-1048.8
MT ) aims at applying statistical models to structured data . In this paper , we present a syntax-based statistical machine translation system based on a probabilistic synchronous dependency insertion grammar . Synchronous dependency insertion grammars approach to inducing such a grammar from parallel corpora . Second , we describe the graphical model for the machine translation task , which can also be that our system outperforms the baseline system based on the IBM models in both translation speed and	USAGE	5	6	P05-1067.2	8	9	P05-1067.3	USAGE	26	30	P05-1067.5	18	22	P05-1067.4	PART_WHOLE	41	41	P05-1067.9	43	44	P05-1067.10	USAGE	51	52	P05-1067.11	55	57	P05-1067.12	USAGE	73	74	P05-1067.19	68	69	P05-1067.18
novel training method for a localized phrase-based prediction model for statistical machine translation ( SMT ) . The model predicts blocks likelihood criterion to train a log-linear block bigram model which uses real-valued features ( e.g . a language	USAGE	5	8	P05-1069.2	10	15	P05-1069.3	USAGE	32	33	P05-1069.9	26	29	P05-1069.8
Corpora Previous work has used monolingual parallel corpora to extract and generate paraphrases . We show that this a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation and contrast the quality with paraphrases extracted from automatic alignments .	PART_WHOLE	12	12	P05-1074.2	5	7	P05-1074.1	PART_WHOLE	23	23	P05-1074.11	27	29	P05-1074.12	PART_WHOLE	40	40	P05-1074.18	43	44	P05-1074.19
Machine Translation We present a Czech-English statistical machine translation system which performs tree-to-tree translation of dependency structures . The and plan to compare our system 's output with a benchmark system .	USAGE	5	9	P05-2016.1	12	13	P05-2016.2	COMPARE	24	26	P05-2016.9	29	30	P05-2016.10
. The combination with a two-step clustering process using sentence co-occurrences as features allows for accurate	USAGE	9	10	E06-1018.8	5	7	E06-1018.7
Meetings We present results on addressee identification in four-participants face-to-face meetings using Bayesian Network and Naive 's gaze information . The classifiers show little gain from information about meeting context	USAGE	5	6	E06-1022.1	8	10	E06-1022.2	RESULT	21	21	E06-1022.17	24	24	E06-1022.18
Using Block Movements Most state-of-the-art evaluation measures for machine translation assign high costs to movements we will present a new evaluation measure which explicitly models block reordering as an edit operation . we will show how some evaluation measures can be improved by the introduction of word-dependent substitution costs . The correlation of the new measure with human judgment has been investigated systematically on additional increase of correlation between automatic evaluation measures and human judgment .	USAGE	5	6	E06-1031.1	8	9	E06-1031.2	USAGE	20	21	E06-1031.6	25	26	E06-1031.7	RESULT	46	48	E06-1031.12	37	38	E06-1031.11	COMPARE	55	55	E06-1031.13	57	58	E06-1031.14	COMPARE	69	71	E06-1031.18	73	74	E06-1031.19
the problem of automatically predicting segment boundaries in spoken multiparty dialogue . We extend prior work impact on performance of using ASR output as opposed to human transcription . Examination of the effect , ( 2 ) for predicting top-level boundaries , the machine learning approach that combines lexical-cohesion and conversational We also find that the transcription errors inevitable in ASR output have a negative impact on	PART_WHOLE	5	6	E06-1035.1	8	10	E06-1035.2	COMPARE	21	22	E06-1035.6	26	27	E06-1035.7	USAGE	43	45	E06-1035.13	38	40	E06-1035.12	MODEL-FEATURE	56	57	E06-1035.18	60	61	E06-1035.19
Ensemble Methods for Unsupervised WSD Combination methods are an effective way of improving system performance . This paper examines the unsupervised WSD systems . Our combination methods rely on predominant senses which are derived automatically from	RESULT	5	6	P06-1013.1	13	14	P06-1013.2	USAGE	29	30	P06-1013.8	25	26	P06-1013.7
elimination problem : Given an underspecified semantic representation ( USR ) of a scope ambiguity , compute an USR with	MODEL-FEATURE	5	10	P06-1052.2	13	14	P06-1052.3
we describe the research using machine learning techniques to build a comma checker to be integrated in a grammar checker for Basque . After several experiments , and trained with a little corpus of 100,000 words , the system guesses correctly that is , a bigger corpus written by one unique author .	USAGE	5	7	P06-2001.1	11	12	P06-2001.2	USAGE	18	19	P06-2001.3	21	21	P06-2001.4	PART_WHOLE	35	35	P06-2001.6	32	32	P06-2001.5	MODEL-FEATURE	51	51	P06-2001.15	46	46	P06-2001.14
Clustering This paper presents an unsupervised learning approach to disambiguate various relations between named entities by use of various lexical and syntactic features from the contexts . It ACE corpora show that this spectral clustering based approach outperforms the other clustering methods .	USAGE	19	22	P06-2012.3	5	7	P06-2012.1	COMPARE	33	36	P06-2012.13	40	41	P06-2012.14
a novel method of building polarity-tagged corpus from HTML documents . The characteristics of this the method could construct a corpus consisting of 126,610 sentences .	PART_WHOLE	5	6	P06-2059.1	8	9	P06-2059.2	PART_WHOLE	24	24	P06-2059.8	20	20	P06-2059.7
- named entity annotations and scenario templates - can be used to enhance access to text collections via a standard text browser . We describe how this information is used in a prototype system designed to support information workers ' access to a pharmaceutical news archive as part of their industry watch function . We also report to be done on the interface to make users aware of the increased potential of IE-enhanced text browsers .	USAGE	5	6	H01-1040.3	20	21	H01-1040.5	USAGE	32	33	H01-1040.6	50	51	H01-1040.9	PART_WHOLE	62	62	H01-1040.11	72	74	H01-1040.13
Dialog Systems Recent advances in Automatic Speech Recognition technology have put the goal of naturally sounding dialog systems within reach . However , user . The issue of system response to users has been extensively studied by the natural language generation community , though rarely in the We show how research in generation can be adapted to dialog systems , and how the high cost of hand-crafting knowledge-based generation systems can be overcome by employing machine learning techniques .	USAGE	5	8	H01-1055.1	16	17	H01-1055.2	TOPIC	38	41	H01-1055.9	28	29	H01-1055.7	USAGE	52	52	H01-1055.11	57	58	H01-1055.12	USAGE	75	77	H01-1055.14	67	69	H01-1055.13
Automated Analyst 's Assistant The TAP-XL Automated Analyst 's Assistant is an application designed to help an English -speaking analyst write a topical report , culling information from a large inflow of multilingual , multimedia data . It gives users the	USAGE	32	35	N03-4004.4	5	9	N03-4004.1
Grammars This paper investigates some computational problems associated with probabilistic translation models that have recently been adopted on machine translation . These models can be viewed as pairs of probabilistic context-free grammars working in a 'synchronous ' way . Two hardness results for the class NP are reported , along with	MODEL-FEATURE	5	6	H05-1101.1	9	11	H05-1101.2	MODEL-FEATURE	29	31	H05-1101.5	22	22	H05-1101.4	MODEL-FEATURE	45	45	H05-1101.7	40	40	H05-1101.6
languages without word delimiters Automatic evaluation metrics for Machine Translation ( MT ) systems , such as BLEU or language pairs like English-Chinese or English-Japanese , because of the word segmentation problem . This study establishes the between the standard use of BLEU in word n-grams and its application at the level . The use of BLEU at the character level eliminates the word segmentation	USAGE	5	6	I05-2014.1	8	13	I05-2014.2	MODEL-FEATURE	29	31	I05-2014.8	24	24	I05-2014.7	USAGE	42	42	I05-2014.9	44	45	I05-2014.10	USAGE	56	56	I05-2014.12	59	59	I05-2014.13
) , to understand the model 's strengths and weaknesses , and to compare it to other MT systems . Using this visualization method , we can find and address conceptual and practical problems in an MT system . In our demonstration at	COMPARE	5	5	P05-3025.6	17	18	P05-3025.7	USAGE	22	23	P05-3025.8	36	37	P05-3025.9
are of considerable importance to Statistical Machine Translation ( SMT ) but which have not been addressed satisfactorily by the SMT research community . Over the last decade little is known about the computational complexity of some of the fundamental problems of SMT . Our work aims at unlikely that there exists a polynomial time solution for any of these hard problems ( unless P = NP	TOPIC	20	22	E06-1004.2	5	10	E06-1004.1	MODEL-FEATURE	33	34	E06-1004.4	42	42	E06-1004.5	USAGE	53	55	E06-1004.10	60	61	E06-1004.11
claim by adopting a simple MT-based paraphrasing technique and evaluating QA system performance on paraphrased questions .	USAGE	5	7	N06-2009.5	10	11	N06-2009.6
model information extraction as a token classification task , using various tagging strategies to combine multiple tokens .	USAGE	11	12	N06-2038.3	5	7	N06-2038.2
exploration tool called InfoMagnets . InfoMagnets aims at making exploratory corpus analysis accessible to researchers who are uncover relationships between language and behavioral patterns in two distinct domains : tutorial dialogue ( Kumar et al. , 2006 ) . As an educational tool , it has been used as part of a unit on protocol analysis in an Educational Research Methods	USAGE	5	5	N06-4001.3	9	11	N06-4001.4	PART_WHOLE	22	23	N06-4001.7	29	30	N06-4001.8	USAGE	41	42	N06-4001.10	54	55	N06-4001.11
products of them . The polarization of the objects of the elementary structures controls the saturation of the final structure . This formalism is both	USAGE	5	5	P06-1018.7	11	12	P06-1018.8	MODEL-FEATURE	15	15	P06-1018.9	19	19	P06-1018.10
paper examines what kind of similarity between words can be represented by what kind of word vectors in the vector space model word vectors , i.e. , LSA-based , cooccurrence-based and dictionary-based methods , were compared in terms of the ability to represent two kinds of similarity , i.e. , taxonomic similarity the comparison was that the dictionary-based word vectors better reflect taxonomic similarity , while the LSA-based and the cooccurrence-based word vectors better reflect associative similarity .	MODEL-FEATURE	15	16	P06-2110.3	5	5	P06-2110.1	USAGE	27	32	P06-2110.6	46	46	P06-2110.7	USAGE	57	59	P06-2110.10	62	63	P06-2110.11	USAGE	67	72	P06-2110.12	75	76	P06-2110.13
. In this paper , events are defined as event terms and associated event elements . by PageRank algorithm on the event map constructed from documents . Experimental results are encouraging	MODEL-FEATURE	9	10	P06-3007.3	5	5	P06-3007.2	USAGE	25	25	P06-3007.9	21	22	P06-3007.8
paper describes FERRET , an interactive question-answering ( Q/A ) system designed to address the challenges of integrating automatic Q/A applications into real-world environments . utilizes a novel approach to Q/A known as predictive questioning which attempts to identify the	USAGE	5	10	P06-4007.2	18	19	P06-4007.3	USAGE	33	34	P06-4007.6	30	30	P06-4007.5
analysis of move structures in abstracts of research articles . In our approach , sentences in a given abstract are analyzed and labeled with gathering a large number of abstracts from the Web and building a language model of abstract moves . We also present a CARE , which exploits the move-tagged abstracts for digital learning . This system provides a	PART_WHOLE	5	5	P06-4011.2	7	8	P06-4011.3	PART_WHOLE	14	14	P06-4011.4	18	18	P06-4011.5	PART_WHOLE	29	29	P06-4011.8	32	32	P06-4011.9	MODEL-FEATURE	36	37	P06-4011.10	39	40	P06-4011.11	USAGE	51	52	P06-4011.14	54	55	P06-4011.15
MT demonstrator assembles independently valuable general-purpose NLP components into a machine translation pipeline that capitalizes on output quality	PART_WHOLE	5	7	P06-4014.2	10	12	P06-4014.3
California at San Diego , verbs are represented as interconnected sets of subpredicates . These subpredicates may be a listener makes when a verb is used in a sentence . They confer a meaning structure on the sentence in which the verb is used .	MODEL-FEATURE	12	12	T78-1001.3	5	5	T78-1001.2	PART_WHOLE	23	23	T78-1001.7	28	28	T78-1001.8	PART_WHOLE	41	41	T78-1001.11	37	37	T78-1001.10
Reasoning The paper outlines a computational theory of human plausible reasoning constructed from analysis of people . Like logic , the theory is expressed in a content-independent formalism . Unlike logic , the theory specifies how different information in the conclusions drawn . The theory consists of a dimensionalized space of different inference types and their certainty conditions , including a variety of meta-inference types where the inference depends on the person 's	MODEL-FEATURE	5	6	T78-1028.1	8	10	T78-1028.2	MODEL-FEATURE	26	27	T78-1028.5	21	21	T78-1028.4	COMPARE	30	30	T78-1028.6	33	33	T78-1028.7	PART_WHOLE	48	49	T78-1028.10	44	44	T78-1028.9	MODEL-FEATURE	56	57	T78-1028.12	52	53	T78-1028.11	MODEL-FEATURE	63	64	T78-1028.13	67	67	T78-1028.14
the same two nodes . Path-based inference rules may be written using a binary relational calculus notation . Node-based inference allows a structure of nodes to be inferred from the existence of an instance of a pattern of node structures . Node-based inference rules can be constructed in a semantic network using a variant of a predicate calculus notation . Path-based inference is more efficient , while node-based inference is more general . A and to the explication of inheritance in hierarchies are sketched .	USAGE	13	16	T78-1031.10	5	7	T78-1031.9	USAGE	38	39	T78-1031.14	18	19	T78-1031.11	USAGE	56	58	T78-1031.17	41	43	T78-1031.15	COMPARE	60	61	T78-1031.18	67	68	T78-1031.19	MODEL-FEATURE	79	79	T78-1031.24	81	81	T78-1031.25
. By using commands or rules which are defined to facilitate the construction of format expected or some mathematical expressions , elaborate and pretty documents	USAGE	5	5	C80-1039.7	18	19	C80-1039.8
been made to use an Augmented Transition Network as a procedural dialog model . The development of such represent and to use different dialog schemata proposed in empirical conversation analysis ; as a device to order to account for the verbal interactions of task-oriented dialogs .	USAGE	5	7	C80-1073.1	11	12	C80-1073.2	TOPIC	28	29	C80-1073.5	23	24	C80-1073.4	PART_WHOLE	40	41	C80-1073.11	43	44	C80-1073.12
to Extensible Semantic Analysis Interpreting metaphors is an integral and inescapable process in human understanding of natural language . This paper discusses a method of analyzing metaphors based on the existence of a small number of generalized metaphor mappings . Each generalized metaphor contains a recognition network , a basic mapping ,	PART_WHOLE	5	5	P80-1004.1	13	17	P80-1004.2	USAGE	36	38	P80-1004.4	23	26	P80-1004.3	PART_WHOLE	45	46	P80-1004.6	41	42	P80-1004.5
largely on determining the literal meaning of input from their users . While such decoding is an essential underpinning , much recent work suggests that natural language interfaces will never appear cooperative or graceful unless they also incorporate numerous non-literal aspects of communication , such as robust communication the new technology of powerful personal computers with integral graphics displays offers techniques superior to those needs . The paper proposes interfaces based on a judicious mixture of these techniques and the still valuable methods of more traditional natural language interfaces .	MODEL-FEATURE	5	5	P80-1019.2	7	7	P80-1019.3	USAGE	39	42	P80-1019.7	14	14	P80-1019.5	PART_WHOLE	57	58	P80-1019.11	53	54	P80-1019.10	COMPARE	69	69	P80-1019.13	86	88	P80-1019.14
to describe FlexP , a bottom-up pattern-matching parser that we have designed and implemented to provide these flexibilities for restricted natural language input to a limited-domain computer	USAGE	5	7	P80-1026.8	19	21	P80-1026.9
series of modifications to the left corner parsing algorithm for context-free grammars . It is argued that a good choice for the parser used in a natural language interface .	USAGE	5	8	C82-1054.1	10	11	C82-1054.2	USAGE	22	22	C82-1054.3	26	28	C82-1054.4
entirely in Prolog , a programming language based on logic . With the aid of formalism called extraposition grammars , Chat-80 translates English questions into the Prolog subset of logic . The resulting logical expression efficient Prolog , cf . query optimisation in a relational database . Finally , the Prolog	USAGE	9	9	J82-3002.6	5	6	J82-3002.5	USAGE	20	20	J82-3002.9	22	23	J82-3002.10	PART_WHOLE	27	29	J82-3002.12	26	26	J82-3002.11	USAGE	40	41	J82-3002.16	44	45	J82-3002.17
memos , rough drafts , conversation transcripts etc. , have features that differ significantly from neat texts , posing special problems for is to make use of expectations , based both on knowledge of surface English and on world knowledge of be used to figure out unknown words from context , constrain the possible word-senses of words with multiple meanings ( ambiguity ) , fill in missing words ( ellipsis ) , and resolve referents ( anaphora ) . This method of using expectations to aid the understanding of scruffy texts has been incorporated into a	COMPARE	5	6	P82-1035.8	15	16	P82-1035.9	USAGE	34	35	P82-1035.15	27	27	P82-1035.14	MODEL-FEATURE	49	49	P82-1035.19	46	47	P82-1035.18	MODEL-FEATURE	54	54	P82-1035.20	56	59	P82-1035.21	PART_WHOLE	66	67	P82-1035.23	69	69	P82-1035.24	PART_WHOLE	74	74	P82-1035.25	76	76	P82-1035.26	USAGE	83	83	P82-1035.27	89	90	P82-1035.28
TEACHING This abstract describes a natural language system which deals usefully with ungrammatical input and describes some actual and	USAGE	5	7	P84-1020.1	12	13	P84-1020.2
the empirical viewpoint . For English-Japanese machine translation , the syntax directed approach is effective where the Heuristic play important roles . For Japanese-English translation , the semantics directed approach is powerful where the Conceptual examples of the difference between Japanese sentence structure and English sentence structure , which is vital to	USAGE	10	12	P84-1034.5	5	7	P84-1034.4	USAGE	23	24	P84-1034.8	27	29	P84-1034.9	COMPARE	40	42	P84-1034.13	44	46	P84-1034.14
definitions of the structure and surface representation of domain entities are grouped together . Like recognition and the use of multiple parsing strategies , and so is particularly useful for robust recognition of extra-grammatical input . Several advantages from the presented , along with a control structure for an entity-oriented parser , some parsing strategies that use the control structure , and worked examples of parses . A parser incorporating the control structure and the parsing strategies is	MODEL-FEATURE	5	6	P84-1047.3	8	9	P84-1047.4	USAGE	20	22	P84-1047.8	31	34	P84-1047.9	USAGE	45	46	P84-1047.12	49	50	P84-1047.13	USAGE	58	59	P84-1047.15	53	54	P84-1047.14	PART_WHOLE	71	72	P84-1047.18	68	68	P84-1047.17
may be viewed as a proposition with implicit fuzzy quantifiers which are approximations to all the result of suppressing the fuzzy quantifier most in the proposition most birds can fly . the stage for representing the meaning of a proposition through the use of test-score approach to semantics , the meaning of a proposition , p , is represented description of an approach to reasoning with dispositions which is based on the concept of a fuzzy syllogism . Syllogistic reasoning with dispositions has an important bearing on commonsense reasoning as well as on the management of uncertainty in expert systems . As a simple application we formulate a definition of typicality -- a concept which plays an important role in human cognition and is of relevance to	PART_WHOLE	8	9	P84-1064.7	5	5	P84-1064.6	PART_WHOLE	20	21	P84-1064.8	25	25	P84-1064.9	MODEL-FEATURE	36	36	P84-1064.15	39	39	P84-1064.16	MODEL-FEATURE	50	50	P84-1064.19	53	53	P84-1064.20	USAGE	75	76	P84-1064.22	64	66	P84-1064.21	RESULT	78	81	P84-1064.23	87	88	P84-1064.24	PART_WHOLE	94	96	P84-1064.25	98	99	P84-1064.26	RESULT	110	110	P84-1064.27	120	121	P84-1064.28
report describes Paul , a computer text generation system designed to create cohesive text through the use of lexical substitutions . Specifically , this system designed to deterministically choose between pronominalization , superordinate substitution , and definite noun phrase system identifies a strength of antecedence recovery for each of the lexical substitutions , and matches them against the strength of potential antecedence of each element in the text to select the proper substitutions for these elements .	USAGE	18	19	P84-1078.4	5	8	P84-1078.2	COMPARE	30	30	P84-1078.5	32	33	P84-1078.6	MODEL-FEATURE	44	45	P84-1078.8	50	51	P84-1078.9	MODEL-FEATURE	58	61	P84-1078.10	72	72	P84-1078.12
important role in conveying the meaning of an utterance , but they have often devise methods to grasp the global meaning of a sentence , even if not in way . Another problem with determiners is their inherent ambiguity . In this paper we determiners without forcing a particular interpretation when their meaning is still not clear .	MODEL-FEATURE	5	5	C86-1081.2	8	8	C86-1081.3	MODEL-FEATURE	19	20	C86-1081.4	23	23	C86-1081.5	MODEL-FEATURE	38	38	C86-1081.7	34	34	C86-1081.6	MODEL-FEATURE	49	49	C86-1081.10	52	52	C86-1081.11
paper describes a system ( RAREAS ) which synthesizes marine weather forecasts directly from formatted weather data . Such synthesis appears feasible in certain natural sublanguages with stereotyped text structure . RAREAS draws on several kinds of linguistic and non-linguistic knowledge and mirrors a forecaster 's	USAGE	5	5	C86-1132.1	14	16	C86-1132.2	MODEL-FEATURE	27	29	C86-1132.5	24	25	C86-1132.4	USAGE	37	40	C86-1132.7	31	31	C86-1132.6
SPEECH UNDERSTANDING A method for error correction of ill-formed input is described that acquires dialogue is not expected . A dialogue acquisition and tracking algorithm is presented along with a description of its implementation in a voice interactive system . A series of tests	USAGE	5	6	J86-1002.1	8	9	J86-1002.2	PART_WHOLE	20	24	J86-1002.9	36	38	J86-1002.11
the role of purpose and processing in discourse . In this theory , structure of the sequence of utterances ( called the linguistic structure ) , a structure of purposes ( called the intentional structure ) , and the state of focus of attention ( called the attentional state ) . The linguistic structure consists of segments of the discourse into which the utterances naturally aggregate . The intentional structure captures the discourse-relevant purposes , expressed in each of relationships among them . The attentional state is an abstraction of the focus of attention of the participants as the , and interruptions . The theory of attention , intention , and aggregation of utterances is illustrated in the paper with a number of example discourses . Various properties of discourse for describing the processing of utterances in a discourse . Discourse processing requires recognizing how the utterances of the discourse aggregate into segments , recognizing the intentions expressed in the discourse and the relationships among intentions	RESULT	5	5	J86-3001.3	7	7	J86-3001.4	MODEL-FEATURE	22	23	J86-3001.7	18	18	J86-3001.6	MODEL-FEATURE	33	34	J86-3001.9	29	29	J86-3001.8	MODEL-FEATURE	47	48	J86-3001.11	41	43	J86-3001.10	PART_WHOLE	63	63	J86-3001.14	59	59	J86-3001.13	MODEL-FEATURE	68	69	J86-3001.15	72	73	J86-3001.16	MODEL-FEATURE	84	85	J86-3001.18	91	93	J86-3001.19	MODEL-FEATURE	104	113	J86-3001.28	124	124	J86-3001.29	PART_WHOLE	135	135	J86-3001.35	138	138	J86-3001.36	PART_WHOLE	146	146	J86-3001.38	149	149	J86-3001.39	PART_WHOLE	156	156	J86-3001.41	160	160	J86-3001.42
work is the enrichment of human-machine interactions in a natural language environment . Because a speaker and listener can not be assured to	MODEL-FEATURE	9	11	J86-4002.2	5	6	J86-4002.1	COMPARE	15	15	J86-4002.3	17	17	J86-4002.4
the two grammatical formalisms : Tree Adjoining Grammars and Head Grammars . We briefly investigate the weak equivalence of the two formalisms . We then turn to a discussion comparing the linguistic expressiveness of the two formalisms .	COMPARE	5	7	P86-1011.2	9	10	P86-1011.3	MODEL-FEATURE	17	17	P86-1011.4	21	21	P86-1011.5	MODEL-FEATURE	31	32	P86-1011.6	36	36	P86-1011.7
use structures containing sets of features to describe linguistic objects . Although computational algorithms for model in which descriptions of feature structures can be regarded as logical formulas , and interpreted by sets are , in fact , transition graphs for a special type of deterministic finite automaton . This semantics for feature structures extends the ideas of Pereira are specified by disjunctions and path values embedded within disjunctions . Our interpretation differs from and Shieber by using a logical model in place of a denotational semantics . This logical model yields a calculus of equivalences , which can be used to simplify formulas . Unification is attractive , a careful examination of the computational complexity of unification . We have shown that the consistency problem for formulas with disjunctive values is NP-complete	MODEL-FEATURE	5	5	P86-1038.2	8	9	P86-1038.3	MODEL-FEATURE	20	21	P86-1038.7	26	27	P86-1038.8	PART_WHOLE	38	39	P86-1038.11	45	47	P86-1038.12	MODEL-FEATURE	50	50	P86-1038.13	52	53	P86-1038.14	PART_WHOLE	64	65	P86-1038.16	68	68	P86-1038.17	COMPARE	79	80	P86-1038.18	85	86	P86-1038.19	USAGE	89	90	P86-1038.20	103	103	P86-1038.22	MODEL-FEATURE	114	115	P86-1038.25	117	117	P86-1038.26	MODEL-FEATURE	124	125	P86-1038.27	127	127	P86-1038.28
and heuristically-produced complete sentences in text or text-to-speech form . Deictic reference and feedback about the discourse are enabled . The interface	COMPARE	5	5	A88-1001.7	7	8	A88-1001.8	MODEL-FEATURE	13	13	A88-1001.10	16	16	A88-1001.11
paper , we describe the pronominal anaphora resolution module of Lucy , a portable English understanding Thus we have implemented a blackboard-like architecture in which individual partial theories can be encoded as separate	PART_WHOLE	5	8	A88-1003.1	10	10	A88-1003.2	PART_WHOLE	26	27	A88-1003.6	21	22	A88-1003.5
paper discusses the application of Unification Categorial Grammar ( UCG ) to the framework of Isomorphic Grammars for Machine Translation pioneered by Landsbergen . The to MT involves developing the grammars of the Source and Target languages in parallel , in order to ensure that SL and TL expressions which stand in the but as constraints on the translation relation , not as levels of textual representation . After introducing this approach	USAGE	5	10	C88-1007.1	18	19	C88-1007.3	MODEL-FEATURE	30	30	C88-1007.5	33	36	C88-1007.6	COMPARE	45	45	C88-1007.7	47	47	C88-1007.8	COMPARE	58	59	C88-1007.13	65	66	C88-1007.14
conditions for the use of demonstrative expressions in English and discusses implications for current examine a broad range of texts to show how the distribution of demonstrative forms and functions is genre dependent . This	PART_WHOLE	5	6	C88-1044.1	8	8	C88-1044.2	PART_WHOLE	26	29	C88-1044.5	19	19	C88-1044.4
interpret it . CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow use of CCRs leads to syntactic descriptions formulated entirely with restrictive statements . The paper shows how algorithms for the analysis of context free languages can be adapted to the CCR formalism . Special attention is given that checks the fulfillment of logical well-formedness conditions on trees .	MODEL-FEATURE	5	6	C88-1066.4	11	11	C88-1066.5	MODEL-FEATURE	27	28	C88-1066.11	22	23	C88-1066.10	COMPARE	39	41	C88-1066.12	47	48	C88-1066.13	MODEL-FEATURE	59	61	C88-1066.15	63	63	C88-1066.16
and straightforward explanation for the presuppositional nature of these sentences .	MODEL-FEATURE	5	6	C88-2086.3	9	9	C88-2086.4
Descriptions We have developed a computational model of the process of describing the layout of an apartment or house , a much-studied discourse task first characterized linguistically by Linde ( 1974 ) . The model is embodied in a program , APT , that can reproduce segments	USAGE	5	6	C88-2130.1	22	23	C88-2130.2	PART_WHOLE	34	34	C88-2130.3	41	41	C88-2130.4
place where the easily identifiable fragments occur in the sentence , the process will extend	PART_WHOLE	5	5	C88-2132.7	9	9	C88-2132.8
disambiguation scheme based on the paraphrasing of a parser 's multiple output . Some examples of paraphrasing ambiguous sentences are presented .	RESULT	8	8	C88-2160.10	5	5	C88-2160.9	MODEL-FEATURE	16	16	C88-2160.11	18	18	C88-2160.12
, learning methodology applicable in general domains does not readily lend itself in the linguistic domain . For another , linguistic representation used by language processing systems is not geared to learning new linguistic representation , the Dynamic Hierarchical Phrasal Lexicon ( DHPL ) [ Zernik88 ] , to facilitate language acquisition . From this , a language learning model was implemented in the program RINA , which enhances its own lexical hierarchy by processing examples in context tasks : First , how linguistic concepts are acquired from training examples and organized in a hierarchy in this paper how a lexical hierarchy is used in predicting new linguistic concepts . Thus , a program in the presence of a lexical unknown , and a hypothesis can be produced for covering	COMPARE	5	6	C88-2162.3	14	15	C88-2162.4	USAGE	20	21	C88-2162.5	24	26	C88-2162.6	USAGE	37	43	C88-2162.9	50	51	C88-2162.10	PART_WHOLE	71	72	C88-2162.13	57	59	C88-2162.11	MODEL-FEATURE	83	84	C88-2162.14	88	89	C88-2162.15	USAGE	100	101	C88-2162.17	107	108	C88-2162.18	MODEL-FEATURE	124	124	C88-2162.21	119	120	C88-2162.20
Natural Language Systems Although every natural language system needs a computational lexicon , each system puts different and building COMPLEX , a computational lexicon designed to be a repository of shared lexical information for use by Natural Language explicit and implicit information from machine-readable dictionaries ( MRD 's ) to create a broad coverage lexicon .	USAGE	10	11	C88-2166.2	5	7	C88-2166.1	PART_WHOLE	30	32	C88-2166.6	22	23	C88-2166.5	USAGE	43	48	C88-2166.8	52	54	C88-2166.9
paper explores the role of user modeling in such systems . It begins with a types of information that a user model may be required to keep about a user are then identified and discussed acquiring the knowledge for a user model is a fundamental problem in user modeling , a section is devoted	RESULT	5	6	J88-3002.4	9	9	J88-3002.5	MODEL-FEATURE	20	21	J88-3002.7	29	29	J88-3002.8	PART_WHOLE	40	41	J88-3002.10	47	48	J88-3002.11
bidirectional grammar generation system called feature structure-directed generation , developed for a dialogue translation system . The system utilizes typed feature structures to control the top-down derivation in a declarative way . This generation system also uses disjunctive feature structures to reduce the number of the derivation tree . The grammar for this generator is designed to properly generate	USAGE	5	7	C90-1013.2	12	14	C90-1013.3	USAGE	19	21	C90-1013.4	25	26	C90-1013.5	USAGE	37	39	C90-1013.7	33	34	C90-1013.6	USAGE	50	50	C90-1013.9	53	53	C90-1013.10
for the disambiguation of the dependency structure of sentences . The DoPS system extracts preference knowledge from a target document or other documents automatically . for the the analysis of dependency structures of Japanese patent claim sentences .	MODEL-FEATURE	5	6	C90-2032.2	8	8	C90-2032.3	USAGE	11	12	C90-2032.4	18	19	C90-2032.5	MODEL-FEATURE	30	31	C90-2032.11	33	36	C90-2032.12
describes the framework of a Korean phonological knowledge base system using the unification-based grammar formalism : Korean Phonology Structure Grammar ) . The approach of KPSG provides an explicit development model for constructing a computational phonological system : speech recognition and synthesis	USAGE	12	14	C90-3014.2	5	9	C90-3014.1	USAGE	25	25	C90-3014.4	35	36	C90-3014.5
beyond the limited confines of syntax , for instance , to the task of semantic interpretation or automatic translation of natural natural languages to their associated semantics represented in a logical form language , or to their translates in another natural language ; in summary , we intend it to allow TAGs to be used beyond their role in syntax proper . We discuss the application	COMPARE	5	5	C90-3045.3	14	15	C90-3045.4	MODEL-FEATURE	30	32	C90-3045.11	26	26	C90-3045.10	MODEL-FEATURE	37	37	C90-3045.12	40	41	C90-3045.13	USAGE	51	51	C90-3045.14	59	60	C90-3045.15
Argumentation This paper proposes that sentence analysis should be treated as defeasible reasoning , and presents such a treatment for Japanese sentence analyses using an argumentation system by Konolige , which is a formalization of defeasible reasoning , that includes arguments and defeat rules that capture defeasibility .	MODEL-FEATURE	5	6	C90-3046.1	11	12	C90-3046.2	USAGE	25	26	C90-3046.4	20	22	C90-3046.3	MODEL-FEATURE	33	33	C90-3046.5	35	36	C90-3046.6	MODEL-FEATURE	42	43	C90-3046.8	46	46	C90-3046.9
Spelling-checking for Highly Inflective Languages Spelling-checkers have become an integral part of most text processing software . From different reasons among they are usually based on dictionaries of word forms instead of words . This approach is sufficient for languages with little inflection such as English , but fails for highly inflective languages such as Czech , Russian , Slovak or of the scale of existing spelling-checkers for English and the main dictionary fits whereas the number of recognized word forms exceeds 6 million ( for Czech ) . Further , a	PART_WHOLE	5	5	C90-3072.1	13	15	C90-3072.2	COMPARE	26	29	C90-3072.3	32	32	C90-3072.4	MODEL-FEATURE	42	42	C90-3072.5	45	45	C90-3072.6	MODEL-FEATURE	50	52	C90-3072.7	55	55	C90-3072.8	USAGE	66	66	C90-3072.14	68	68	C90-3072.15	PART_WHOLE	79	80	C90-3072.18	86	86	C90-3072.19
sentence hypotheses . To avoid grammar coverage problems we use a fully-connected first-order statistical class grammar . The speech-search algorithm is implemented on a board with a single Intel i860 chip , which provides a factor board plugs directly into the VME bus of the SUN4 , which controls the system	USAGE	11	15	H90-1016.4	5	7	H90-1016.3	MODEL-FEATURE	28	30	H90-1016.7	24	24	H90-1016.6	PART_WHOLE	41	42	H90-1016.11	45	45	H90-1016.12
present a new paradigm for speaker-independent ( SI ) training of hidden Markov models ( HMM ) , which uses a large amount of speech from a few speakers instead is done by averaging the statistics of independently trained models rather than the usual pooling of all the speech data from many speakers prior to training . With only 12 training speakers for SI recognition , we achieved a 7.5 % word error rate on a standard grammar and test set from the DARPA Resource Management corpus . This performance is comparable show a significant improvement for speaker adaptation ( SA ) using the new SI corpus and a small amount of target ) speaker . A probabilistic spectral mapping is estimated independently for each training ( reference ) speaker and the target speaker . Each reference model is transformed to the space of the target speaker and combined by averaging . Using only 40 utterances from the target speaker for adaptation , the error rate dropped	USAGE	24	24	H90-1060.4	5	9	H90-1060.2	COMPARE	35	35	H90-1060.9	48	49	H90-1060.11	RESULT	60	61	H90-1060.14	71	73	H90-1060.16	PART_WHOLE	79	80	H90-1060.18	83	86	H90-1060.19	USAGE	105	106	H90-1060.23	97	101	H90-1060.22	MODEL-FEATURE	117	119	H90-1060.26	125	129	H90-1060.27	USAGE	150	150	H90-1060.32	136	137	H90-1060.29	USAGE	155	155	H90-1060.33	161	161	H90-1060.35
This paper presents a specialized editor for a highly structured dictionary . The basic goal in building that editor was to provide an adequate tool to help lexicologists produce a valid and coherent dictionary on the basis of a linguistic theory . If we want valuable lexicons and grammars to achieve complex natural language processing , we must provide very	USAGE	5	5	J90-3002.1	10	10	J90-3002.2	USAGE	18	18	J90-3002.3	27	27	J90-3002.4	USAGE	39	40	J90-3002.6	33	33	J90-3002.5	USAGE	48	48	J90-3002.8	52	54	J90-3002.9
Algorithm The principle known as free indexation plays an important role in the determination of the referential properties of noun phrases in the principle-and-parameters language framework	RESULT	5	6	P90-1014.1	16	20	P90-1014.2
describe three techniques for making syntactic analysis more robust -- -an agenda-based scheduling parser , a recovery technique for terminal substring parsing . For pragmatics processing , we describe how the method of abductive inference is inherently robust , in	USAGE	11	13	A92-1026.6	5	6	A92-1026.5	USAGE	33	34	A92-1026.10	24	25	A92-1026.9
present an efficient algorithm for chart-based phrase structure parsing of natural language that is tailored to the of extracting specific information from unrestricted texts where many of the words are unknown and much of only the topmost of the edges adjacent to it , rather than all such edges as in conventional treatments . facilitated through the use of phrase boundary heuristics based on the placement of function words , and by heuristic rules that permit certain kinds of phrases to be deduced despite the presence of unknown words . A further reduction in space is achieved by using semantic rather than syntactic categories on the terminal and non-terminal thereby reducing the amount of ambiguity and thus the number of edges , since only edges with a valid semantic interpretation are ever introduced .	USAGE	5	8	A92-1027.1	10	11	A92-1027.2	PART_WHOLE	28	28	A92-1027.4	22	23	A92-1027.3	COMPARE	39	39	A92-1027.11	48	48	A92-1027.12	USAGE	67	68	A92-1027.18	59	61	A92-1027.17	PART_WHOLE	87	88	A92-1027.21	79	79	A92-1027.20	COMPARE	99	99	A92-1027.23	102	103	A92-1027.24	RESULT	114	114	A92-1027.26	120	120	A92-1027.27	MODEL-FEATURE	128	128	A92-1027.29	124	124	A92-1027.28
defined and a method for discourse segmentation primarily based on abduction of temporal relations between segments is proposed . This method	USAGE	10	10	C92-1052.3	5	6	C92-1052.2	MODEL-FEATURE	12	13	C92-1052.4	15	15	C92-1052.5
a discrimination and robustness oriented adaptive learning procedure is proposed to deal with the task of syntactic ambiguity resolution . Owing to the problem of insufficient training data and approximation error introduced by the language model , traditional statistical approaches , which resolve ambiguities by indirectly and implicitly using maximum likelihood method , fail to achieve high in the test . The accuracy rate of syntactic disambiguation is raised from 46.0 %	USAGE	5	7	C92-1055.1	16	18	C92-1055.2	RESULT	34	35	C92-1055.5	29	30	C92-1055.4	USAGE	49	51	C92-1055.8	38	39	C92-1055.6	RESULT	65	66	C92-1055.14	62	63	C92-1055.13
Quasi-Destructive Graph Unification with Structure-Sharing Graph unification remains the most expensive part of unification-based grammar parsing . We focus on one method of structure-sharing which avoids log ( d ) overheads often associated with structure-sharing of graphs without any use of costly	PART_WHOLE	5	6	C92-2068.1	13	15	C92-2068.2	MODEL-FEATURE	26	30	C92-2068.7	34	36	C92-2068.8
A Similarity-Driven Transfer System The transfer phase in machine translation ( MT ) systems has been considered to be more complicated than analysis and generation , since it are being made to use case-based reasoning in machine translation , that is , to transfer system , called a Similarity-driven Transfer System ( SimTran ) , for use in such case-based MT ( CBMT ) .	COMPARE	5	6	C92-2115.1	22	22	C92-2115.3	USAGE	33	34	C92-2115.6	36	37	C92-2115.7	USAGE	48	53	C92-2115.11	59	63	C92-2115.12
portion is detected , the parser skips that portion using a fake non-terminal symbol . The unidentified portion is very efficiently by using the parse record of the first utterance . The user does not in practical systems . Detected unknown words can be incrementally incorporated into the dictionary after the interaction with the	USAGE	12	13	C92-3165.7	5	5	C92-3165.5	MODEL-FEATURE	24	25	C92-3165.11	29	29	C92-3165.12	PART_WHOLE	40	41	C92-3165.16	48	48	C92-3165.17
based on the concept of sublanguage , is proposed for identifying unknown words , especially personal names , in Chinese newspapers . The proposed mechanism includes	USAGE	5	5	C92-4199.3	11	12	C92-4199.4	PART_WHOLE	15	16	C92-4199.5	19	20	C92-4199.6
the understanding process of the spatial descriptions in Japanese . In order to understand language texts and produces a model of the described world . To reconstruct the model , the authors extract the qualitative spatial constraints from the text , and represent them as the numerical constraints on the spatial attributes of the entities . This makes it possible . The interpretation reflects the temporary belief about the world .	PART_WHOLE	5	6	C92-4207.1	8	8	C92-4207.2	MODEL-FEATURE	19	19	C92-4207.7	23	23	C92-4207.8	PART_WHOLE	34	36	C92-4207.10	39	39	C92-4207.11	MODEL-FEATURE	50	51	C92-4207.13	54	54	C92-4207.14	MODEL-FEATURE	65	66	C92-4207.16	69	69	C92-4207.17
paper describes a recently collected spoken language corpus for the ATIS ( Air Travel Information System ) domain . This data collection effort collection and distribution of 12,000 utterances of spontaneous speech from five sites for use	MODEL-FEATURE	10	17	H92-1003.2	5	7	H92-1003.1	MODEL-FEATURE	30	31	H92-1003.8	28	28	H92-1003.7
LIMSI in the field of speech processing , but also in the related areas of Human-Machine Communication , including Natural Language Processing	COMPARE	5	6	H92-1010.2	15	16	H92-1010.3
This paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system : non-monotonic reasoning , implicit have done in extending the n-best speech/language integration architecture to improving OCR accuracy .	MODEL-FEATURE	5	6	H92-1017.1	11	15	H92-1017.2	RESULT	26	29	H92-1017.8	33	33	H92-1017.10
that takes advantage of detailed linguistic information to resolve ambiguity . HBG incorporates lexical , syntactic , semantic , and structural information from the parse tree into that will determine the correct parse of a sentence . This stands in contrast the usual approach of further grammar tailoring via the usual linguistic introspection in the hope of generating we call P-CFG , the HBG model significantly outperforms P-CFG , increasing the parsing accuracy	USAGE	5	6	H92-1026.3	9	9	H92-1026.4	USAGE	13	21	H92-1026.6	11	11	H92-1026.5	MODEL-FEATURE	32	32	H92-1026.13	35	35	H92-1026.14	USAGE	51	52	H92-1026.16	46	46	H92-1026.15	COMPARE	63	64	H92-1026.21	67	67	H92-1026.22
algorithm , are expanded and reestimation formulas are given for HMM with Gaussian mixture observation densities . Because of its adaptive nature , Bayesian learning serves as a unified approach for the following four speech recognition applications , namely parameter smoothing	USAGE	5	6	H92-1036.6	10	15	H92-1036.7	USAGE	23	24	H92-1036.8	34	35	H92-1036.9
there are polysemous words like sentence whose meaning or sense depends on the recently reported on two new word-sense disambiguation systems , one trained on bilingual material ( the Canadian Hansards ) a polysemous word such as sentence appears two or more times in a well-written discourse , it is extremely likely that the tendency to share sense in the same discourse is extremely strong ( 98 as an additional source of constraint for improving the performance of the word-sense disambiguation algorithm . In addition , it be used to help evaluate disambiguation algorithms that did not make use of the discourse constraint .	MODEL-FEATURE	7	7	H92-1045.3	5	5	H92-1045.2	USAGE	25	26	H92-1045.6	18	20	H92-1045.5	PART_WHOLE	37	37	H92-1045.13	45	46	H92-1045.14	PART_WHOLE	57	57	H92-1045.16	61	61	H92-1045.17	USAGE	72	72	H92-1045.18	79	81	H92-1045.19	USAGE	101	102	H92-1045.21	92	93	H92-1045.20
, we explore correlation of dependency relation paths to rank candidate answers in answer extraction . Using the correlation measure , we compare dependency relations of a candidate answer and mapped question phrases in sentence with the corresponding mapping algorithm and incorporate the mapping score into the correlation measure . The correlations are further	USAGE	5	7	P06-1112.1	13	14	P06-1112.2	MODEL-FEATURE	23	24	P06-1112.4	31	32	P06-1112.5	PART_WHOLE	43	44	P06-1112.9	47	48	P06-1112.10
scheme for collecting statistics on cooccurrence patterns in a large corpus . To a large extent , these statistics reflect semantic constraints and thus are used to disambiguate anaphora references and syntactic ambiguities . The experiment was performed to resolve references of the pronoun `` it '' in sentences that were randomly selected from the corpus . The results of the most of the cases the cooccurrence statistics indeed reflect the semantic constraints and thus provide a basis for a useful disambiguation tool .	PART_WHOLE	5	6	C90-3063.3	10	10	C90-3063.4	USAGE	20	21	C90-3063.5	28	29	C90-3063.6	MODEL-FEATURE	40	40	C90-3063.8	43	46	C90-3063.9	PART_WHOLE	48	48	C90-3063.10	55	55	C90-3063.11	USAGE	66	67	C90-3063.12	81	82	C90-3063.14
relative entropy , between a probabilistic context-free grammar and a probabilistic finite automaton . We show that there for one part of the Kullback-Leibler distance , viz . the cross-entropy . We discuss several applications result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata .	COMPARE	5	7	C04-1011.3	10	12	C04-1011.4	PART_WHOLE	29	29	C04-1011.7	23	24	C04-1011.6	USAGE	49	51	C04-1011.10	40	41	C04-1011.8
Agglutinative Languages Methods developed for spelling correction for languages like English ( see the poster presents an approach to spelling correction in agglutinative languages that is based on two-level present results from experiments with spelling correction in Turkish .	USAGE	5	6	A94-1037.1	8	8	A94-1037.2	USAGE	19	20	A94-1037.5	22	23	A94-1037.6	USAGE	34	35	A94-1037.9	37	37	A94-1037.10
demonstrate robust , high performance continuous speech recognition ( CSR ) techniques focussed on application in Spoken Language Systems ( SLS ) which will enhance the effectiveness help catalyze the transition of spoken language technology into military and civilian systems , with particular focus on application of robust CSR to mobile military command and control . The research effort focusses recognition-time adaptation techniques for robust large-vocabulary CSR , and on applying these techniques to the new ARPA large-vocabulary CSR corpora and to military application tasks	USAGE	5	11	H94-1102.1	16	21	H94-1102.2	USAGE	32	34	H94-1102.5	36	39	H94-1102.6	USAGE	48	48	H94-1102.7	50	54	H94-1102.8	USAGE	65	66	H94-1102.11	76	79	H94-1102.12
of hypertext presentation generators . Presentor offers intuitive and powerful declarative languages specifying the presentation at different	PART_WHOLE	10	11	P98-1118.4	5	5	P98-1118.3
of groups involved in the DARPA Spoken Language Systems ( SLS ) program to agree on a methodology for comparative evaluation of SLS systems , and that methodology has evaluations are probably the only NL evaluations other than the series of Message Understanding Conferences ( Sundheim , 1989 ; This paper describes a practical `` black-box '' methodology for automatic evaluation of question-answering NL systems . While each new application	TOPIC	5	12	A92-1023.4	22	23	A92-1023.5	TOPIC	41	43	A92-1023.8	34	35	A92-1023.7	USAGE	54	57	A92-1023.9	62	64	A92-1023.10
Application To Psycholinguistic Modeling The psycholinguistic literature provides evidence for syntactic priming , i.e. , the tendency describes a method for incorporating priming into an incremental probabilistic parser . Three models are compared the reading time advantage for parallel structures found in human data , and also yield a	TOPIC	5	6	P06-1053.1	10	11	P06-1053.2	USAGE	22	22	P06-1053.3	25	27	P06-1053.4	PART_WHOLE	38	39	P06-1053.10	42	43	P06-1053.11
Sense Disambiguation Instances of a word drawn from different domains may have different sense priors ( the proportions of the different senses of a word ) . This in turn affects the accuracy of word sense disambiguation ( WSD ) systems trained and applied on different domains . This paper presents a method to estimate the sense priors of words drawn from a new domain highlights the importance of using well calibrated probabilities when performing these estimations . By using well calibrated probabilities , we are able to estimate the sense priors effectively to achieve significant improvements	MODEL-FEATURE	13	14	P06-1012.3	5	5	P06-1012.1	MODEL-FEATURE	21	21	P06-1012.4	24	24	P06-1012.5	USAGE	34	40	P06-1012.6	46	46	P06-1012.7	MODEL-FEATURE	56	57	P06-1012.8	59	59	P06-1012.9	USAGE	70	72	P06-1012.11	76	76	P06-1012.12	USAGE	80	82	P06-1012.13	90	91	P06-1012.14
Language Dictionary How to obtain hierarchical relations ( e.g . superordinate -hyponym relation , synonym relation ) is one of the most important problems for thesaurus construction . A pilot system for extracting these relations automatically from an ordinary Japanese language dictionary ( Shinmeikai Kokugojiten , published . The features of the definition sentences in the dictionary , the mechanical extraction of	PART_WHOLE	5	6	C86-1105.1	25	26	C86-1105.4	PART_WHOLE	34	34	C86-1105.5	39	41	C86-1105.6	PART_WHOLE	52	53	C86-1105.7	56	56	C86-1105.8
by researchers originally interested in natural language understanding who take machine translation to be one possible application However , not only the ambiguity but also the vagueness which every natural language inevitably has leads this approach the Mu-project , adopts the transfer approach as the basic framework of MT . This paper describes the detailed construction of the transfer phase of our system from Japanese to English , and gives some examples of problems which seem difficult to treat in the interlingual approach . The basic design principles	USAGE	5	7	C86-1021.2	10	11	C86-1021.3	MODEL-FEATURE	22	22	C86-1021.4	29	30	C86-1021.5	USAGE	41	42	C86-1021.7	48	48	C86-1021.8	COMPARE	58	59	C86-1021.9	81	82	C86-1021.12
entropy classifiers , boosting and SVMs are applied to language processing tasks , it is possible to further improve performance , various error correction mechanisms have been developed , but in practice , most of them can not be relied on to predictably improve performance on unseen data ; indeed , depending upon	USAGE	5	5	C04-1058.4	9	11	C04-1058.5	USAGE	22	24	C04-1058.6	46	47	C04-1058.7
problem of automatic acquisition of entailment relations between verbs . While this task has acquisition which aims to discover semantic equivalence between verbs , the main challenge of entailment acquisition is to capture asymmetric , or directional , relations . Motivated by the intuition that it often underlies the local structure of coherent text , we develop a method verb entailment using evidence about discourse relations between clauses available in a parsed corpus and learns the mapping between verbs with highly varied argument structures .	MODEL-FEATURE	5	6	N06-1007.2	8	8	N06-1007.3	MODEL-FEATURE	19	20	N06-1007.5	22	22	N06-1007.6	TOPIC	28	29	N06-1007.7	33	38	N06-1007.8	MODEL-FEATURE	49	50	N06-1007.9	52	53	N06-1007.10	MODEL-FEATURE	64	65	N06-1007.12	67	67	N06-1007.13	MODEL-FEATURE	78	78	N06-1007.17	82	83	N06-1007.18
sentence generation in which alternative phrases are represented as packed sets of trees , or forests , and statistical generation . An efficient ranking algorithm is described , together with experimental results showing significant improvements over simple enumeration or a lattice-based approach .	MODEL-FEATURE	5	5	A00-2023.2	12	12	A00-2023.3	COMPARE	23	24	A00-2023.8	40	41	A00-2023.9
two different models to extract sentences for summary generation under two tasks initiated by SUMMAC-1 . For categorization task , positive feature vectors and negative feature vectors are For adhoc task , a text model based on relationship between nouns and verbs is used to filter out irrelevant discourse segment , to rank relevant sentences , and to generate the user-directed summaries . The result shows that	USAGE	5	5	X98-1022.6	7	8	X98-1022.7	USAGE	20	22	X98-1022.10	17	18	X98-1022.9	USAGE	33	34	X98-1022.13	60	61	X98-1022.18
word vectors , and the similarity between the vectors is then calculated . The of articles , an efficient threading algorithm that runs in 0 ( n ) time ( where n is the with words that represent the topics of the threads , and words that represent new information in each article . The	MODEL-FEATURE	5	5	P98-2213.3	8	8	P98-2213.4	MODEL-FEATURE	19	20	P98-2213.8	24	28	P98-2213.9	MODEL-FEATURE	39	39	P98-2213.12	42	42	P98-2213.13	MODEL-FEATURE	45	45	P98-2213.14	49	49	P98-2213.15
) annotation schema where each SSTC describes a sentence , a representation tree as well as the correspondence between substrings in the sentence and subtrees in the representation tree . In the process of we first try to build subtrees for phrases in the input sentence which	MODEL-FEATURE	5	5	P98-1113.6	8	8	P98-1113.7	PART_WHOLE	19	19	P98-1113.9	22	22	P98-1113.10	PART_WHOLE	24	24	P98-1113.11	27	28	P98-1113.12	MODEL-FEATURE	39	39	P98-1113.14	41	41	P98-1113.15
( HMM ) and an HMM-based chunk tagger , from which a named entity ( NE ) recognition ( NER ) system is built to recognize and deterministic internal feature of the words , such as capitalization and digitalization ; 2 ) effectively . Evaluation of our system on MUC-6 and MUC-7 English NE tasks achieves F-measures of 96.6 % and 94.1	USAGE	5	7	P02-1060.2	12	21	P02-1060.3	MODEL-FEATURE	36	36	P02-1060.8	32	32	P02-1060.7	RESULT	47	47	P02-1060.13	56	56	P02-1060.15
Lexical Sublanguage Grammar Porting a Natural Language Processing ( NLP ) system to a new domain remains one of the bottlenecks , and to attune the existing grammar to the idiosyncracies of the new sublanguage . This paper shows how the process of fitting a lexicalized grammar to a domain can be automated to a a hybrid system that combines traditional knowledge-based techniques with a corpus-based approach .	USAGE	14	15	C96-2213.2	5	11	C96-2213.1	USAGE	26	27	C96-2213.5	33	34	C96-2213.6	USAGE	45	46	C96-2213.7	49	49	C96-2213.8	COMPARE	60	62	C96-2213.10	65	66	C96-2213.11
for orthographic variants caused by transliteration in a large corpus . The method employs two similarities . One is string similarity based on edit distance . The other is contextual similarity by a vector space model . Experimental results show that	PART_WHOLE	5	5	C04-1102.2	9	9	C04-1102.3	USAGE	23	24	C04-1102.6	19	20	C04-1102.5	USAGE	33	35	C04-1102.8	29	30	C04-1102.7
focused on identifying and understanding temporal expressions in newswire texts . In this paper we report our work on anchoring temporal expressions in a novel genre , emails . The highly have developed and evaluated a Temporal Expression Anchoror ( TEA ) , and the result shows that it performs significantly better than the baseline , and compares favorably with	PART_WHOLE	5	6	N06-1018.2	8	9	N06-1018.3	MODEL-FEATURE	25	25	N06-1018.5	20	21	N06-1018.4	COMPARE	36	41	N06-1018.9	54	54	N06-1018.10
will demonstrate the usefulness of voice input for interactive problem solving . The system will accept . Combining speech recognition and natural language processing to achieve speech understanding , the system will be speech recognition system using a segment-based approach to phonetic recognition . The recognition system will eventually be integrated with natural language processing to achieve spoken language understanding .	USAGE	5	6	H89-2066.2	8	10	H89-2066.3	USAGE	21	23	H89-2066.8	26	27	H89-2066.9	USAGE	38	39	H89-2066.12	41	42	H89-2066.13	USAGE	52	54	H89-2066.15	57	59	H89-2066.16
implemented in it . The knowledge to be expressed in text is first divided into small The Fragment-and-Compose paradigm and the computational methods of KDS are described .	PART_WHOLE	5	5	J81-1002.4	10	10	J81-1002.5	USAGE	21	22	J81-1002.15	24	24	J81-1002.16
Of A Hybrid Deterministic Parser A deterministic parser is under development which represents a departure from traditional deterministic parsers in that it combines both from patterns derived from the rules of a deterministic grammar . The development and evolution architecture has lead to a parser which is superior to any known deterministic parser . Experiments are described and powerful training techniques are demonstrated that permit decision-making by the connectionist component in the parsing process . This approach has permitted some simplifications to the rules of other deterministic parsers , including the elimination of presented which show how a connectionist ( neural ) network trained with linguistic rules can parse both expected ( grammatical ) sentences as well as some novel	COMPARE	5	7	C90-1002.1	16	18	C90-1002.2	PART_WHOLE	29	29	C90-1002.5	32	33	C90-1002.6	COMPARE	44	44	C90-1002.8	50	52	C90-1002.9	USAGE	59	60	C90-1002.10	65	65	C90-1002.11	PART_WHOLE	68	69	C90-1002.12	72	73	C90-1002.13	PART_WHOLE	83	83	C90-1002.14	86	87	C90-1002.15	USAGE	98	102	C90-1002.18	110	114	C90-1002.20
empirically motivates an integration of supervised learning with unsupervised learning to deal with human biases in summarization . In particular , we human created summaries . The corpus of human created extracts is created from a newspaper corpus and used as a test	USAGE	5	6	P02-1059.1	16	16	P02-1059.3	PART_WHOLE	36	37	P02-1059.7	27	27	P02-1059.6
describe a search procedure for statistical machine translation ( MT ) based on dynamic programming ( DP ) . Starting from a DP-based are carried out on the Verbmobil task ( German-English , 8000-word vocabulary ) , which is a limited-domain spoken-language task .	USAGE	13	17	C00-2123.2	5	10	C00-2123.1	MODEL-FEATURE	40	42	C00-2123.6	28	29	C00-2123.5
paper addresses the issue of word-sense ambiguity in extraction from machine-readable resources for the construction of large-scale ) , i.e. , that verb semantics and syntactic behavior are predictably related ; ( can be achieved in deriving semantic information from syntactic cues if we first divide the syntactic cues into distinct groupings that correlate with different word senses . Finally , we show	PART_WHOLE	5	6	C96-1055.1	10	11	C96-1055.2	COMPARE	22	23	C96-1055.8	25	26	C96-1055.9	USAGE	40	41	C96-1055.11	37	38	C96-1055.10	COMPARE	47	48	C96-1055.12	56	57	C96-1055.13
concept representations , for building natural language processing ( NLP ) systems for text understanding . Systems built with PAKTUS as a news wire . PAKTUS supports the adaptation of the generic core to a variety of domains : JINTACCS messages , RAINFORM messages , news	USAGE	5	11	M91-1029.4	13	14	M91-1029.5	USAGE	25	25	M91-1029.9	39	40	M91-1029.10
Parsing The multiplicative fragment of linear logic has found a number of applications in computational linguistics : in the `` glue language '' approach to LFG semantics , and in the formulation	USAGE	5	6	P98-1088.1	14	15	P98-1088.2	USAGE	19	22	P98-1088.3	25	26	P98-1088.4
emphatic facial displays for an embodied conversational agent in a dialogue system . A corpus of sentences	PART_WHOLE	5	7	E06-1045.1	10	11	E06-1045.2
a simultaneous language model and parser for large-vocabulary speech recognition . The model is adapted and parser probabilities . The parser uses structural and lexical dependencies not considered by n-gram models language model while extracting additional structural information useful for speech understanding .	USAGE	5	5	P04-1030.3	7	9	P04-1030.4	USAGE	22	25	P04-1030.8	20	20	P04-1030.7	USAGE	36	37	P04-1030.13	40	41	P04-1030.14
. They are probability , rank , and entropy . We evaluated the performance of the three pruning criteria in a real application of Chinese text input in terms of character error	COMPARE	5	5	P02-1023.4	8	8	P02-1023.5	USAGE	17	18	P02-1023.6	24	26	P02-1023.7
are stated declaratively using a unification-based grammar that is used by a multidimensional chart parser to compose inputs . This an alternative approach in which multimodal parsing and understanding are achieved using a weighted finite-state device which takes speech and gesture	USAGE	5	6	C00-1054.4	12	14	C00-1054.5	USAGE	33	35	C00-1054.8	25	28	C00-1054.7
paper proposes to use a convolution kernel over parse trees to model syntactic structure information for relation extraction . Our study reveals that the syntactic structure features embedded in a parse tree are very effective for relation	MODEL-FEATURE	5	6	N06-1037.1	12	14	N06-1037.3	PART_WHOLE	24	26	N06-1037.5	30	31	N06-1037.6
describes a particular approach to parsing that utilizes recent advances in unification-based parsing and in classification-based knowledge representation . As unification-based grammatical frameworks are extended to handle richer descriptions of linguistic information , they begin to share many of the properties that have been developed in KL-ONE-like knowledge representation systems . This commonality suggests that some of the classification-based representation techniques can be applied to unification-based linguistic descriptions . This merging supports the . The use of a KL-ONE style representation for parsing and semantic interpretation was first 2 ] , in which parsing is characterized as an inference process called incremental description refinement .	USAGE	11	12	H90-1011.2	5	5	H90-1011.1	COMPARE	20	22	H90-1011.4	46	49	H90-1011.6	USAGE	58	60	H90-1011.7	65	67	H90-1011.8	USAGE	78	80	H90-1011.11	82	82	H90-1011.12	USAGE	101	103	H90-1011.16	93	93	H90-1011.15
explain complex phenomena , an explanation system must be able to select information from a formal representation of domain knowledge , organize the selected information seven-year effort to empirically study explanation generation from semantically rich , large-scale knowledge bases . In particular , it describes a robust explanation system that constructs multisentential and multi-paragraph explanations from the a large-scale knowledge base in the domain of botanical	USAGE	18	19	J97-1004.2	5	6	J97-1004.1	USAGE	33	38	J97-1004.7	30	31	J97-1004.6	USAGE	58	60	J97-1004.10	46	48	J97-1004.8
or word sense , a topic signature is a set of words that tend to co-occur with it . Topic signatures can be useful in a number of Natural Language Processing ( NLP ) applications , such as Word Sense the different way in which word senses are lexicalised in English and Chinese , and also exploits the large amount of Chinese text available in corpora and on the Web . We evaluated the topic signatures on a WSD task , where we trained a	PART_WHOLE	11	11	P04-2005.5	5	6	P04-2005.4	USAGE	19	20	P04-2005.6	28	34	P04-2005.7	PART_WHOLE	45	46	P04-2005.10	50	50	P04-2005.11	PART_WHOLE	61	62	P04-2005.13	65	65	P04-2005.14	USAGE	74	75	P04-2005.15	78	79	P04-2005.16
This paper presents a novel ensemble learning approach to resolving German pronouns . Boosting , the method Furthermore , we present a standalone system that resolves pronouns in unannotated text by using a fully automatic performs well within a limited textual domain , further research is needed to make it effective for open-domain question answering and text summarisation .	USAGE	5	7	P04-2010.1	10	11	P04-2010.2	USAGE	22	23	P04-2010.7	28	29	P04-2010.9	COMPARE	40	41	P04-2010.12	52	54	P04-2010.13
Approach This paper presents a machine learning approach to bare slice disambiguation in dialogue . We extract a set of heuristic principles from a corpus-based sample and formulate them as probabilistic Horn clauses . We then use the to create a set of domain independent features to annotate an input dataset , and run two different algorithms : SLIPPER , a rule-based learning algorithm , and TiMBL , a memory-based system . Both learners perform well The results show that the features in terms of which we formulate our heuristic principles have significant predictive power , and that rules that closely resemble our Horn clauses can be learnt automatically from	USAGE	5	7	C04-1035.1	9	11	C04-1035.2	MODEL-FEATURE	30	32	C04-1035.6	20	21	C04-1035.4	MODEL-FEATURE	43	45	C04-1035.8	49	50	C04-1035.9	COMPARE	61	63	C04-1035.11	69	70	C04-1035.12	MODEL-FEATURE	81	81	C04-1035.14	89	90	C04-1035.15	COMPARE	98	98	C04-1035.16	103	104	C04-1035.17
. The new criterion – meaning-entailing substitutability – fits the needs of semantic-oriented NLP applications and can be evaluated directly agreement . Motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word . Finally , a novel feature weighting and selection function is presented , which yields superior feature vectors and better word similarity performance	USAGE	5	6	C04-1036.3	12	14	C04-1036.4	MODEL-FEATURE	25	26	C04-1036.6	33	36	C04-1036.7	RESULT	47	51	C04-1036.10	58	59	C04-1036.11
this paper , we identify features of electronic discussions that influence the clustering process influences . We tested the clustering and filtering processes on electronic newsgroup discussions , and evaluated their performance by means of two experiments : coarse-level clustering simple information retrieval .	MODEL-FEATURE	5	5	C04-1068.4	7	8	C04-1068.5	USAGE	19	22	C04-1068.9	24	26	C04-1068.10	RESULT	38	39	C04-1068.12	31	31	C04-1068.11
new HMM tagger that exploits context on both sides of a word to be tagged , and lexicons . Observing that the quality of the lexicon greatly impacts the accuracy that can be achieved by we present a method of HMM training that improves accuracy when training of lexical probabilities	MODEL-FEATURE	5	5	C04-1080.1	11	11	C04-1080.2	RESULT	22	22	C04-1080.7	29	29	C04-1080.9	RESULT	40	41	C04-1080.11	44	44	C04-1080.12
Grouping Past work of generating referring expressions mainly utilized attributes of objects and binary relations between objects . However , such an utilizing the perceptual groups of objects and n-ary relations among them . The key	USAGE	5	6	C04-1096.1	11	11	C04-1096.2	MODEL-FEATURE	13	14	C04-1096.3	16	16	C04-1096.4	MODEL-FEATURE	29	30	C04-1096.7	27	27	C04-1096.6
Orthographical Mapping For Machine Transliteration Machine transliteration/back-transliteration plays an important role in many multilingual speech and language applications . In this paper , a novel framework for machine transliteration/backtransliteration that allows us to carry out direct orthographical mapping ( DOM ) between two different languages is transliteration model , also called n-gram transliteration model ( n-gram TM ) , is further proposed to model the transliteration process . We evaluate the proposed methods through several transliteration/backtransliteration experiments for English/Chinese and English/Japanese language pairs . Our study reveals that	PART_WHOLE	5	6	C04-1103.1	13	17	C04-1103.2	USAGE	27	28	C04-1103.3	35	40	C04-1103.4	MODEL-FEATURE	51	57	C04-1103.7	65	66	C04-1103.8	USAGE	75	76	C04-1103.9	78	82	C04-1103.10
paper , we present a corpus-based supervised word sense disambiguation ( WSD ) system for Dutch which combines statistical classification ( . Instead of building individual classifiers per ambiguous wordform , we introduce a lemma-based approach . The advantage of this is that it clusters all inflected forms of an ambiguous word in one classifier , therefore augmenting the training material available to the algorithm . Testing the lemma-based model on the Dutch Senseval-2 test data , we achieve a significant	USAGE	5	13	C04-1112.1	15	15	C04-1112.2	COMPARE	26	26	C04-1112.6	34	35	C04-1112.8	MODEL-FEATURE	46	47	C04-1112.9	50	51	C04-1112.10	USAGE	59	60	C04-1112.12	64	64	C04-1112.13	USAGE	68	69	C04-1112.14	72	75	C04-1112.15
Stylistic Variations We present a text mining method for finding synonymous expressions based on the distributional hypothesis in a set of coherent new methodology to improve the accuracy of a term aggregation system using each author 's text as a coherent corpus . Our approach is based person tends to use one expression for one meaning . According to our assumption , most of the words with similar context features in each author 's corpus Our proposed method improves the accuracy of our term aggregation system , showing that our approach	USAGE	15	16	C04-1116.3	5	7	C04-1116.1	RESULT	30	32	C04-1116.6	27	27	C04-1116.5	USAGE	37	37	C04-1116.7	41	41	C04-1116.8	MODEL-FEATURE	55	55	C04-1116.10	52	52	C04-1116.9	MODEL-FEATURE	67	69	C04-1116.12	65	65	C04-1116.11	RESULT	83	85	C04-1116.16	80	80	C04-1116.15
Pairs In Email Conversations While sentence extraction as an approach to summarization has been shown to work in documents of certain genres , because of the conversational nature of email communication where utterances are made in relation to may not capture the necessary segments of dialogue that would make a summary work on the detection of question-answer pairs in an email conversation for the task of email . We show that various features based on the structure of email-threads can be used to improve upon lexical similarity of discourse segments for question-answer	USAGE	5	6	C04-1128.1	11	11	C04-1128.2	MODEL-FEATURE	21	21	C04-1128.4	18	18	C04-1128.3	PART_WHOLE	29	30	C04-1128.5	32	32	C04-1128.6	PART_WHOLE	43	43	C04-1128.8	45	45	C04-1128.9	PART_WHOLE	60	61	C04-1128.12	56	57	C04-1128.11	USAGE	72	72	C04-1128.14	85	86	C04-1128.15
algorithm to efficiently compute the co-occurrence distribution between pairs of terms , an independence model , use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models , in this paper we models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance	MODEL-FEATURE	5	6	C04-1147.3	10	10	C04-1147.4	MODEL-FEATURE	21	21	C04-1147.8	23	23	C04-1147.9	USAGE	26	27	C04-1147.10	30	31	C04-1147.11	MODEL-FEATURE	42	43	C04-1147.13	48	48	C04-1147.14
paper presents a method for word sense disambiguation based on parallel corpora . The method exploits recent advances in word alignment and word clustering based on automatic extraction of translation equivalents and being used to check and spot alignment errors in multilingually aligned wordnets as BalkaNet and EuroWordNet .	USAGE	10	11	C04-1192.2	5	7	C04-1192.1	USAGE	26	27	C04-1192.5	22	23	C04-1192.4	PART_WHOLE	38	39	C04-1192.14	41	43	C04-1192.15
Statistical Machine Translation We present Minimum Bayes-Risk ( MBR ) decoding for statistical machine translation . This statistical approach aims loss of translation errors under loss functions that measure translation performance . We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings , word-to-word alignments from an MT system , and syntactic structure from parse-trees of source and target language sentences . We report the performance of the MBR decoders on a Chinese-to-English translation task . Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions .	USAGE	5	10	N04-1022.1	12	14	N04-1022.2	MODEL-FEATURE	25	26	N04-1022.5	29	30	N04-1022.6	MODEL-FEATURE	37	38	N04-1022.7	44	45	N04-1022.8	PART_WHOLE	54	55	N04-1022.11	50	51	N04-1022.10	MODEL-FEATURE	61	61	N04-1022.13	63	67	N04-1022.14	RESULT	72	72	N04-1022.15	75	76	N04-1022.16	USAGE	87	88	N04-1022.18	94	96	N04-1022.19
Confidence Estimation For Information Extraction Information extraction techniques automatically create structured databases from unstructured data sources , desirable to accurately estimate the confidence the system has in the correctness of each extracted field . The information extraction system we evaluate is based on a linear-chain conditional random field ( CRF ) , a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary , overlapping features of the input in a Markov model . We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records ,	RESULT	5	7	N04-4028.1	10	11	N04-4028.2	MODEL-FEATURE	22	22	N04-4028.6	31	32	N04-4028.7	USAGE	44	50	N04-4028.9	35	37	N04-4028.8	USAGE	53	54	N04-4028.10	60	62	N04-4028.11	MODEL-FEATURE	78	79	N04-4028.14	72	72	N04-4028.12	MODEL-FEATURE	88	88	N04-4028.15	91	92	N04-4028.16
It then presents an implemented graphic interpretation system that takes into account a variety of communicative signals , and an evaluation study	USAGE	15	16	P05-1028.4	5	7	P05-1028.3
We present a framework for word alignment based on log-linear models . All knowledge sources are treated as feature functions , which depend on the and possible additional variables . Log-linear models allow statistical alignment models to be easily extended by , POS correspondence , and bilingual dictionary coverage as features . Our experiments show that log-linear models significantly outperform IBM translation models .	USAGE	9	10	P05-1057.2	5	6	P05-1057.1	USAGE	13	14	P05-1057.3	18	19	P05-1057.4	USAGE	30	31	P05-1057.7	33	35	P05-1057.8	USAGE	46	48	P05-1057.12	50	50	P05-1057.13	COMPARE	56	57	P05-1057.14	60	62	P05-1057.15
results of automatically inducing a Combinatory Categorial Grammar ( CCG ) lexicon from a Turkish dependency treebank . The fact that Turkish is an agglutinating free word order language presents a challenge for language CCG principles , from a treebank which is an order of magnitude smaller than Penn WSJ .	USAGE	14	16	P05-2013.2	5	11	P05-2013.1	MODEL-FEATURE	24	28	P05-2013.4	21	21	P05-2013.3	COMPARE	39	39	P05-2013.8	48	49	P05-2013.9
Parser of Chinese In the Chinese language , a verb may have its dependents on on both sides . The ambiguity resolution of right-side dependencies is essential for dependency parsing of sentences with two or more verbs . Previous works on shift-reduce parsers may not guarantee the connectivity of a dependency tree due to their weakness at . This paper proposes a two-phase shift-reduce dependency parser based on SVM learning . The left-side dependents and our proposed method outperforms previous shift-reduce dependency parsers for the Chine language , showing improvement of dependency	PART_WHOLE	9	9	I05-2044.2	5	6	I05-2044.1	PART_WHOLE	20	21	I05-2044.4	28	29	I05-2044.6	PART_WHOLE	36	36	I05-2044.8	31	31	I05-2044.7	MODEL-FEATURE	47	47	I05-2044.10	50	51	I05-2044.11	USAGE	68	69	I05-2044.14	62	65	I05-2044.13	USAGE	80	82	I05-2044.18	85	86	I05-2044.19
present an operable definition of focus which is argued to be of a cognito-pragmatic nature and explore how it is determined in discourse in a formalized manner . prospect of the integration of focus via FDA as a discourse-level construct into speech synthesis systems , in particular , concept-to-speech	PART_WHOLE	5	5	E99-1038.1	22	22	E99-1038.2	USAGE	33	33	E99-1038.9	41	43	E99-1038.12
Context-Free Chart Parsing Currently several grammatical formalisms converge towards being declarative and towards utilizing context-free phrase-structure grammar as a backbone , e.g a practical comparison of fundamental rule-invocation strategies within context-free chart parsing .	USAGE	14	16	E87-1037.2	5	6	E87-1037.1	PART_WHOLE	27	28	E87-1037.11	30	32	E87-1037.12
I will argue for a model of grammatical processing that is based on uniform processing and knowledge sources . The this model is to view parsing and generation as two strongly interleaved tasks	USAGE	13	14	E91-1043.2	5	8	E91-1043.1	COMPARE	25	25	E91-1043.5	27	27	E91-1043.6
is faced with when decomposing words into their constituent parts is ambiguity : the generation of multiple analyses for one input word , many of which are deal with ambiguity , the MORphological PArser MORPA is provided with a probabilistic context-free grammar ( PCFG ) , i.e . it combines a `` conventional '' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of MORPA is a fully implemented parser developed for use in a text-to-speech conversion system .	PART_WHOLE	8	9	E93-1023.2	5	5	E93-1023.1	MODEL-FEATURE	17	17	E93-1023.5	20	21	E93-1023.6	PART_WHOLE	39	44	E93-1023.9	32	34	E93-1023.8	USAGE	64	66	E93-1023.12	51	56	E93-1023.10	USAGE	77	77	E93-1023.18	83	85	E93-1023.19
and OOV identification . The output can be customized to meet different segmentation standards through the application of an list of transformation . The system participated in all the tracks of the segmentation bakeoff -- PK-open , PK-closed , AS-open , AS-closed , HK-open , HK-closed , MSR-open and MSR- closed -- and achieved the state-of-the-art performance in MSR-open , MSR-close and	MODEL-FEATURE	12	13	I05-3022.5	5	5	I05-3022.4	RESULT	24	24	I05-3022.6	55	56	I05-3022.16
Component In this paper a morphological component with a limited capability to automatically interpret ( and generate ) derived words is presented . The system , 1991b ] with a feature-based word grammar building on a hierarchical lexicon . Polymorphemic stems not explicitly stored in the lexicon are given a compositional interpretation . That way the system	USAGE	5	6	E93-1043.1	18	19	E93-1043.2	USAGE	36	37	E93-1043.5	30	32	E93-1043.4	MODEL-FEATURE	50	51	E93-1043.8	39	40	E93-1043.6
paper proposes an approach to full parsing suitable for Information Extraction from texts . Sequences of of rules deterministically analyze the text , building unambiguous structures . Initially basic chunks are It was implemented in the IE module of FACILE , a EU project for multilingual text classification and IE .	USAGE	5	6	E99-1014.1	9	10	E99-1014.2	MODEL-FEATURE	24	25	E99-1014.6	21	21	E99-1014.5	PART_WHOLE	36	37	E99-1014.13	39	49	E99-1014.14
. A very simple improved duration model has reduced the error rate by about 10 % in technique . Finally , the recognizer has been modified to use bigram back-off language models . The system was then	RESULT	5	6	H91-1010.3	10	11	H91-1010.4	USAGE	28	31	H91-1010.8	22	22	H91-1010.7
language . There are four language pairs currently supported by GLOSSER : English-Bulgarian , English-Estonian , and lemmatized indexing for an aligned bilingual corpus of word examples .	MODEL-FEATURE	5	6	A97-1020.3	10	10	A97-1020.4	PART_WHOLE	25	26	A97-1020.14	21	23	A97-1020.13
the problem of identifying likely topics of texts by their position in the of topic-bearing sentences based on genre-specific regularities of discourse structure . This method can be	MODEL-FEATURE	5	5	A97-1042.1	7	7	A97-1042.2	MODEL-FEATURE	18	19	A97-1042.7	21	22	A97-1042.8
We make use of a conditional log-linear model , with hidden variables representing the assignment of lexical items to word clusters or word senses . The learns to automatically make these assignments based on a discriminative training criterion . Training and decoding with the model requires summing over an exponential number of hidden-variable assignments : the required summations can be computed efficiently and exactly using dynamic programming . As a case study of ~1.25 % beyond the base parser , and an ~0.25 % improvement beyond Collins ( 2000 ) reranker . Although our experiments are	MODEL-FEATURE	10	11	H05-1064.4	5	7	H05-1064.3	MODEL-FEATURE	19	20	H05-1064.7	16	17	H05-1064.6	USAGE	35	37	H05-1064.10	31	31	H05-1064.9	USAGE	65	66	H05-1064.14	41	41	H05-1064.12	COMPARE	77	78	H05-1064.17	86	90	H05-1064.18
: Data Collection and Annotation Taiwan Child Language Corpus contains scripts transcribed from about 330 hours of recordings of fourteen young children from Southern Min Chinese speaking families in Taiwan . The format of the corpus adopts the Child Language Data Exchange System ( CHILDES ) . The size of the corpus is about 1.6 million words . In this paper , , word segmentation , and part-of-speech annotation of this corpus . Applications of the corpus	PART_WHOLE	10	10	I05-4008.2	5	8	I05-4008.1	MODEL-FEATURE	23	25	I05-4008.4	17	17	I05-4008.3	MODEL-FEATURE	38	45	I05-4008.6	35	35	I05-4008.5	PART_WHOLE	56	56	I05-4008.8	51	51	I05-4008.7	USAGE	67	68	I05-4008.12	71	71	I05-4008.13
Selection in Flexible Parsing Robust natural language interpretation requires strong semantic domain models , fail-soft recovery heuristics , flexible control structures . Although single-strategy parsers have met with a measure of success , a multi-strategy approach is shown to provide a , and ability to bring task-specific domain knowledge ( in addition to general linguistic knowledge ) to bear on both and ungrammatical input . A parsing algorithm is presented that integrates several different parsing strategies , with case-frame instantiation dominating . Each of these parsing strategies exploits different types of knowledge ; and their combination provides , fragmentary input , and ungrammatical structures , as well as less exotic , grammatically correct input . Several specific heuristics for handling ungrammatical input are presented within this multi-strategy framework .	USAGE	10	12	P81-1032.2	5	7	P81-1032.1	COMPARE	23	24	P81-1032.5	34	35	P81-1032.6	COMPARE	46	48	P81-1032.7	53	55	P81-1032.8	USAGE	74	75	P81-1032.11	66	67	P81-1032.10	USAGE	89	91	P81-1032.14	85	86	P81-1032.13	COMPARE	102	103	P81-1032.17	111	113	P81-1032.18	PART_WHOLE	116	117	P81-1032.19	126	127	P81-1032.21
, one can describe the discontinuous constituents of non-configurational languages . These discontinuous constituents can be described by a variant of definite clause grammars , and these grammars can be used in conjunction with a proof procedure to create a parser for non-configurational languages .	PART_WHOLE	5	6	P85-1015.3	8	9	P85-1015.4	MODEL-FEATURE	21	23	P85-1015.6	12	13	P85-1015.5	USAGE	27	27	P85-1015.7	40	43	P85-1015.9
is described for acquiring a context-sensitive , phrase structure grammar which is applied by a best-path , bottom-up , deterministic parser . The grammar was based , this research concludes that CSG is a computationally and conceptually tractable approach to the construction of phrase structure grammar for news story text .	USAGE	5	9	P91-1016.1	15	20	P91-1016.2	USAGE	31	31	P91-1016.6	43	45	P91-1016.7
linguistics literature for selecting the semantically unmarked term out of a pair of antonymous adjectives . Solutions to this problem	PART_WHOLE	5	7	P95-1027.3	13	14	P95-1027.4
black-box method for comparing the lexical coverage of MT systems . The method is based on lists of words from different frequency classes . It is shown how	MODEL-FEATURE	5	6	P97-1015.4	8	9	P97-1015.5	MODEL-FEATURE	21	22	P97-1015.7	18	18	P97-1015.6
describe a method for interpreting abstract flat syntactic representations , LFG f-structures , as underspecified semantic representations , here Underspecified Discourse Representation Structures ( UDRSs ) . The method establishes a formalisms . It provides a model theoretic interpretation and an inferential component which operates directly on underspecified representations for f-structures through the translation images of f-structures as UDRSs .	MODEL-FEATURE	14	25	P97-1052.2	5	11	P97-1052.1	MODEL-FEATURE	36	38	P97-1052.6	50	50	P97-1052.9	MODEL-FEATURE	53	54	P97-1052.10	56	56	P97-1052.11
systematic approach for creating a dialog management system based on a Construct Algebra , a collection of relations and operations on a task representation . These relations and operations are analytical components for building higher level abstractions called dialog motivators . The dialog manager , consisting of a collection of dialog motivators , is entirely built using	USAGE	11	12	P99-1025.2	5	7	P99-1025.1	MODEL-FEATURE	15	19	P99-1025.3	22	23	P99-1025.4	PART_WHOLE	30	31	P99-1025.6	38	39	P99-1025.7	PART_WHOLE	48	51	P99-1025.9	42	43	P99-1025.8
, 1998 ) is a language-independent system for automatic discovery of text in parallel translation on the This paper extends the preliminary STRAND results by adding automatic language identification , scaling up by orders most recent end-product is an automatically acquired parallel corpus comprising 2491 English-French document pairs , approximately 1.5 million words	USAGE	5	6	P99-1068.2	8	11	P99-1068.3	PART_WHOLE	26	28	P99-1068.6	22	22	P99-1068.5	PART_WHOLE	45	47	P99-1068.8	39	42	P99-1068.7
main of this project is computer-assisted acquisition and morpho-syntactic description of verb-noun collocations in Polish . We present methodology and phase . The presented here corpus-based approach permitted us to triple the size the verb-noun collocation dictionary for Polish . In the paper we	USAGE	5	12	L08-1260.2	14	14	L08-1260.3	USAGE	25	26	L08-1260.9	34	38	L08-1260.10
deal with a recently developed large Czech MWE database containing at the moment 160 000 MWEs ( treated as lexical units encyclopedias and dictionaries , public databases of proper names and toponyms , collocations obtained from Czech WordNet , lists of botanical and . We compare the built MWEs database with the corpus data from Czech National Corpus ( use a technique exploiting the Word Sketch Engine , which allows us to work with statistical parameters such as frequency of MWEs as well as with the salience for the whole MWEs . We also discuss exploitation of the database for working out a more adequate tagging and lemmatization . The final to be able to recognize MWEs in corpus text and lemmatize them as complete	PART_WHOLE	15	15	L08-1540.2	5	8	L08-1540.1	PART_WHOLE	28	29	L08-1540.7	26	26	L08-1540.6	PART_WHOLE	33	33	L08-1540.9	36	37	L08-1540.10	COMPARE	48	49	L08-1540.14	52	53	L08-1540.15	MODEL-FEATURE	74	75	L08-1540.21	64	66	L08-1540.20	MODEL-FEATURE	86	86	L08-1540.23	90	90	L08-1540.24	USAGE	98	98	L08-1540.25	105	105	L08-1540.26	PART_WHOLE	116	116	L08-1540.28	118	119	L08-1540.29
set of experiments to explore statistical techniques for ranking and selecting the best translations in a graph of translation hypotheses . In a previous paper we have described how the hypotheses graph is generated through shallow mapping and permutation rules . We have given examples of its nodes consisting of vectors representing morpho-syntactic properties of words and phrases . types of text and their log-linear combination is then used to retrieve the best M translation paths in the graph . We language modelling toolkits , the CMU and the SRI toolkit and arrive at three results : 1 ) word-lemma based feature function models produce better results than token-based models , 2 ) adding a PoS-tag feature function to the word-lemma model improves the output and 3 ) weights for lexical translations are suitable if the training material is similar to the texts to be translated .	USAGE	5	6	L08-1110.1	13	13	L08-1110.2	PART_WHOLE	18	19	L08-1110.4	16	16	L08-1110.3	USAGE	35	36	L08-1110.6	30	31	L08-1110.5	PART_WHOLE	50	53	L08-1110.9	47	47	L08-1110.8	USAGE	64	65	L08-1110.16	74	75	L08-1110.17	COMPARE	86	86	L08-1110.20	89	90	L08-1110.21	COMPARE	99	103	L08-1110.22	108	109	L08-1110.23	PART_WHOLE	115	117	L08-1110.24	120	121	L08-1110.25	MODEL-FEATURE	128	128	L08-1110.26	130	131	L08-1110.27	COMPARE	136	137	L08-1110.28	142	142	L08-1110.29
term candidates by looking for internal and contextual information associated with domain specific terms . The algorithms always face the dilemma that fewer features are not enough to distinguish terms from non-terms whereas more features presents a novel approach for term extraction based on delimiters which are much more stable	MODEL-FEATURE	5	8	L08-1154.2	11	13	L08-1154.3	MODEL-FEATURE	23	23	L08-1154.4	29	29	L08-1154.5	USAGE	44	44	L08-1154.10	40	41	L08-1154.9
corpus annotation scenario capturing the discourse relations in Czech . We primarily focus on the description of the syntactically motivated relations in discourse , basing our findings on is to revisit the present-day syntactico-semantic ( tectogrammatical ) annotation in the Prague Dependency Treebank , extend it for the to design a new , discourse level of annotation . In this paper , , comparing the possibilities the Praguian dependency-based approach offers with the Penn discourse annotation based primarily on the analysis	PART_WHOLE	5	6	L08-1050.2	8	8	L08-1050.3	PART_WHOLE	18	20	L08-1050.4	22	22	L08-1050.5	PART_WHOLE	33	37	L08-1050.8	40	42	L08-1050.9	MODEL-FEATURE	53	54	L08-1050.11	56	56	L08-1050.12	COMPARE	67	69	L08-1050.13	73	75	L08-1050.14
, we reported experiments of unsupervised automatic acquisition of Italian and English verb subcategorization frames ( SCFs ) from general and domain corpora . The proposed technique operates not relying on any previous lexico-syntactic knowledge about SCFs . Although preliminary , reported . The issue of whether verbs sharing similar SCFs distributions happen to share similar semantic was also explored by clustering verbs that share frames with the same distribution using	USAGE	19	22	L08-1097.3	5	7	L08-1097.1	MODEL-FEATURE	33	34	L08-1097.6	36	36	L08-1097.7	MODEL-FEATURE	50	51	L08-1097.10	47	47	L08-1097.9	MODEL-FEATURE	65	65	L08-1097.13	62	62	L08-1097.12
American Sign Language Animation The translation of English text into American Sign Language ( ASL ) animation tests the limits of traditional MT architectural designs . A new semantic representation is proposed that uses virtual reality 3D scene modeling software to produce spatially complex ASL The model acts as an interlingua within a new multi-pathway MT architecture design that also incorporates transfer and	USAGE	21	24	N04-2005.4	5	5	N04-2005.1	USAGE	28	29	N04-2005.5	34	39	N04-2005.6	PART_WHOLE	50	50	N04-2005.9	54	57	N04-2005.10
research into the design of cognitively well-motivated interfaces relying primarily on the display of graphical information , we have observed that working towards the integration of natural language generation to augment the interaction	USAGE	12	15	A92-1010.2	5	7	A92-1010.1	USAGE	26	28	A92-1010.6	32	32	A92-1010.7
experiments were carried out with vocabularies containing up to 20k words . The recognizer makes use of continuous density HMM with Gaussian mixture for acoustic modeling and n-gram statistics estimated on the newspaper texts for language modeling . The recognizer uses a language models . A second forward pass , which makes use of a word graph generated with the bigram , a trigram language model . Acoustic modeling uses cepstrum-based features , context-dependent phone models (	PART_WHOLE	10	10	H94-1064.8	5	5	H94-1064.7	MODEL-FEATURE	21	22	H94-1064.10	17	19	H94-1064.9	USAGE	27	28	H94-1064.12	35	36	H94-1064.14	USAGE	55	56	H94-1064.18	47	48	H94-1064.17	USAGE	70	71	H94-1064.22	67	68	H94-1064.21
categorizing unknown words . The system is based on a multi-component architecture where each component is responsible of this paper is the components that identify names and spelling errors . Each component uses a decision tree architecture to combine multiple types of evidence about the unknown word . The system is evaluated using data from live closed captions - a genre replete with a wide variety of unknown words .	USAGE	10	11	A00-1024.3	5	5	A00-1024.2	USAGE	22	22	A00-1024.6	25	25	A00-1024.7	USAGE	34	36	A00-1024.10	31	31	A00-1024.9	MODEL-FEATURE	42	42	A00-1024.11	45	46	A00-1024.12	PART_WHOLE	67	68	A00-1024.15	55	57	A00-1024.14
System Used For MET Japanese Recognition of proper nouns in Japanese text has been studied as a the more general problem of morphological analysis in Japanese text processing ( [ 1 ] [ the given task as a morphological analysis problem in Japanese . Our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i.e . Named Entity ( NE ) items in the Japanese text . it uses several kinds of dictionaries to segment and tag Japanese character strings . Second , based on stage , a set of rules is applied to the segmented strings in order to identify NE	USAGE	5	8	X96-1059.1	10	11	X96-1059.2	PART_WHOLE	22	23	X96-1059.3	25	27	X96-1059.4	USAGE	38	40	X96-1059.7	42	42	X96-1059.8	USAGE	45	46	X96-1059.9	55	74	X96-1059.10	USAGE	85	85	X96-1059.16	90	92	X96-1059.17	USAGE	103	103	X96-1059.19	108	109	X96-1059.20
The Web We present a practically unsupervised learning method to produce single-snippet answers to definition questions in question engines . The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples , which are then used	USAGE	5	8	H05-1041.1	11	12	H05-1041.2	USAGE	23	26	H05-1041.6	35	39	H05-1041.7
work in the context of terms extracted from corpora : given a set of terms , obtained from an existing resource or extracted from a corpus , identifying hierarchical ( or other types of ) relations between these terms . The present paper focusses on terminology structuring by lexical methods , which match terms on the basis on their content words , taking morphological variants into a 'flat ' list of terms obtained from an originally hierarchically-structured terminology : the French version of thesaurus . We compare the lexically-induced relations with the original MeSH relations : after a quantitative evaluation human analysis ofthe 'new ' relations not present in the MeSH . This analysis shows , some specific structuring choices and naming conventions made by the MeSH designers , and emphasizes ontological	PART_WHOLE	5	5	W02-1403.2	8	8	W02-1403.3	PART_WHOLE	14	14	W02-1403.4	25	25	W02-1403.5	MODEL-FEATURE	28	35	W02-1403.6	38	38	W02-1403.7	USAGE	48	49	W02-1403.9	45	46	W02-1403.8	PART_WHOLE	59	60	W02-1403.11	53	53	W02-1403.10	PART_WHOLE	71	71	W02-1403.13	76	77	W02-1403.14	COMPARE	88	89	W02-1403.16	93	94	W02-1403.17	PART_WHOLE	105	105	W02-1403.19	110	110	W02-1403.20	MODEL-FEATURE	121	122	W02-1403.22	126	126	W02-1403.23
aligning terms and thus extracting translations from a small , domain-specific corpus consisting of parallel English and are suggested by analysing the frequency profiles of parallel concordances . The method overcomes the limitations of conventional statistical methods which require large corpora to be effective , and lexical approaches which depend on existing bilingual dictionaries . Pilot testing on a parallel corpus of about 113K Chinese words and 120K English words gives errors , and acquiring a translation lexicon for legal terminology by filtering out general terms	PART_WHOLE	5	5	W02-1404.3	8	11	W02-1404.4	MODEL-FEATURE	22	23	W02-1404.8	25	26	W02-1404.9	USAGE	39	40	W02-1404.11	34	36	W02-1404.10	USAGE	52	53	W02-1404.13	46	47	W02-1404.12	PART_WHOLE	64	65	W02-1404.15	59	60	W02-1404.14	PART_WHOLE	79	80	W02-1404.21	76	77	W02-1404.20
And Improve MT A Posteriori Coedition of a natural language text and its representation in some users interact directly with the text in their language ( L0 ) , and indirectly with the and trying to align the tree and the selected trajectory with as few crossing liaisons as possible . A central	USAGE	5	5	W02-1602.1	8	10	W02-1602.2	MODEL-FEATURE	24	27	W02-1602.10	21	21	W02-1602.9	MODEL-FEATURE	46	47	W02-1602.35	38	38	W02-1602.33
unsupervised learning method using the Expectation-Maximization ( EM ) algorithm proposed by Nigam et al . for text classification problems in order to apply it The improved method stops the EM algorithm at the optimum iteration number . To estimate that number experiments , we solved 50 noun WSD problems in the Japanese Dictionary Task in SENSEVAL2 . The score of our	USAGE	5	9	W03-0406.2	17	19	W03-0406.3	MODEL-FEATURE	34	36	W03-0406.6	30	31	W03-0406.5	PART_WHOLE	47	49	W03-0406.7	52	56	W03-0406.8
paper we discuss a proposed user knowledge modeling architecture for the ICICLE system , a language tutoring application for deaf learners of written English . The model will represent production . We motivate our model design by citing relevant research on second language and cognitive skill acquisition , and briefly discuss preliminary	PART_WHOLE	5	8	W99-0408.1	11	12	W99-0408.2	USAGE	15	17	W99-0408.3	22	23	W99-0408.4	USAGE	41	46	W99-0408.9	34	35	W99-0408.8
paper describes novel and practical Japanese parsers that uses decision trees . First , we construct a single decision tree to estimate modification probabilities ; how one phrase tends boosting algorithm in which several decision trees are constructed and then combined for probability estimation . The two constructed parsers	USAGE	9	10	P98-1083.2	5	6	P98-1083.1	MODEL-FEATURE	18	19	P98-1083.3	22	23	P98-1083.4	USAGE	34	35	P98-1083.7	42	43	P98-1083.8
Information Retrieval Automatic estimation of word significance oriented for speech-based Information Retrieval ( IR ) is addressed . Since the significance of words differs in IR , automatic ) , which gives a weight on errors from the viewpoint of IR , instead of word error rate ( WER ) , which treats all words uniformly . A decoding strategy that minimizes WWER based on a Minimum Bayes-Risk framework has been shown , and reduction of errors on both ASR and IR has been reported . In paper , we propose an automatic estimation method for word significance ( weights ) based on its influence on	USAGE	5	6	I08-1027.2	9	14	I08-1027.3	MODEL-FEATURE	20	20	I08-1027.4	22	22	I08-1027.5	COMPARE	33	33	I08-1027.9	44	49	I08-1027.11	USAGE	66	68	I08-1027.15	58	59	I08-1027.13	COMPARE	79	79	I08-1027.16	81	81	I08-1027.17	USAGE	92	94	I08-1027.18	96	100	I08-1027.19
Knowledge This study presents a method to automatically acquire paraphrases using bilingual corpora , which utilizes the bilingual dependency relations obtained by projecting a monolingual dependency parse onto the other language sentence based on statistical alignment techniques . Since the paraphrasing method capable of clearly disambiguating the sense of an original phrase using the bilingual context of be possible to obtain interchangeable paraphrases under a given context . Also , we provide an advanced method to acquire generalized translation knowledge using the extracted paraphrases . We applied the method to acquire the generalized translation knowledge for Korean-English translation . Through experiments with parallel corpora of a Korean and English language pairs , we show that our paraphrasing method effectively extracts paraphrases with high precision , 94.3 % and 84.6 and English , and the translation knowledge extracted from the bilingual corpora could be generalized successfully using the paraphrases with the 12.5 % compression ratio .	USAGE	11	12	I08-1043.2	5	9	I08-1043.1	USAGE	34	36	I08-1043.5	17	19	I08-1043.3	MODEL-FEATURE	47	47	I08-1043.7	51	51	I08-1043.8	MODEL-FEATURE	66	66	I08-1043.12	62	62	I08-1043.11	USAGE	83	83	I08-1043.14	77	79	I08-1043.13	MODEL-FEATURE	92	94	I08-1043.15	96	97	I08-1043.16	PART_WHOLE	106	110	I08-1043.18	102	103	I08-1043.17	RESULT	116	117	I08-1043.19	123	123	I08-1043.21	PART_WHOLE	134	135	I08-1043.24	139	140	I08-1043.25	MODEL-FEATURE	152	153	I08-1043.27	147	147	I08-1043.26
Segmentation This paper describes a computational model of word segmentation and presents simulation results on the capacity and limitations of statistical learning mechanisms that have recently gained prominence in cognitive psychology and linguistics .	MODEL-FEATURE	5	6	W04-1307.1	8	9	W04-1307.2	USAGE	20	22	W04-1307.4	29	30	W04-1307.5
a transfer dictionary automatically . Dictionary construction , one of the most difficult tasks in developing a machine translation system , is expensive . To investigate how we build a dictionary using existing linguistic resources . Our algorithm can be applied to any language pairs , but for the present we focus on building a Korean-to-Japanese dictionary using English as a pivot . We attempt three ways corroborate the effect of the directionality of dictionaries . First , we introduce `` one-time look up '' method using a Korean-to-English and a Japanese-to-English dictionary . Second , we show	PART_WHOLE	5	6	W04-2204.2	17	19	W04-2204.3	USAGE	33	34	W04-2204.5	30	30	W04-2204.4	USAGE	37	37	W04-2204.6	43	44	W04-2204.7	USAGE	61	61	W04-2204.10	55	56	W04-2204.8	MODEL-FEATURE	72	72	W04-2204.12	74	74	W04-2204.13	USAGE	88	92	W04-2204.15	80	85	W04-2204.14
to annotating a level of discourse structure that is based on identifying discourse connectives and their arguments . The	USAGE	12	13	W04-2703.4	5	6	W04-2703.3
named IntEx , to identify gene and protein interactions in biomedical text . Our approach is based on first splitting complex sentences into simple clausal structures made up of syntactic roles . Then , tagging biological entities with the help of biomedical and linguistic ontologies . Finally , extracting complete linguistically significant combinations . Our extraction system handles complex sentences and extracts multiple and nested interactions specified in a sentence . Experimental evaluations with two extraction systems indicate that the IntEx system achieves better performance without the labor intensive pattern	PART_WHOLE	5	8	W05-1308.3	10	11	W05-1308.4	PART_WHOLE	23	25	W05-1308.6	20	21	W05-1308.5	MODEL-FEATURE	41	44	W05-1308.9	35	36	W05-1308.8	USAGE	55	56	W05-1308.12	58	59	W05-1308.13	PART_WHOLE	62	65	W05-1308.14	69	69	W05-1308.15	RESULT	80	81	W05-1308.17	84	84	W05-1308.18
a framework to derive the distance between concepts from distributional measures of word co-occurrences . We use the categories in a published thesaurus as coarse-grained concepts , allowing all possible distance values to be stored in a concept-concept matrix roughly.01 % the size of show that the newly proposed concept-distance measures outperform traditional distributional word-distance measures in the tasks of ( 1 ) ranking word pairs in order of semantic distance , and ( 2 ) task , of all the WordNet-based measures , only that proposed by Jiang and Conrath outperforms the best distributional concept-distance measures .	MODEL-FEATURE	5	5	W06-1605.1	7	7	W06-1605.2	PART_WHOLE	18	18	W06-1605.4	22	22	W06-1605.5	PART_WHOLE	24	25	W06-1605.6	37	38	W06-1605.8	COMPARE	49	50	W06-1605.9	52	55	W06-1605.10	MODEL-FEATURE	69	70	W06-1605.12	64	65	W06-1605.11	COMPARE	81	82	W06-1605.14	94	96	W06-1605.15
of the the use of labeled directed graph to represent various types of linguistic structures , and illustrate how this allows one to view NLP tasks as graph transformations . We present a general applications of the method : identification of non-local depenencies ( using Penn Treebank data ) and semantic role labeling ( using Proposition Bank data ) .	MODEL-FEATURE	5	7	W07-0208.1	13	14	W07-0208.2	MODEL-FEATURE	27	28	W07-0208.4	24	25	W07-0208.3	MODEL-FEATURE	39	42	W07-0208.7	45	47	W07-0208.8	MODEL-FEATURE	50	52	W07-0208.9	55	57	W07-0208.10
is the task of ranking blog posts with respect to their relevance for a given topic . To improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process . describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models . show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is	MODEL-FEATURE	11	11	P08-1105.3	5	6	P08-1105.2	USAGE	25	27	P08-1105.6	19	22	P08-1105.5	USAGE	38	38	P08-1105.11	46	47	P08-1105.12	RESULT	58	59	P08-1105.15	62	63	P08-1105.16
ineffective : 1 ) Many words within song lyrics actually contribute little to sentiment address these problems , the sentiment vector space model ( s-VSM ) is proposed to represent song lyric document . The preliminary experiments prove that the s-VSM model outperforms the VSM model in the lyric-based song sentiment	PART_WHOLE	5	5	P08-2034.4	7	8	P08-2034.5	MODEL-FEATURE	19	25	P08-2034.15	30	32	P08-2034.16	COMPARE	40	41	P08-2034.17	44	45	P08-2034.18
often possible to identify the source language of medium-length speeches in the EUROPARL corpus on the basis of frequency counts of word n-grams ( 87.2 % -96.7 % accuracy depending on classification method ) . The paper also	MODEL-FEATURE	5	6	C08-1118.1	12	13	C08-1118.2	MODEL-FEATURE	18	19	C08-1118.3	21	22	C08-1118.4	RESULT	31	32	C08-1118.6	28	28	C08-1118.5
Segmentation for Statistical Machine Translation Words in Chinese text are not naturally separated by MT ) systems . In MT , the widely used approach is to apply a Chinese word segmenter trained from manually annotated data translation . We propose a Bayesian semi-supervised Chinese word segmentation model which uses both monolingual and bilingual information to derive a segmentation suitable for MT . Experiments show that our	PART_WHOLE	5	5	C08-1128.1	7	8	C08-1128.2	USAGE	29	31	C08-1128.6	19	19	C08-1128.5	USAGE	51	54	C08-1128.12	42	47	C08-1128.11	USAGE	58	58	C08-1128.13	61	61	C08-1128.14
reference translations . Indeed , automatic evaluations need high-quality data that allow the comparison of describes the impact of using different-quality references on evaluation . Surprisingly enough , similar , the limitations of the automatic metrics used within MT are also discussed in this	USAGE	8	9	C08-2010.7	5	6	C08-2010.6	USAGE	20	21	C08-2010.9	23	23	C08-2010.10	USAGE	34	35	C08-2010.11	38	38	C08-2010.12
ngrams . The tool supports queries with an arbitrary number of wildcards . It takes a fraction	MODEL-FEATURE	11	11	C08-3010.4	5	5	C08-3010.3
presents an approach to the unsupervised learning of parts of speech which uses both morphological and syntactic information . While the model is which have been employed for unsupervised learning of POS tags in English , which use only syntactic information , the variety of languages in the world requires that we consider morphology as well . In many languages , morphology provides better clues to a word 's category than word order . We present the computational model for POS learning , and present results for applying it to Bulgarian , a Slavic language with relatively free word order and rich morphology .	USAGE	14	17	W03-2907.3	5	6	W03-2907.1	USAGE	39	40	W03-2907.7	28	29	W03-2907.5	PART_WHOLE	53	53	W03-2907.9	45	45	W03-2907.8	COMPARE	61	61	W03-2907.11	71	72	W03-2907.12	USAGE	77	78	W03-2907.13	80	81	W03-2907.14	MODEL-FEATURE	90	90	W03-2907.15	97	99	W03-2907.17
to the challenge of the CoNLL 2008 shared task that uses a generative history-based latent variable model to predict the most likely derivation of a synchronous dependency parser for both syntactic and semantic dependencies . The submitted model yields 79.1 % macro-average F1 performance , for the joint task dependencies F1 . A larger model trained after the deadline achieves 80.5 % macro-average F1 , 87.6 % syntactic dependencies	USAGE	12	16	W08-2122.2	5	8	W08-2122.1	MODEL-FEATURE	22	22	W08-2122.3	30	33	W08-2122.5	RESULT	37	37	W08-2122.6	41	43	W08-2122.7	RESULT	54	54	W08-2122.10	62	63	W08-2122.11
have grown increasingly complex as architectural modules were added to support language functionalities such as referring expressions , relative placement of these new modules in the overall architecture . Recent work on another which suggest that in a pipelined NLG architecture , the best approach is to strongly tie it to a revision component . Finally , we evaluate	USAGE	5	6	P03-1034.2	11	12	P03-1034.3	PART_WHOLE	23	23	P03-1034.7	27	27	P03-1034.8	PART_WHOLE	52	53	P03-1034.13	38	40	P03-1034.12
With performance above 97 % accuracy for newspaper text , part of speech ( pos ) tagging might be considered a solved have shown that allowing the parser to resolve pos tag ambiguity does not improve performance . However , for grammar formalisms which use more fine-grained grammatical categories , for example tag and infeasible . We describe a multi-tagging approach which maintains a suitable level of lexical category ambiguity for accurate and efficient ccg parsing . We extend this multi-tagging seems high , maintaining some pos tag ambiguity in the language processing pipeline results in more accurate ccg supertagging .	RESULT	10	16	P06-1088.3	5	5	P06-1088.1	USAGE	27	27	P06-1088.4	30	32	P06-1088.5	USAGE	46	48	P06-1088.7	41	42	P06-1088.6	USAGE	59	60	P06-1088.14	74	75	P06-1088.16	RESULT	86	88	P06-1088.21	98	99	P06-1088.23
Marks Both rhetorical structure and punctuation have been helpful in discourse processing . Based on a corpus , this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts : , and Semicolon . The rhetorical patterns of these marks are compared against patterns around cue phrases in general . Results show that these Chinese punctuation marks , though fewer in number than cue phrases , are easy to identify	USAGE	5	5	P06-3008.2	10	11	P06-3008.3	MODEL-FEATURE	22	23	P06-3008.5	26	28	P06-3008.6	COMPARE	39	40	P06-3008.14	47	47	P06-3008.15	COMPARE	58	60	P06-3008.17	67	68	P06-3008.18
, but proceed to develop algorithms which can sometimes alleviate the unpleasant consequences of this intractability .	USAGE	5	5	C90-3007.4	15	15	C90-3007.5
algorithm for selecting an appropriate classifier word for a noun . In Thai language , fluctuation in the choice of classifier for a given concrete noun , both from the point to pick up a corresponding classifier of each noun . Registration of classifier for each noun is limited to the type representation . We propose a corpus-based method ( Biber,1993 ; Nagao,1993 ; Smadja,1993 ) which generates Noun Classifier Associations ( NCA ) to overcome the problems in classifier assignment and semantic construction of noun	MODEL-FEATURE	5	6	C94-1091.1	9	9	C94-1091.2	MODEL-FEATURE	20	20	C94-1091.4	24	25	C94-1091.5	MODEL-FEATURE	36	36	C94-1091.11	39	39	C94-1091.12	MODEL-FEATURE	43	43	C94-1091.13	46	46	C94-1091.14	USAGE	57	58	C94-1091.16	79	80	C94-1091.18
Phrases This paper describes an unsupervised learning method for associative relationships between verb phrases , which is important in aim is to develop an unsupervised learning method that can obtain such an associative relationship , which we call scenario currently working on uses an expectation-maximization ( EM ) based word-clustering algorithm , and we have evaluated the effectiveness of this method using Japanese verb phrases .	USAGE	5	7	C02-1120.1	9	13	C02-1120.2	USAGE	24	26	C02-1120.12	32	33	C02-1120.13	USAGE	44	50	C02-1120.15	62	64	C02-1120.16
address this problem . These models provide principled ways of including additional conditioning variables other than the preceding words , such as morphological or . This paper presents an entirely data-driven model selection procedure based on genetic search , which is shown to outperform both knowledge-based and random selection procedures on two different language modeling tasks ( Arabic and Turkish )	COMPARE	5	5	C04-1022.4	17	18	C04-1022.6	USAGE	36	37	C04-1022.11	29	33	C04-1022.10	USAGE	45	49	C04-1022.12	53	55	C04-1022.13
. Landsbergen 's advocacy of analytical inverses for compositional syntax rules encourages the application of Definite Clause Grammar techniques to the construction of a parser returning Montague analysis trees . A parser MDCC is presented which implements an augmented Friedman - Warren algorithm permitting post referencing * and so as to display the derivational history of corresponding reduced IL formulae . Some familiarity with Montague	MODEL-FEATURE	5	6	E85-1004.1	8	10	E85-1004.2	USAGE	15	18	E85-1004.3	24	24	E85-1004.4	USAGE	38	42	E85-1004.7	31	32	E85-1004.6	MODEL-FEATURE	53	54	E85-1004.10	57	59	E85-1004.11
research in the area of machine translation usually involves the search for and creation of an appropriate formalism . An important issue in the way in which the compositionality of translation is to be defined . , we will introduce the anaphoric component of the Mimo formalism . It makes the definition to strict compositionality . In Mimo , the translation of anaphoric relations is compositional . The anaphoric component is used to define linguistic phenomena such as wh-movement , the	USAGE	17	17	E89-1040.2	5	6	E89-1040.1	MODEL-FEATURE	28	28	E89-1040.3	30	30	E89-1040.4	PART_WHOLE	41	42	E89-1040.5	45	46	E89-1040.6	USAGE	57	57	E89-1040.11	60	60	E89-1040.12	USAGE	68	69	E89-1040.14	74	75	E89-1040.15
Domain-Independent And Domain-Specific Information A domain independent model is proposed for the automated interpretation of nominal compounds in English . This model is meant which are inferred from the morpho-syntactic and semantic characteristics of the nominal constituents . In particular , we Pustejovsky 's principles concerning the predicative information associated with nominals . We argue that it to draw a line between generalizable semantic principles and domain-specific semantic information . We explain this distinction may be applied to the interpretation of compounds in real texts , provided	USAGE	5	7	C96-1062.1	12	13	C96-1062.2	PART_WHOLE	15	16	C96-1062.3	18	18	C96-1062.4	MODEL-FEATURE	29	32	C96-1062.7	35	36	C96-1062.8	MODEL-FEATURE	47	48	C96-1062.9	51	51	C96-1062.10	COMPARE	62	64	C96-1062.11	66	68	C96-1062.12	MODEL-FEATURE	79	79	C96-1062.13	81	81	C96-1062.14
. We present a novel entity-based representation of discourse which is inspired by Centering raw text . We view coherence assessment as a ranking learning problem and show that the proposed Our experiments demonstrate that the induced model achieves significantly higher accuracy than a state-of-the-art coherence model .	MODEL-FEATURE	5	6	P05-1018.2	8	8	P05-1018.3	MODEL-FEATURE	23	25	P05-1018.7	19	20	P05-1018.6	COMPARE	36	37	P05-1018.10	44	46	P05-1018.12
Sentence Boundary Detection In Speech Sentence boundary detection in speech is important for enriching speech recognition output , making it easier work , we have developed hidden Markov model ( HMM ) and maximum entropy ( Maxent ) classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries . news speech ) on both human transcriptions and speech recognition output . In general , our CRF model yields a lower error rate than the HMM and Max-ent models on the NIST sentence boundary	USAGE	5	7	P05-1056.1	14	15	P05-1056.3	USAGE	44	45	P05-1056.5	26	38	P05-1056.4	COMPARE	56	57	P05-1056.10	59	60	P05-1056.11	COMPARE	67	67	P05-1056.12	76	79	P05-1056.13
a good match between the training and test data with respect to topic . This paper demonstrates that and presents preliminary experiments with training data labeled with emoticons , which has the potential	MODEL-FEATURE	12	12	P05-2008.6	5	8	P05-2008.5	MODEL-FEATURE	27	27	P05-2008.8	23	24	P05-2008.7
over the Last Decade Using natural language processing , we carried out a trend survey on Japanese natural language processing studies that have been done over	USAGE	5	7	I05-2043.2	16	20	I05-2043.3
the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful hypothesis under examination is that useful terms tend to be more similar to each other than to other query terms . Preliminary experiments with similarities to confirm the hypothesis . Term similarities could then be used for determining which query terms are useful and best reflect of evidence for tuning the weights of the query terms .	MODEL-FEATURE	5	6	E99-1034.1	8	8	E99-1034.2	USAGE	11	12	E99-1034.3	17	17	E99-1034.4	COMPARE	28	29	E99-1034.5	41	42	E99-1034.6	MODEL-FEATURE	53	54	E99-1034.8	62	63	E99-1034.9	MODEL-FEATURE	74	74	E99-1034.10	77	78	E99-1034.11
of the model formalizing the structure of communicative context in dialogue interaction . The relationships between the	MODEL-FEATURE	5	8	E85-1041.2	10	11	E85-1041.3
results of previous invocations . Memo-functions also facilitate a simple way to construct a very compact representation of the parse forest . For LR ( 0 . Extended CF grammars ( grammars with regular expressions at the right hand side a simple modification of the LR-parser for normal CF grammars .	USAGE	5	5	E91-1012.8	19	20	E91-1012.9	PART_WHOLE	33	34	E91-1012.14	31	31	E91-1012.13	USAGE	45	45	E91-1012.15	48	49	E91-1012.16
Annotations This paper defines a generative probabilistic model of parse trees , which we call PCFG-LA with latent variables . Finegrained CFG rules are automatically induced from a parsed corpus by training a PCFG-LA model using an EM-algorithm . Because exact parsing with a PCFG-LA is NP-hard , several approximations corpus , our automatically trained model gave a performance of 86.6 % ( F1 , sentences < 40 words ) , which is comparable to that of an unlexicalized PCFG parser created using extensive manual feature selection .	MODEL-FEATURE	5	7	P05-1010.1	9	10	P05-1010.2	USAGE	28	29	P05-1010.9	21	22	P05-1010.8	USAGE	37	37	P05-1010.12	31	31	P05-1010.10	USAGE	44	44	P05-1010.14	41	41	P05-1010.13	RESULT	55	55	P05-1010.18	58	58	P05-1010.19	PART_WHOLE	68	68	P05-1010.21	65	65	P05-1010.20	USAGE	84	86	P05-1010.23	78	80	P05-1010.22
syntactic and semantic knowledge in feature-based relation extraction using SVM . Our study illustrates that the base phrase chunking information is very effective for relation extraction and contributes to most of the performance improvement from syntactic aspect while additional . We also demonstrate how semantic information such as WordNet and Name List , can be used in feature-based relation extraction to further improve the performance . Evaluation on the ACE of diverse features enables our system outperform previously best-reported systems on the 24 ACE relation	USAGE	9	9	P05-1053.4	5	7	P05-1053.3	RESULT	17	18	P05-1053.5	32	33	P05-1053.7	RESULT	44	45	P05-1053.13	64	64	P05-1053.17	COMPARE	75	75	P05-1053.21	79	79	P05-1053.22
This paper describes a novel system for acquiring adjectival subcategorization frames ( scfs ) and associated frequency information from English corpus data . The system incorporates a decision-tree classifier for 30 scf types which tests for the presence of grammatical relations ( grs ) in the output of a robust statistical parser powerful pattern-matching language to classify grs into frames hierarchically in a way that The experiments show that the system is able to detect scf types with 70 % precision and 66 % recall rate . A new tool for linguistic annotation of scfs in corpus data is also introduced which can alleviate the process of obtaining training and test data for subcategorization acquisition .	USAGE	5	5	P05-1076.1	7	10	P05-1076.2	MODEL-FEATURE	19	19	P05-1076.4	20	21	P05-1076.5	PART_WHOLE	27	28	P05-1076.7	24	24	P05-1076.6	PART_WHOLE	39	40	P05-1076.9	46	46	P05-1076.11	MODEL-FEATURE	59	59	P05-1076.15	57	57	P05-1076.14	RESULT	70	70	P05-1076.18	78	80	P05-1076.20	USAGE	89	89	P05-1076.22	91	92	P05-1076.23	PART_WHOLE	94	94	P05-1076.24	96	97	P05-1076.25	USAGE	108	111	P05-1076.26	113	114	P05-1076.27
which takes as input a raw text in French and produces as output the which every occurrence of the pronoun il is tagged either with tag [ ANA ] for anaphoric or [ IMP an antecedent , and the expletive occurrences of this pronoun , for which it does for an antecedent . The precision rate for ILIMP is 97,5 % . The analyzed in detail . Other tasks using the method developed for ILIMP are described well as the use of ILIMP in a modular syntactic analysis system .	MODEL-FEATURE	8	8	I05-2013.4	5	6	I05-2013.3	MODEL-FEATURE	26	28	I05-2013.7	19	20	I05-2013.6	MODEL-FEATURE	39	40	I05-2013.15	43	43	I05-2013.16	RESULT	57	57	I05-2013.18	54	55	I05-2013.17	USAGE	71	71	I05-2013.21	68	68	I05-2013.20	USAGE	82	82	I05-2013.23	86	88	I05-2013.24
GENERATING TEXT FROM SYSTEMIC GRAMMARS Systemic grammar has been used for AI text generation work in the past , to systemic text generation where AI problem solving techniques are applied directly to an unadulterated systemic grammar . This approach is made result is simple , efficient text generation firmly based in a linguistic theory .	USAGE	5	6	E85-1037.1	11	13	E85-1037.2	USAGE	24	27	E85-1037.5	34	35	E85-1037.6	USAGE	52	53	E85-1037.11	46	47	E85-1037.10
Systems This paper presents a critical discussion of the various approaches that have been used in the evaluation of Natural Language systems . We conclude that previous , e.g . solving a task requiring data retrieval . This raises questions about paper , we report a laboratory study using the Wizard of Oz technique to identify NL requirements for reference and reference to the structure of the information source . We discuss how these	TOPIC	5	6	E89-1016.1	17	21	E89-1016.3	USAGE	34	35	E89-1016.7	32	32	E89-1016.6	USAGE	50	53	E89-1016.10	46	47	E89-1016.9	MODEL-FEATURE	64	64	E89-1016.19	67	68	E89-1016.20
LFG Semantics Via Constraints Semantic theories of natural language associate meanings with utterances by providing meanings for lexical items and rules for determining the meaning of larger units given the meanings of their , which works well when constituent structure trees are used to guide semantic composition . More recently , the functional structure of LFG has been used to provide the syntactic information necessary for constraining derivations of meaning in a cross-linguistically composition . In contrast to compositional approaches , we present a deductive approach to assembling meanings , based with the unordered nature of information in the functional structure . Our use of linear as well as of the LFG requirements of completeness and coherence .	TOPIC	4	5	E93-1013.1	7	8	E93-1013.2	MODEL-FEATURE	10	10	E93-1013.3	12	12	E93-1013.4	MODEL-FEATURE	15	15	E93-1013.5	17	18	E93-1013.6	MODEL-FEATURE	24	24	E93-1013.8	27	27	E93-1013.9	USAGE	38	40	E93-1013.13	45	46	E93-1013.14	PART_WHOLE	52	53	E93-1013.15	55	55	E93-1013.16	USAGE	62	63	E93-1013.17	67	67	E93-1013.18	COMPARE	78	79	E93-1013.24	84	85	E93-1013.25	PART_WHOLE	96	96	E93-1013.28	99	100	E93-1013.29	MODEL-FEATURE	114	114	E93-1013.34	111	111	E93-1013.33
analysis of temporal anaphora in sentences which contain quantification over events , within the framework of Partee , 1984 ) of quantified sentences , introduced by a temporal connective , gives the wrong truth-conditions when the temporal connective in the subordinate clause is before or after . as an instance of the proportion problem and given a solution from a Generalized Quantifier approach . By using a careful propose a solution to this problem , within the framework of DRT . We show some applications of this solution to additional temporal anaphora phenomena in quantified sentences .	PART_WHOLE	8	10	E95-1036.3	5	5	E95-1036.2	PART_WHOLE	27	28	E95-1036.6	21	22	E95-1036.5	PART_WHOLE	36	37	E95-1036.8	40	41	E95-1036.9	TOPIC	60	62	E95-1036.12	52	53	E95-1036.11	USAGE	79	79	E95-1036.15	73	73	E95-1036.14	USAGE	87	87	E95-1036.16	90	92	E95-1036.17
proposes an automatic , essentially domain-independent means of evaluating Spoken Language Systems ( SLS ) which combines software we have developed for that ) and a set of specifications for answer expressions ( the `` Common Answer Common Answer Specification determines the syntax of answer expressions , the minimal content that included in them , the data to be included in and excluded from test corpora , and the procedures used by the Comparator . Though some details of the CAS are particular to individual domains , the Comparator software is domain-independent , as is the CAS	USAGE	17	17	H89-2019.2	5	14	H89-2019.1	MODEL-FEATURE	28	28	H89-2019.4	30	31	H89-2019.5	MODEL-FEATURE	42	42	H89-2019.12	44	45	H89-2019.13	PART_WHOLE	56	56	H89-2019.15	64	65	H89-2019.16	USAGE	69	69	H89-2019.17	73	73	H89-2019.18	MODEL-FEATURE	85	85	H89-2019.20	80	80	H89-2019.19	MODEL-FEATURE	91	91	H89-2019.22	88	89	H89-2019.21
Two themes have evolved in speech and text image processing work at Xerox PARC that expand and redefine the role of recognition technology in document-oriented applications . One is the development functionality similar to that of text processors but operate directly on audio and scanned image data . A second , related theme is the use of speech and text-image recognition to retrieve arbitrary , user-specified information from documents with signal content . This paper discusses three	TOPIC	12	13	H93-1076.4	5	9	H93-1076.3	PART_WHOLE	21	22	H93-1076.5	24	25	H93-1076.6	COMPARE	36	37	H93-1076.7	42	46	H93-1076.8	USAGE	57	60	H93-1076.9	68	71	H93-1076.10
this paper we present a statistical profile of the Named Entity task , a specific information extraction task for which corpora in several languages are available . Using the results of the statistical analysis , we propose an algorithm for lower bound estimation for Named Entity corpora and discuss the significance of the cross-lingual comparisons provided by the analysis .	MODEL-FEATURE	5	6	A97-1028.1	9	11	A97-1028.2	MODEL-FEATURE	23	23	A97-1028.5	20	20	A97-1028.4	RESULT	32	33	A97-1028.7	29	29	A97-1028.6	USAGE	38	38	A97-1028.8	40	42	A97-1028.9	TOPIC	58	58	A97-1028.12	53	54	A97-1028.11
We consider the problem of question-focused sentence retrieval from complex news articles describing multi-event stories published over questions central to understanding each story in our corpus . Because of the dynamic `` ) . Judges found sentences providing an answer to each question . To address the sentence retrieval problem , we apply a stochastic , graph-based method for comparing the relative importance a topic-sensitive version of our method and hypothesize that it can outperform a competitive baseline , which compares the similarity of each sentence to the input question via In our experiments , the method achieves a TRDR score that is significantly higher than	USAGE	5	7	H05-1115.1	10	11	H05-1115.2	PART_WHOLE	22	22	H05-1115.6	25	25	H05-1115.7	PART_WHOLE	39	39	H05-1115.12	36	36	H05-1115.11	USAGE	54	57	H05-1115.15	47	49	H05-1115.14	COMPARE	68	68	H05-1115.18	77	77	H05-1115.19	MODEL-FEATURE	82	82	H05-1115.20	85	85	H05-1115.21	RESULT	96	96	H05-1115.24	99	100	H05-1115.25
Languages Augmented With Reduplication A model is presented to characterize the class of languages obtained by adding reduplication to context-free languages . The model is a pushdown automaton augmented with the ability to check reduplication by using the stack in a new way . of accommodating the sort of reduplications that have been observed to occur in natural languages , but it excludes many	MODEL-FEATURE	5	5	J89-4003.1	11	13	J89-4003.2	PART_WHOLE	17	17	J89-4003.3	19	20	J89-4003.4	USAGE	38	38	J89-4003.8	26	27	J89-4003.6	PART_WHOLE	49	49	J89-4003.13	57	58	J89-4003.14
devoted to the problem of quantifying noun groups in German . After a thorough description kind of information other than grammar sensu stricto into the treebank . We argue that a more sophisticated and fine-grained annotation in the tree-bank would have very positve effects and it would make the treebank more valuable as a source of data for theoretical linguistic investigations . The information gained from SILVA , a parsing and extraction tool for German text corpora .	PART_WHOLE	5	7	I05-6010.1	9	9	I05-6010.2	MODEL-FEATURE	25	25	I05-6010.5	20	22	I05-6010.4	PART_WHOLE	35	35	I05-6010.6	38	38	I05-6010.7	USAGE	49	49	I05-6010.12	58	60	I05-6010.14	USAGE	71	72	I05-6010.18	74	76	I05-6010.19
Formal Constraints on Metarules Metagrammatical formalisms that combine context-free phrase structure rules and metarules ( MPS grammars statement of generalizations about the syntax of natural languages . Unconstrained MPS grammars ,	PART_WHOLE	8	11	P83-1004.2	4	5	P83-1004.1	PART_WHOLE	22	22	P83-1004.4	24	25	P83-1004.5
this paper we present a formalization of the centering approach to modeling attentional structure in discourse and use it as the basis for an algorithm to track discourse context and bind pronouns . As has been implemented in an HPSG natural language system which serves as the interface to a database query application .	MODEL-FEATURE	5	5	P87-1022.1	12	15	P87-1022.3	USAGE	24	24	P87-1022.4	27	28	P87-1022.5	USAGE	39	42	P87-1022.12	50	52	P87-1022.13
the two theories . While HPSG has a more elaborated principle-based theory of possible phrase structures , TAG provides the means to represent lexicalized structures more explicitly . Our objectives clear definitions that determine the projection of structures from the lexicon , and identify maximal projections	PART_WHOLE	10	11	P95-1013.6	5	5	P95-1013.5	USAGE	17	17	P95-1013.8	23	24	P95-1013.9	PART_WHOLE	35	37	P95-1013.10	40	40	P95-1013.11
Matrix Multiplication Valiant showed that Boolean matrix multiplication ( BMM ) can be used for CFG parsing . We prove a dual result : CFG parsers running in time O ( |G||w|3-e ) on a grammar G and process we also provide a formal definition of parsing motivated by an informal notion : a fast , practical CFG parser would yield a fast , practical BMM algorithm , which is not believed	USAGE	5	10	P97-1002.1	15	16	P97-1002.2	MODEL-FEATURE	28	32	P97-1002.4	24	25	P97-1002.3	MODEL-FEATURE	43	44	P97-1002.9	46	46	P97-1002.10	RESULT	57	58	P97-1002.12	65	66	P97-1002.13
Optimality Theory This paper introduces primitive Optimality Theory ( OTP ) , a linguistically motivated formalization of OT . OTP specifies the class In contrast to less restricted theories using Generalized Alignment , OTP 's optimal surface forms can be generated with finite-state methods adapted from ( Ellison , 1994 ) . Unfortunately these methods take time exponential on the size of the grammar . Indeed the generation problem is shown NP-complete in this sense . However , factored automata , where regular languages are represented compactly via formal intersections of FSAs .	MODEL-FEATURE	5	10	P97-1040.1	17	17	P97-1040.2	USAGE	30	31	P97-1040.8	28	28	P97-1040.7	USAGE	42	43	P97-1040.11	36	37	P97-1040.10	MODEL-FEATURE	56	63	P97-1040.13	54	54	P97-1040.12	MODEL-FEATURE	71	71	P97-1040.15	67	68	P97-1040.14	MODEL-FEATURE	88	91	P97-1040.21	82	83	P97-1040.20
of a collection of 20 Wall Street Journal articles from the Penn Treebank Corpus and our experiments with WordNet	PART_WHOLE	5	8	P97-1072.2	11	13	P97-1072.3
for hardware verification To verify hardware designs by model checking , circuit specifications are commonly expressed in the temporal logic CTL . Automatic conversion of English the definition of an appropriately restricted subset of English . We show how the limited semantic expressibility of CTL can be exploited to derive with approaches that take existing computational semantic analyses of English as their starting point -- need to ensure that all sentences in the subset possess a CTL translation .	USAGE	8	9	P99-1058.2	5	6	P99-1058.1	MODEL-FEATURE	18	20	P99-1058.4	11	12	P99-1058.3	PART_WHOLE	31	32	P99-1058.6	34	34	P99-1058.7	MODEL-FEATURE	41	42	P99-1058.8	44	44	P99-1058.9	TOPIC	55	57	P99-1058.11	59	59	P99-1058.12	PART_WHOLE	70	70	P99-1058.13	73	73	P99-1058.14
paper , we present an unlexicalized parser for German which employs smoothing and suffix analysis to achieve a labelled bracket F-score of 76.2 , higher than model , the use of smoothing in an unlexicalized parser allows us to better examine	USAGE	5	6	P05-1039.1	8	8	P05-1039.2	RESULT	13	14	P05-1039.4	18	20	P05-1039.5	USAGE	31	31	P05-1039.8	34	35	P05-1039.9
Alignment This paper proposes an alignment adaptation approach to improve domain-specific ( in-domain ) word alignment . The basic idea of alignment adaptation is to use out-of-domain corpus to improve in-domain word alignment results . In this paper alignment models with the large-scale out-of-domain corpus and the small-scale in-domain corpus respectively , and then interpolate show that our approach improves domain-specific word alignment in terms of both precision and recall , achieving a relative error rate reduction of 6.56 % as compared	USAGE	5	7	P05-1058.1	10	15	P05-1058.2	USAGE	26	27	P05-1058.4	30	32	P05-1058.5	COMPARE	43	44	P05-1058.7	48	49	P05-1058.8	RESULT	60	62	P05-1058.10	73	76	P05-1058.13
contributions include a concise , modular architecture with reversible processes of understanding and generation , an information-state	PART_WHOLE	11	11	P05-3001.3	5	6	P05-3001.2
This article deals with the interpretation of conceptual operations underlying the communicative use of The operations are reduced to functions of a formal language , thus changing the level , that pertaining to the conceptual system of NL . For this purpose , have designed a version of KL-ONE which represents the epistemological level , while the new experimental language , KL-Conc , represents the conceptual level . KL-Conc would seem to	MODEL-FEATURE	5	5	E83-1021.1	7	8	E83-1021.2	PART_WHOLE	19	19	E83-1021.5	22	23	E83-1021.6	MODEL-FEATURE	34	35	E83-1021.9	37	37	E83-1021.10	MODEL-FEATURE	48	48	E83-1021.11	52	53	E83-1021.12	MODEL-FEATURE	61	61	E83-1021.13	65	66	E83-1021.14
And Verb Form Semantics The verb forms are often claimed to convey two kinds of information : 1. whether the event described in a sentence is present , past or information ) 2. whether the event described in a sentence is presented as completed , component to the analysis of verb form meanings , namely whether or not they express habituality . The framework of the	MODEL-FEATURE	15	15	E87-1043.2	5	6	E87-1043.1	PART_WHOLE	20	20	E87-1043.3	24	24	E87-1043.4	PART_WHOLE	35	35	E87-1043.9	39	39	E87-1043.10	MODEL-FEATURE	60	60	E87-1043.13	50	52	E87-1043.12
the appropriate method for expressing relations between representations in the form of feature approach is desirable . A declarative formalism is presented which permits direct mappings of one feature structure into	MODEL-FEATURE	5	5	E91-1050.2	7	7	E91-1050.3	USAGE	18	19	E91-1050.5	25	25	E91-1050.6
We give an analysis of ellipsis resolution in terms of a straightforward discourse copying algorithm that correctly predicts a wide encodes the intuitive distinction between full NPs and the referential elements that corefer with them through role linking . The correct predictions for several problematic examples of ellipsis naturally result . Finally ,	MODEL-FEATURE	12	14	E93-1025.2	5	6	E93-1025.1	COMPARE	25	26	E93-1025.4	29	30	E93-1025.5	MODEL-FEATURE	41	41	E93-1025.7	47	47	E93-1025.8
Representing Text Chunks Dividing sentences in chunks of words is a useful preprocessing step introduced a `` convenient '' data representation for chunking by converting it to a we will examine seven different data representations for the problem of recognizing noun phrase chunks . We will show that the data representation choice has a minor influence on chunking performance . However , equipped with suitable data representation , our memory-based learning chunker was able to improve the best published chunking results for a standard data set	PART_WHOLE	6	8	E99-1023.2	4	4	E99-1023.1	USAGE	19	20	E99-1023.6	22	22	E99-1023.7	MODEL-FEATURE	33	34	E99-1023.9	40	42	E99-1023.10	RESULT	49	51	E99-1023.11	57	58	E99-1023.12	RESULT	69	71	E99-1023.14	79	80	E99-1023.15
compare two competing approaches to part-of-speech tagging , statistical and constraint-based disambiguation , using French as our test language . We imposed a time on the design of our constraint system was about the same as the time we used to train and test the easy-to-implement statistical model . We describe the two . The accuracy of the statistical method is reasonably good , comparable to taggers for English . But the	USAGE	8	11	E95-1021.2	5	6	E95-1021.1	USAGE	14	14	E95-1021.3	17	18	E95-1021.4	COMPARE	29	30	E95-1021.5	46	47	E95-1021.6	COMPARE	58	59	E95-1021.8	66	66	E95-1021.9
In order to build robust automatic abstracting systems , there is a need for better training resources than are currently available . paper , we introduce an annotation scheme for scientific articles which can be used to build such a resource in a consistent way .	USAGE	15	16	E99-1015.2	5	7	E99-1015.1	USAGE	27	28	E99-1015.3	40	40	E99-1015.4
a partial list of the subcategorization frames in which each verb occurs . The completeness of the total occurrences of each verb in the training corpus . False positive rates are	MODEL-FEATURE	5	6	H91-1067.2	10	10	H91-1067.3	PART_WHOLE	21	21	H91-1067.5	24	25	H91-1067.6
of building large repositories of lexical conceptual structure ( LCS ) representations for verbs in multiple languages . One work on verb classification and thematic grid tagging , and outputs LCS representations for different languages . These representations have been ported into English , Arabic and Spanish lexicons , each containing approximately 9000 We are currently using these lexicons in an operational foreign language tutoring and machine translation .	MODEL-FEATURE	5	11	A97-1021.2	13	13	A97-1021.3	USAGE	24	26	A97-1021.9	30	31	A97-1021.10	USAGE	37	37	A97-1021.12	42	47	A97-1021.13	USAGE	58	58	A97-1021.15	61	64	A97-1021.16
investigate the utility of an algorithm for translation lexicon acquisition ( SABLE ) , used previously on a very large corpus to acquire general translation lexicons , when that algorithm is applied to a much smaller corpus to produce candidates for domain-specific translation lexicons .	USAGE	5	12	A97-1050.1	24	25	A97-1050.3	USAGE	29	29	A97-1050.4	41	43	A97-1050.6
trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement . The agreement in question involves number in nouns and reflexive pronouns and is than semantic in nature because grammatical number in English , like grammatical gender in languages such as French , is partly arbitrary . to be valid even if English is presumed to contain grammatical sentences in which respectively operates across a pair of coordinate phrases one of whose members has fewer conjuncts than the other ; it the facts may be regarding constructions with unequal numbers of conjuncts in the scope of respectively	MODEL-FEATURE	5	5	J87-1003.2	12	15	J87-1003.3	MODEL-FEATURE	22	22	J87-1003.5	24	24	J87-1003.6	PART_WHOLE	35	36	J87-1003.8	38	38	J87-1003.9	PART_WHOLE	41	42	J87-1003.10	47	47	J87-1003.12	PART_WHOLE	63	64	J87-1003.15	58	58	J87-1003.14	PART_WHOLE	81	81	J87-1003.17	73	74	J87-1003.16	PART_WHOLE	97	97	J87-1003.19	92	92	J87-1003.18
, we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic	USAGE	5	6	I05-5004.2	9	10	I05-5004.3	PART_WHOLE	14	15	I05-5004.4	20	21	I05-5004.5
Interaction in Flexible Parsing A flexible parser can deal with input that deviates from its grammar , in addition to input kind is facilitated by a construction-specific approach to flexible parsing , with specialized parsing techniques for each type of construction , and specialized ambiguity representations for each type of ambiguity that a particular construction can give rise to . A construction-specific approach also aids in task-specific language development by allowing a language definition	PART_WHOLE	15	15	P81-1033.2	5	6	P81-1033.1	USAGE	26	27	P81-1033.8	29	30	P81-1033.9	USAGE	33	35	P81-1033.10	40	40	P81-1033.11	MODEL-FEATURE	44	45	P81-1033.12	50	50	P81-1033.13	USAGE	61	62	P81-1033.15	66	68	P81-1033.16
5 , 8 ] , Plume 's approach to parsing is based on semantic caseframe instantiation . This has the advantages of ungrammatical input . While Plume is well adapted to simple declarative and imperative utterances , it handles passives , relative clauses and interrogatives in an ad hoc manner leading to patchy syntactic coverage . This paper outlines Plume	USAGE	13	15	P85-1019.4	5	9	P85-1019.3	RESULT	26	26	P85-1019.9	53	54	P85-1019.14
Translation Mismatches With Information Flow Languages differ in the concepts and real-world entities for which they have words and grammatical constructs . Therefore a matter of approximating the meaning of a source language text rather than finding an exact language . We propose a translation framework based on Situation Theory . The basic ingredients are an information lattice , a representation scheme for utterances embedded in contexts , and a mismatch resolution scheme defined in terms of information flow . We motivate our approach with examples of translation between English and Japanese .	PART_WHOLE	17	17	P91-1025.4	5	5	P91-1025.1	MODEL-FEATURE	28	28	P91-1025.7	31	33	P91-1025.8	USAGE	48	49	P91-1025.11	44	45	P91-1025.10	MODEL-FEATURE	60	61	P91-1025.13	63	63	P91-1025.14	MODEL-FEATURE	77	78	P91-1025.17	70	72	P91-1025.16	USAGE	87	87	P91-1025.18	89	89	P91-1025.19
Two-Level , Many-Paths Generation Large-scale natural language generation requires the integration of vast amounts of knowledge : lexical , grammatical , and conceptual . A robust generator must be able to operate well even when pieces of knowledge are missing . It must , we have built a hybrid generator , in which gaps in symbolic knowledge are filled by statistical methods . We describe algorithms and be used to simplify current generators and enhance their portability , even when perfect knowledge	USAGE	15	15	P95-1034.2	4	7	P95-1034.1	USAGE	37	37	P95-1034.4	25	26	P95-1034.3	USAGE	60	61	P95-1034.8	48	49	P95-1034.6	MODEL-FEATURE	76	76	P95-1034.11	72	72	P95-1034.10
names and technical terms across languages with different alphabets and sound inventories . These For example , computer in English comes out as ~ i/l : : : '= -- ~ -- ( konpyuutaa ) in Japanese . Translating such items from evaluate a method for performing backwards transliterations by machine . This method uses a generative model , incorporating several distinct stages in the transliteration process .	MODEL-FEATURE	5	5	P97-1017.3	8	8	P97-1017.4	COMPARE	19	19	P97-1017.7	36	36	P97-1017.8	USAGE	50	50	P97-1017.14	47	48	P97-1017.13	USAGE	56	57	P97-1017.15	65	66	P97-1017.16
, for applications such as speech processing in which speed is important finite-state models are often preferred . These grammar to automatically derive a finite-state approximation which can then be used as a filter to guide speech recognition or to reject many hypotheses	USAGE	12	13	P97-1058.6	5	6	P97-1058.5	USAGE	24	25	P97-1058.8	36	37	P97-1058.9
and Context We present a statistical model of Japanese unknown words consisting of a set of spelling models classified by the character types that constitute a word . The point is quite types are very important because Japanese script has both ideograms like Chinese ( kanji )	MODEL-FEATURE	5	6	P99-1036.1	8	10	P99-1036.2	PART_WHOLE	21	22	P99-1036.4	26	26	P99-1036.5	PART_WHOLE	41	41	P99-1036.9	37	38	P99-1036.8
Selection This paper discusses a decision-tree approach to the problem of assigning probabilities to words following a given text . In contrast with previous	USAGE	5	6	P99-1080.1	12	12	P99-1080.2	PART_WHOLE	14	14	P99-1080.3	18	18	P99-1080.4
This poster paper describes a full scale two-level morphological description ( Karttunen , 1983 ; Koskenniemi , 1983 ) of Turkish word structures . The description has been and is based on a root word lexicon of about 23,000 roots words . Almost all the special rules have been implemented . Turkish is an agglutinative language with word structures formed by create adverbial constructs . The surface realizations of morphological constructions are constrained and modified by	MODEL-FEATURE	5	9	E93-1066.1	20	22	E93-1066.2	PART_WHOLE	39	40	E93-1066.5	33	35	E93-1066.4	MODEL-FEATURE	51	51	E93-1066.7	54	55	E93-1066.8	MODEL-FEATURE	66	67	E93-1066.21	69	70	E93-1066.22
enable a variety of different text applications to use a set of common text processing modules . Since user interfaces work is appropriator that no particular user interface styles or conventions are described in the TIPSTER Architecture specification . However , the Computing CRL ) has constructed several TIPSTER applications that use a common set of configurable Graphical User Interface ( GUI ) functions . These GUIs were constructed using CRL 's TIPSTER User Interface Toolkit ( TUIT ) . TUIT is a software library that can be used to construct multilingual TIPSTER user interfaces for a set of common	USAGE	12	15	X96-1041.3	5	6	X96-1041.2	TOPIC	35	37	X96-1041.7	26	30	X96-1041.6	USAGE	57	63	X96-1041.10	48	49	X96-1041.9	USAGE	70	78	X96-1041.12	66	66	X96-1041.11	USAGE	83	84	X96-1041.14	91	94	X96-1041.15
paper describes to what extent deep processing may benefit from shallow techniques and it presents a NLP system which integrates a linguistic PoS tagger and chunker as a preprocessing module of that our system also provides robustness to the linguistic processing while maintaining both the accuracy and the precision of the grammar .	USAGE	10	11	C02-1071.2	5	6	C02-1071.1	PART_WHOLE	21	25	C02-1071.4	16	17	C02-1071.3	MODEL-FEATURE	36	36	C02-1071.7	39	40	C02-1071.8	RESULT	51	51	C02-1071.11	48	48	C02-1071.10
the performance of a state-of-the-art statistical parser ( Bikel , 2004 ) in parsing written and spoken language and in generating sub-categorization cues and spoken language . Although Bikel 's parser achieves a higher accuracy for parsing written language , show that current technology for extracting subcategorization frames initially designed for written texts works equally well for spoken we explore the utility of punctuation in helping parsing and extraction of subcategorization cues parsing spoken language and extracting subcategorization cues from spoken language . This indicates that there is no need to add punctuation in transcribing spoken corpora simply in order to help	USAGE	5	6	P06-2067.1	14	17	P06-2067.2	RESULT	28	30	P06-2067.5	34	34	P06-2067.6	USAGE	45	47	P06-2067.11	51	52	P06-2067.12	USAGE	63	63	P06-2067.14	66	66	P06-2067.15	PART_WHOLE	77	78	P06-2067.20	80	81	P06-2067.21	PART_WHOLE	92	92	P06-2067.22	95	96	P06-2067.23
Chinese This paper describes a characters-based Chinese collocation system and discusses the advantages of it over a traditional word-based system . Since wordbreaks are not conventionally marked in Chinese text corpora , a character-based collocation system sub-lexical information . Furthermore , word-based collocational properties can be obtained through an auxiliary module of automatic segmentation .	COMPARE	5	8	C94-1088.1	18	19	C94-1088.2	PART_WHOLE	22	22	C94-1088.3	28	30	C94-1088.4	USAGE	52	53	C94-1088.9	41	43	C94-1088.8
With Bit Vectors An efficient bit-vector-based CKY-style parser for context-free parsing is presented . The parser computes a compact parse forest representation of the complete set of possible analyses for large treebank grammars and long input sentences . The parser uses bit-vector operations to parallelise the basic parsing	USAGE	5	7	C04-1024.1	9	10	C04-1024.2	MODEL-FEATURE	19	21	C04-1024.4	28	32	C04-1024.5	USAGE	41	42	C04-1024.8	39	39	C04-1024.7
architecture which exploits both a language model for answers and a transformation model for answer/question terms , trained on a corpus of 1 million question/answer pairs collected from the Web .	USAGE	5	6	N04-1008.4	8	8	N04-1008.5	USAGE	11	12	N04-1008.6	14	15	N04-1008.7	PART_WHOLE	24	25	N04-1008.9	20	20	N04-1008.8
The applicability of many current information extraction techniques is severely limited by the need for supervised training data . We demonstrate that for certain field structured extraction tasks , such as classified advertisements and bibliographic citations , small amounts of prior knowledge can be used to learn HMMs ) provide a suitable generative model for field structured text , general unsupervised HMM learning domains , we found that unsupervised methods can attain accuracies with 400 unlabeled examples comparable labeled examples , and that semi-supervised methods can make good use of small amounts of labeled data .	USAGE	15	17	P05-1046.2	5	7	P05-1046.1	USAGE	40	41	P05-1046.4	24	27	P05-1046.3	MODEL-FEATURE	52	53	P05-1046.6	55	57	P05-1046.7	RESULT	68	69	P05-1046.10	72	72	P05-1046.11	USAGE	93	94	P05-1046.16	83	84	P05-1046.15
much recent progress on accurate semantic role labeling , previous work has largely used independent classifiers , possibly combined with separate joint structure , with strong dependencies between arguments . We show how to build a joint model of argument frames , incorporating novel features that model these interactions into discriminative log-linear models . This system achieves an state-of-the art independent classifier for gold-standard parse trees on PropBank .	USAGE	14	15	P05-1073.2	5	7	P05-1073.1	MODEL-FEATURE	26	26	P05-1073.6	28	28	P05-1073.7	MODEL-FEATURE	36	37	P05-1073.8	39	40	P05-1073.9	PART_WHOLE	44	44	P05-1073.10	50	52	P05-1073.11	PART_WHOLE	63	65	P05-1073.16	67	67	P05-1073.17
a concise set of reading texts ( from a target corpus ) that contains all the . We used a specialized vocabulary for an English certification test as the target vocabulary and used English Wikipedia , a free-content encyclopedia , as the target corpus . The organized reading materials	PART_WHOLE	5	5	P05-3030.2	9	10	P05-3030.3	USAGE	21	21	P05-3030.5	29	30	P05-3030.6	USAGE	33	34	P05-3030.7	42	43	P05-3030.8
system are described : the syntactic analyzer , based on a Procedural Systemic Grammar , the semantic analyzer relying on the Conceptual Dependency Theory , and the dictionary .	USAGE	11	13	E83-1029.3	5	6	E83-1029.2	USAGE	21	23	E83-1029.5	16	17	E83-1029.4
A proposal to deal with French tenses in the framework of Discourse Representation Theory is presented , as it using operators to express the meaning of the tenses the Reichenbachian point of view tenses with respect to the meaning of the text is understood as contribution to the integration of the events of a sentence in the event structure of the preceeding text . Thereby a system of preceeding text and by the temporal adverbials of the sentence being processed is used . Kamp and Rohrer the exact meaning of the tenses is fixed by the resolution component and not in the process of syntactic analysis .	MODEL-FEATURE	11	13	E89-1006.2	5	6	E89-1006.1	MODEL-FEATURE	24	24	E89-1006.6	27	27	E89-1006.7	MODEL-FEATURE	38	38	E89-1006.9	41	41	E89-1006.10	PART_WHOLE	51	51	E89-1006.11	54	54	E89-1006.12	MODEL-FEATURE	57	58	E89-1006.13	62	62	E89-1006.14	PART_WHOLE	73	74	E89-1006.17	77	77	E89-1006.18	MODEL-FEATURE	88	88	E89-1006.26	91	91	E89-1006.27	COMPARE	96	97	E89-1006.28	104	105	E89-1006.29
The motivation for introducing these languages is to provide tools for formalising grammatical frameworks perspicuously , and the paper how the leading ideas of GPSG can be captured in LT ( LF ) . In addition , the	MODEL-FEATURE	5	5	E93-1004.7	12	13	E93-1004.8	COMPARE	24	24	E93-1004.9	29	32	E93-1004.10
of the claimed benefits of Tree Adjoining Grammars is that they have an extended domain of locality ( EDOL ) . We consider how this to limit the need for feature structure unification during parsing . We compare two wide-coverage lexicalized grammars of English , LEXSYS and XTAG , finding that the two grammars exploit EDOL in different ways .	MODEL-FEATURE	5	7	E99-1029.1	13	19	E99-1029.2	USAGE	30	32	E99-1029.3	34	34	E99-1029.4	COMPARE	45	45	E99-1029.6	47	47	E99-1029.7	USAGE	55	55	E99-1029.9	53	53	E99-1029.8
provide a unified account of sentence-level and text-level anaphora within the framework of a dependency-based grammar model . Criteria for anaphora resolution theory , while those for text-level anaphora incorporate an adapted version of a Grosz-Sidner-style focus model .	MODEL-FEATURE	14	16	E95-1033.2	5	8	E95-1033.1	MODEL-FEATURE	35	37	E95-1033.7	27	28	E95-1033.6
efforts that make use of heuristic rules whose development requires intense knowledge engineering , our approach attempts to our system , features and decision strategies are discovered and trained automatically , using a large body of speech data . This paper describes the	USAGE	11	12	H89-1027.4	5	6	H89-1027.3	USAGE	36	37	H89-1027.8	23	24	H89-1027.7
Lexical Disambiguation A method of sense resolution is proposed that is based on WordNet , an on-line lexical database that incorporates semantic relations ( synonymy , antonymy , between word senses . With WordNet , it is easy to retrieve sets of semantically related words , a facility that will be used for sense resolution during text processing , as follows . When a word with multiple senses is encountered , one of polysemous word ; a large textual corpus will then be searched for these derived strings ; and that sense will chosen that corresponds to the derived string that is found most often in the corpus . Or , ( 2 ) the context of the polysemous word will be used as a a large corpus ; all words found to occur in that context will be noted ; WordNet will then be used to estimate the semantic distance from those words to the closest in meaning to other words occurring in the same context If successful , this procedure	USAGE	13	13	H91-1077.2	5	6	H91-1077.1	PART_WHOLE	21	22	H91-1077.4	17	18	H91-1077.3	PART_WHOLE	42	44	H91-1077.13	33	33	H91-1077.12	PART_WHOLE	53	54	H91-1077.14	56	57	H91-1077.15	MODEL-FEATURE	67	67	H91-1077.17	64	64	H91-1077.16	PART_WHOLE	86	87	H91-1077.27	78	79	H91-1077.26	PART_WHOLE	98	99	H91-1077.29	107	107	H91-1077.30	MODEL-FEATURE	115	115	H91-1077.31	118	119	H91-1077.32	MODEL-FEATURE	136	136	H91-1077.35	130	130	H91-1077.34	USAGE	141	141	H91-1077.36	149	150	H91-1077.37	MODEL-FEATURE	166	166	H91-1077.44	161	161	H91-1077.43
want to show how the morphological component of an existing NLP-system for Dutch ( Dutch Medical Language Processor - DMLP ) has been extended in order that is compatible with the language independent modules of the LSP-MLP system ( Linguistic String Project - Medical Language Processor ) of the New York University latter , while focusing on idiosyncrasies for Dutch . This general strategy will	PART_WHOLE	5	6	A97-1027.1	10	20	A97-1027.2	PART_WHOLE	31	33	A97-1027.3	36	46	A97-1027.4	PART_WHOLE	57	57	A97-1027.6	59	59	A97-1027.7
implemented system for constructing a subcategorization dictionary from textual corpora . Each dictionary entry encodes the relative frequency of occurrence of a comprehensive set of subcategorization classes for English . An initial on a sample of 14 verbs which exhibit multiple complementation patterns , demonstrates that the technique We also demonstrate that a subcategorization dictionary built with the system improves the accuracy of a parser by an	USAGE	8	9	A97-1052.2	5	6	A97-1052.1	MODEL-FEATURE	16	19	A97-1052.4	25	26	A97-1052.5	MODEL-FEATURE	40	42	A97-1052.8	37	37	A97-1052.7	RESULT	53	54	A97-1052.11	61	61	A97-1052.12
HIERARCHIES This paper shows how dictionary word sense definitions can be analysed by applying a hierarchy of phrasal patterns . An experimental system embodying has been implemented for processing definitions from the Longman Dictionary of Contemporary English . A property of this is that it uses a restricted vocabulary in its word sense definitions . The structures generated by for the classification of new word senses in terms of the senses of words in the restricted vocabulary . Examples illustrating the output reasonable incomplete analyses of the definitions are produced when more complete analyses are not possible , resulting in a relatively robust analysis mechanism . Thus the work reported addresses two robustness problems faced by current experimental natural language processing systems : coping with an incomplete	USAGE	17	18	J87-3001.2	5	8	J87-3001.1	PART_WHOLE	29	29	J87-3001.3	32	36	J87-3001.4	USAGE	47	48	J87-3001.6	51	53	J87-3001.7	MODEL-FEATURE	70	70	J87-3001.10	64	65	J87-3001.9	PART_WHOLE	72	72	J87-3001.11	75	76	J87-3001.12	TOPIC	103	104	J87-3001.17	87	87	J87-3001.16	MODEL-FEATURE	112	113	J87-3001.18	118	121	J87-3001.19
Model This paper presents an evaluation method employing a latent variable model for paraphrases with their contexts . We assume that the context of a sentence is indicated by a latent variable of the model as a topic and that the likelihood of each variable can be inferred . A is evaluated for whether its sentences are used in the same context . Experimental results showed that revealed an upper bound of accuracy of 77 % with the method when using only topic information .	USAGE	9	11	I05-5009.2	5	6	I05-5009.1	MODEL-FEATURE	16	16	I05-5009.4	13	13	I05-5009.3	MODEL-FEATURE	22	22	I05-5009.5	25	25	I05-5009.6	PART_WHOLE	30	31	I05-5009.7	34	34	I05-5009.8	MODEL-FEATURE	41	41	I05-5009.10	44	44	I05-5009.11	MODEL-FEATURE	55	55	I05-5009.13	61	61	I05-5009.14	RESULT	82	83	I05-5009.19	72	72	I05-5009.17
formalism is proposed , allowing non-terminals to consist of finite sequences of category labels , and allowing schematic variables to provide a strongly adequate grammar for crossed serial dependencies , as found in e.g simple extension to an existing parsing method for GPSG .	PART_WHOLE	12	13	P83-1003.3	5	5	P83-1003.2	USAGE	24	24	P83-1003.5	26	28	P83-1003.6	USAGE	39	40	P83-1003.10	42	42	P83-1003.11
