Labeling ( SRL ) , arguments are usually limited in a syntax subtree . It is reasonable to label arguments locally in such a sub-tree rather than a whole tree single anchor approach . The anchor group approach achieves an accuracy of 87.75 % and the results also indicate that the prediction of MP improves semantic role labeling .	PART_WHOLE	5	5	C08-1105.2	11	12	C08-1105.3
Labeling ( SRL ) , arguments are usually limited in a syntax subtree . It is reasonable to label arguments locally in such a sub-tree rather than a whole tree single anchor approach . The anchor group approach achieves an accuracy of 87.75 % and the results also indicate that the prediction of MP improves semantic role labeling .	PART_WHOLE	19	19	C08-1105.4	24	24	C08-1105.5
Labeling ( SRL ) , arguments are usually limited in a syntax subtree . It is reasonable to label arguments locally in such a sub-tree rather than a whole tree single anchor approach . The anchor group approach achieves an accuracy of 87.75 % and the results also indicate that the prediction of MP improves semantic role labeling .	RESULT	35	37	C08-1105.15	40	40	C08-1105.16
Labeling ( SRL ) , arguments are usually limited in a syntax subtree . It is reasonable to label arguments locally in such a sub-tree rather than a whole tree single anchor approach . The anchor group approach achieves an accuracy of 87.75 % and the results also indicate that the prediction of MP improves semantic role labeling .	RESULT	51	53	C08-1105.18	55	57	C08-1105.19
undertaken the development of a multilingual translation system based on a symbolic parsing technology and on a transfer-based translation	USAGE	11	13	L08-1579.2	5	7	L08-1579.1
unsupervised learning algorithm for disambiguating verbal word senses using term weight learning . In our method ,	USAGE	9	11	E99-1028.2	5	7	E99-1028.1
approaches to semantic parsing or chunking that depend on full statistical syntactic parsers that require tree bank style results that show that the phrase-by-phrase approach performs better than its word-by-word counterpart .	USAGE	10	12	N04-4037.10	5	5	N04-4037.9
approaches to semantic parsing or chunking that depend on full statistical syntactic parsers that require tree bank style results that show that the phrase-by-phrase approach performs better than its word-by-word counterpart .	COMPARE	23	24	N04-4037.13	29	30	N04-4037.14
improved methods and models for acoustic recognition of continuous speech . The work has focussed and detailed mathematical models of phonemes and their coarticulation for the purpose of large-vocabulary continuous speech recognition . Important goals of this	USAGE	5	6	H91-1080.1	8	9	H91-1080.2
improved methods and models for acoustic recognition of continuous speech . The work has focussed and detailed mathematical models of phonemes and their coarticulation for the purpose of large-vocabulary continuous speech recognition . Important goals of this	USAGE	20	20	H91-1080.3	28	31	H91-1080.4
Keywords . KeyWords compares a word list extracted from what has been called 'the study corpus ' ( the corpus which in describing ) with a word list made from a reference corpus . The only requirement for to this question . Five English corpora were compared to reference corpora of various sizes ( varying as large as the study corpus yielded a larger number of keywords than a smaller reference corpus Keywords analysis , while a reference corpus that is less than five times the size of the study corpus may not be reliable .	PART_WHOLE	5	6	W00-0902.5	15	15	W00-0902.6
Keywords . KeyWords compares a word list extracted from what has been called 'the study corpus ' ( the corpus which in describing ) with a word list made from a reference corpus . The only requirement for to this question . Five English corpora were compared to reference corpora of various sizes ( varying as large as the study corpus yielded a larger number of keywords than a smaller reference corpus Keywords analysis , while a reference corpus that is less than five times the size of the study corpus may not be reliable .	PART_WHOLE	26	27	W00-0902.8	31	32	W00-0902.9
Keywords . KeyWords compares a word list extracted from what has been called 'the study corpus ' ( the corpus which in describing ) with a word list made from a reference corpus . The only requirement for to this question . Five English corpora were compared to reference corpora of various sizes ( varying as large as the study corpus yielded a larger number of keywords than a smaller reference corpus Keywords analysis , while a reference corpus that is less than five times the size of the study corpus may not be reliable .	COMPARE	43	44	W00-0902.15	48	49	W00-0902.16
Keywords . KeyWords compares a word list extracted from what has been called 'the study corpus ' ( the corpus which in describing ) with a word list made from a reference corpus . The only requirement for to this question . Five English corpora were compared to reference corpora of various sizes ( varying as large as the study corpus yielded a larger number of keywords than a smaller reference corpus Keywords analysis , while a reference corpus that is less than five times the size of the study corpus may not be reliable .	PART_WHOLE	66	66	W00-0902.20	60	60	W00-0902.19
Keywords . KeyWords compares a word list extracted from what has been called 'the study corpus ' ( the corpus which in describing ) with a word list made from a reference corpus . The only requirement for to this question . Five English corpora were compared to reference corpora of various sizes ( varying as large as the study corpus yielded a larger number of keywords than a smaller reference corpus Keywords analysis , while a reference corpus that is less than five times the size of the study corpus may not be reliable .	COMPARE	77	78	W00-0902.28	89	90	W00-0902.29
of the performance of a dependency analyser of Italian that runs in both a the contribution of types of lexical information to parsing .	USAGE	5	6	W02-1501.1	8	8	W02-1501.2
of the performance of a dependency analyser of Italian that runs in both a the contribution of types of lexical information to parsing .	USAGE	19	20	W02-1501.5	22	22	W02-1501.6
has been suggested that the relative informativeness of a word can be used to predict by employing two widely accepted measures of informativeness . Our experiments show that a positive correlation between the informativeness of a word and its pitch accent assignment prediction . The computation of word informativeness is inexpensive and can be incorporated into speech synthesis systems easily .	MODEL-FEATURE	5	6	W99-0619.3	9	9	W99-0619.4
has been suggested that the relative informativeness of a word can be used to predict by employing two widely accepted measures of informativeness . Our experiments show that a positive correlation between the informativeness of a word and its pitch accent assignment prediction . The computation of word informativeness is inexpensive and can be incorporated into speech synthesis systems easily .	MODEL-FEATURE	20	20	W99-0619.7	22	22	W99-0619.8
has been suggested that the relative informativeness of a word can be used to predict by employing two widely accepted measures of informativeness . Our experiments show that a positive correlation between the informativeness of a word and its pitch accent assignment prediction . The computation of word informativeness is inexpensive and can be incorporated into speech synthesis systems easily .	MODEL-FEATURE	33	33	W99-0619.9	36	36	W99-0619.10
has been suggested that the relative informativeness of a word can be used to predict by employing two widely accepted measures of informativeness . Our experiments show that a positive correlation between the informativeness of a word and its pitch accent assignment prediction . The computation of word informativeness is inexpensive and can be incorporated into speech synthesis systems easily .	USAGE	47	48	W99-0619.14	56	58	W99-0619.15
Parsing Algorithm `` An efficient parsing algorithm for augmented context-free grammars is introduced , and its . The algorithm is a generalized LR parsing algorithm , which precomputes an LR shift-reduce parsing table ( possibly with multiple entries parsing algorithm as an extended chart parsing algorithm efficiently guided by LR parsing tables . The algorithm is fast . Also , a commercial on-line parser for Japanese language is being built by Intelligent	USAGE	5	6	J87-1004.1	8	10	J87-1004.2
Parsing Algorithm `` An efficient parsing algorithm for augmented context-free grammars is introduced , and its . The algorithm is a generalized LR parsing algorithm , which precomputes an LR shift-reduce parsing table ( possibly with multiple entries parsing algorithm as an extended chart parsing algorithm efficiently guided by LR parsing tables . The algorithm is fast . Also , a commercial on-line parser for Japanese language is being built by Intelligent	USAGE	21	24	J87-1004.4	29	32	J87-1004.5
Parsing Algorithm `` An efficient parsing algorithm for augmented context-free grammars is introduced , and its . The algorithm is a generalized LR parsing algorithm , which precomputes an LR shift-reduce parsing table ( possibly with multiple entries parsing algorithm as an extended chart parsing algorithm efficiently guided by LR parsing tables . The algorithm is fast . Also , a commercial on-line parser for Japanese language is being built by Intelligent	USAGE	49	51	J87-1004.14	43	45	J87-1004.13
Parsing Algorithm `` An efficient parsing algorithm for augmented context-free grammars is introduced , and its . The algorithm is a generalized LR parsing algorithm , which precomputes an LR shift-reduce parsing table ( possibly with multiple entries parsing algorithm as an extended chart parsing algorithm efficiently guided by LR parsing tables . The algorithm is fast . Also , a commercial on-line parser for Japanese language is being built by Intelligent	USAGE	62	63	J87-1004.21	65	66	J87-1004.22
Understanding This article proposes a hybrid statistical and structural semantic model for multi-stage spoken language understanding ( SLU ) . The first stage of this SLU utilizes a weighted finite-state transducer ( WFST ) -based parser , which encodes the regular The proposed method improves the regular grammar model by incorporating a well-known n-gram semantic tagger . This hybrid model thus	USAGE	5	10	W04-3002.1	12	18	W04-3002.2
Understanding This article proposes a hybrid statistical and structural semantic model for multi-stage spoken language understanding ( SLU ) . The first stage of this SLU utilizes a weighted finite-state transducer ( WFST ) -based parser , which encodes the regular The proposed method improves the regular grammar model by incorporating a well-known n-gram semantic tagger . This hybrid model thus	USAGE	28	35	W04-3002.4	25	25	W04-3002.3
Understanding This article proposes a hybrid statistical and structural semantic model for multi-stage spoken language understanding ( SLU ) . The first stage of this SLU utilizes a weighted finite-state transducer ( WFST ) -based parser , which encodes the regular The proposed method improves the regular grammar model by incorporating a well-known n-gram semantic tagger . This hybrid model thus	USAGE	53	55	W04-3002.7	46	47	W04-3002.6
presents a corpus-based account of structural priming in human sentence processing , focusing on the role structural priming effects from a corpus of spontaneous spoken dialogue , annotated syntactically with Combinatory , and we show that priming effects exist both for incremental and normal-form CCG derivations .	MODEL-FEATURE	5	6	W06-1637.2	9	10	W06-1637.3
presents a corpus-based account of structural priming in human sentence processing , focusing on the role structural priming effects from a corpus of spontaneous spoken dialogue , annotated syntactically with Combinatory , and we show that priming effects exist both for incremental and normal-form CCG derivations .	PART_WHOLE	23	25	W06-1637.7	21	21	W06-1637.6
presents a corpus-based account of structural priming in human sentence processing , focusing on the role structural priming effects from a corpus of spontaneous spoken dialogue , annotated syntactically with Combinatory , and we show that priming effects exist both for incremental and normal-form CCG derivations .	MODEL-FEATURE	36	37	W06-1637.13	41	45	W06-1637.14
shown to be successful in information retrieval and classification of medical literature , to a new task	USAGE	5	6	W07-1014.1	10	11	W07-1014.2
table-of-contents . This type of summary could serve as an effective navigation tool for accessing information in long texts , such as books . To generate a coherent table-of-contents , we need to capture both global dependencies across different titles in the table and local	MODEL-FEATURE	5	5	P07-1069.2	18	18	P07-1069.4
table-of-contents . This type of summary could serve as an effective navigation tool for accessing information in long texts , such as books . To generate a coherent table-of-contents , we need to capture both global dependencies across different titles in the table and local	USAGE	39	39	P07-1069.8	28	28	P07-1069.6
. First , we compare cruiser with a baseline system-initiative DS , and show that users	COMPARE	5	5	P08-1055.7	9	10	P08-1055.8
Recognition To improve the Mandarin large vocabulary continuous speech recognition ( LVCSR ) , a unified framework based approach is introduced to exploit multi-level linguistic knowledge . In this framework , each knowledge source is represented by a Weighted Finite State Transducer ( WFST ) , and then they are uniform transducer representation , any knowledge source can be easily integrated into the analyzer , as long as it can be encoded into WFSTs . Moreover , as the	USAGE	23	25	D08-1086.3	5	12	D08-1086.2
Recognition To improve the Mandarin large vocabulary continuous speech recognition ( LVCSR ) , a unified framework based approach is introduced to exploit multi-level linguistic knowledge . In this framework , each knowledge source is represented by a Weighted Finite State Transducer ( WFST ) , and then they are uniform transducer representation , any knowledge source can be easily integrated into the analyzer , as long as it can be encoded into WFSTs . Moreover , as the	MODEL-FEATURE	38	44	D08-1086.5	32	33	D08-1086.4
Recognition To improve the Mandarin large vocabulary continuous speech recognition ( LVCSR ) , a unified framework based approach is introduced to exploit multi-level linguistic knowledge . In this framework , each knowledge source is represented by a Weighted Finite State Transducer ( WFST ) , and then they are uniform transducer representation , any knowledge source can be easily integrated into the analyzer , as long as it can be encoded into WFSTs . Moreover , as the	USAGE	55	56	D08-1086.8	73	73	D08-1086.9
we discuss algorithms for clustering words into classes from unlabeled text using unsupervised algorithms , based	PART_WHOLE	5	5	E03-1009.1	9	10	E03-1009.2
`` This paper presents an unsupervised relation extraction algorithm , which induces relations between entity pairs by grouping them into a	USAGE	5	8	I05-2045.2	14	15	I05-2045.4
in different languages to locate translation equivalents from corpora . The method uses information from unrelated corpora in different languages that do not have to . The method compares the contexts of target compound nouns and translation candidates in the word or semantic applied to select the best English translation candidate for Japanese compound nouns in more than 70 %	PART_WHOLE	5	6	C02-1065.5	8	8	C02-1065.6
in different languages to locate translation equivalents from corpora . The method uses information from unrelated corpora in different languages that do not have to . The method compares the contexts of target compound nouns and translation candidates in the word or semantic applied to select the best English translation candidate for Japanese compound nouns in more than 70 %	MODEL-FEATURE	16	16	C02-1065.7	19	19	C02-1065.8
in different languages to locate translation equivalents from corpora . The method uses information from unrelated corpora in different languages that do not have to . The method compares the contexts of target compound nouns and translation candidates in the word or semantic applied to select the best English translation candidate for Japanese compound nouns in more than 70 %	COMPARE	30	30	C02-1065.10	36	37	C02-1065.12
in different languages to locate translation equivalents from corpora . The method uses information from unrelated corpora in different languages that do not have to . The method compares the contexts of target compound nouns and translation candidates in the word or semantic applied to select the best English translation candidate for Japanese compound nouns in more than 70 %	USAGE	48	49	C02-1065.15	52	54	C02-1065.16
of Semantic Fields Applications of statistical Arabic NLP in general , and text mining in specific , along with perform much better as the statistical processing operates on deeper language factorization ( s ) than on raw text . the conventional exclusive collection of words from dictionaries and thesauri that can not large-scale Arabic morphological analyzer and PoS tagger in the runtime , the possible senses of virtually any given Arabic word are retrievable .	PART_WHOLE	12	13	L08-1611.2	5	7	L08-1611.1
of Semantic Fields Applications of statistical Arabic NLP in general , and text mining in specific , along with perform much better as the statistical processing operates on deeper language factorization ( s ) than on raw text . the conventional exclusive collection of words from dictionaries and thesauri that can not large-scale Arabic morphological analyzer and PoS tagger in the runtime , the possible senses of virtually any given Arabic word are retrievable .	USAGE	24	25	L08-1611.3	29	33	L08-1611.4
of Semantic Fields Applications of statistical Arabic NLP in general , and text mining in specific , along with perform much better as the statistical processing operates on deeper language factorization ( s ) than on raw text . the conventional exclusive collection of words from dictionaries and thesauri that can not large-scale Arabic morphological analyzer and PoS tagger in the runtime , the possible senses of virtually any given Arabic word are retrievable .	PART_WHOLE	44	44	L08-1611.9	46	46	L08-1611.10
of Semantic Fields Applications of statistical Arabic NLP in general , and text mining in specific , along with perform much better as the statistical processing operates on deeper language factorization ( s ) than on raw text . the conventional exclusive collection of words from dictionaries and thesauri that can not large-scale Arabic morphological analyzer and PoS tagger in the runtime , the possible senses of virtually any given Arabic word are retrievable .	USAGE	57	58	L08-1611.21	70	71	L08-1611.22
speech recognition hypotheses , the consensus translation is computed by voting on a confusion network . To create the confusion network , we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering The context of a whole document of translations rather than a single sentence is taken into account to produce the alignment . The proposed alignment and large vocabulary task . The method was also tested in the framework of multi-source and speech translation . On all tasks and	USAGE	13	14	E06-1005.7	5	6	E06-1005.6
speech recognition hypotheses , the consensus translation is computed by voting on a confusion network . To create the confusion network , we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering The context of a whole document of translations rather than a single sentence is taken into account to produce the alignment . The proposed alignment and large vocabulary task . The method was also tested in the framework of multi-source and speech translation . On all tasks and	USAGE	36	38	E06-1005.11	25	26	E06-1005.9
speech recognition hypotheses , the consensus translation is computed by voting on a confusion network . To create the confusion network , we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering The context of a whole document of translations rather than a single sentence is taken into account to produce the alignment . The proposed alignment and large vocabulary task . The method was also tested in the framework of multi-source and speech translation . On all tasks and	USAGE	49	49	E06-1005.13	64	64	E06-1005.16
speech recognition hypotheses , the consensus translation is computed by voting on a confusion network . To create the confusion network , we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering The context of a whole document of translations rather than a single sentence is taken into account to produce the alignment . The proposed alignment and large vocabulary task . The method was also tested in the framework of multi-source and speech translation . On all tasks and	USAGE	75	75	E06-1005.20	83	86	E06-1005.21
that recovers Penn Treebank style syntactic analyses of new sentences including skeletal syntactic structure , The accuracy of the first-stage parser on the standard Parseval metric matches that of the ( Collins , 2003 ) parser on which it is based	USAGE	5	6	N06-1024.3	9	9	N06-1024.4
that recovers Penn Treebank style syntactic analyses of new sentences including skeletal syntactic structure , The accuracy of the first-stage parser on the standard Parseval metric matches that of the ( Collins , 2003 ) parser on which it is based	COMPARE	20	20	N06-1024.9	35	35	N06-1024.11
attachment are the most frequent ambiguities in natural language processing . Several methods have been	MODEL-FEATURE	5	5	E95-1041.3	7	9	E95-1041.4
in speaker-independent system , two vocabulary adaptation algorithms [ 5 ] are implemented in order to tailor the VI subword models to the target vocabulary .	USAGE	5	7	H92-1033.4	18	20	H92-1033.5
has been involved with applying natural language processing ( NLP ) technologies to the field of AAC . One of the major of primarily lexical semantics and sentence generation technology to expand telegraphic input into full sentences . While	USAGE	5	11	W97-0503.2	16	16	W97-0503.3
has been involved with applying natural language processing ( NLP ) technologies to the field of AAC . One of the major of primarily lexical semantics and sentence generation technology to expand telegraphic input into full sentences . While	USAGE	27	29	W97-0503.5	32	33	W97-0503.6
entire problem as series of classification problems and employ memory-based learning ( MBL ) to resolve them . Preliminary	USAGE	9	13	W00-1210.3	5	6	W00-1210.2
Speech Synthesis The problem of word segmentation affects all aspects of Chinese language processing , including the development of	PART_WHOLE	5	6	W02-1813.1	11	13	W02-1813.2
the semantic functions performed by adnominal constituents in Japanese , where many parts of , i.e . adjectives and `` noun + NO '' ( in English `` of + noun '' ) structures , which have a broad range of semantic functions , are discussed . This this was verified with a self-organizing semantic map based on a neural network model .	PART_WHOLE	5	6	W00-0110.3	8	8	W00-0110.4
the semantic functions performed by adnominal constituents in Japanese , where many parts of , i.e . adjectives and `` noun + NO '' ( in English `` of + noun '' ) structures , which have a broad range of semantic functions , are discussed . This this was verified with a self-organizing semantic map based on a neural network model .	MODEL-FEATURE	41	42	W00-0110.11	19	33	W00-0110.10
the semantic functions performed by adnominal constituents in Japanese , where many parts of , i.e . adjectives and `` noun + NO '' ( in English `` of + noun '' ) structures , which have a broad range of semantic functions , are discussed . This this was verified with a self-organizing semantic map based on a neural network model .	USAGE	59	61	W00-0110.15	53	55	W00-0110.14
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	USAGE	5	8	J95-1001.2	10	12	J95-1001.3
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	USAGE	29	30	J95-1001.12	23	24	J95-1001.11
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	MODEL-FEATURE	41	41	J95-1001.17	43	43	J95-1001.18
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	MODEL-FEATURE	54	54	J95-1001.21	56	56	J95-1001.22
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	PART_WHOLE	67	68	J95-1001.23	70	70	J95-1001.24
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	MODEL-FEATURE	81	81	J95-1001.26	87	88	J95-1001.27
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	MODEL-FEATURE	99	100	J95-1001.29	108	108	J95-1001.30
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	MODEL-FEATURE	119	119	J95-1001.34	122	124	J95-1001.35
disambiguation explores the application of statistical pattern recognition procedures to lexical co-occurrence data from very large text databases analyze data , but the disambiguation method itself does not employ statistical data or decision criteria . This an experiment discriminating among the senses of adjectives , which have been relatively nouns for discriminating among the senses of adjectives that modify them . This five of the most frequent ambiguous adjectives in English : and About three-quarters of disambiguated almost errorlessly by the nouns they modify or by the syntactic constructions in which they occur . , a small number of semantic attributes supply a compact means of representing the noun clues in a very few are not useable . The sense of an ambiguous modified noun may be needed to determine the relevant semantic attribute for disambiguation of a target adjective ; and other adjectives ,	MODEL-FEATURE	132	133	J95-1001.36	138	139	J95-1001.38
presents our method of incorporating character clustering based on mutual information into Decision-Tree Dictionary-less morphological analysis improved in both tokenizing and tagging Japanese text .	USAGE	9	10	P98-1108.7	5	6	P98-1108.6
presents our method of incorporating character clustering based on mutual information into Decision-Tree Dictionary-less morphological analysis improved in both tokenizing and tagging Japanese text .	USAGE	21	21	P98-1108.12	23	23	P98-1108.14
the recent development of an automatic method for evaluating definition questions based on n-gram overlap , a commonly-used technique in	USAGE	13	14	W05-0906.4	5	10	W05-0906.3
Chinese Word Segmentation SYSTRAN 'S Chinese word segmentation is one important component of its Chinese-English machine translation system . The Chinese word segmentation module uses a rule-based approach , based on a large rules . It works on general-purpose texts from different Chinese-speaking regions , with comparable performance .	PART_WHOLE	5	7	W03-1729.1	14	17	W03-1729.2
Chinese Word Segmentation SYSTRAN 'S Chinese word segmentation is one important component of its Chinese-English machine translation system . The Chinese word segmentation module uses a rule-based approach , based on a large rules . It works on general-purpose texts from different Chinese-speaking regions , with comparable performance .	USAGE	26	27	W03-1729.4	20	22	W03-1729.3
Chinese Word Segmentation SYSTRAN 'S Chinese word segmentation is one important component of its Chinese-English machine translation system . The Chinese word segmentation module uses a rule-based approach , based on a large rules . It works on general-purpose texts from different Chinese-speaking regions , with comparable performance .	MODEL-FEATURE	42	43	W03-1729.8	38	39	W03-1729.7
supervised morphology induction algorithms at morphological analysis of English and German . ParaMor consists hand , ParaMor then annotates word forms with morpheme boundaries . To set ParaMor 's free parameters we analyze a training corpus of Spanish . Without adjusting parameters , we induce the morphological structure of English and German . Adopting the	USAGE	5	6	W07-1315.6	8	8	W07-1315.7
supervised morphology induction algorithms at morphological analysis of English and German . ParaMor consists hand , ParaMor then annotates word forms with morpheme boundaries . To set ParaMor 's free parameters we analyze a training corpus of Spanish . Without adjusting parameters , we induce the morphological structure of English and German . Adopting the	MODEL-FEATURE	22	23	W07-1315.12	19	20	W07-1315.11
supervised morphology induction algorithms at morphological analysis of English and German . ParaMor consists hand , ParaMor then annotates word forms with morpheme boundaries . To set ParaMor 's free parameters we analyze a training corpus of Spanish . Without adjusting parameters , we induce the morphological structure of English and German . Adopting the	PART_WHOLE	37	37	W07-1315.14	34	35	W07-1315.13
supervised morphology induction algorithms at morphological analysis of English and German . ParaMor consists hand , ParaMor then annotates word forms with morpheme boundaries . To set ParaMor 's free parameters we analyze a training corpus of Spanish . Without adjusting parameters , we induce the morphological structure of English and German . Adopting the	MODEL-FEATURE	46	47	W07-1315.15	49	49	W07-1315.16
that we incorporated novel long distance features to address challenges in computing multi-level confidence scores . Using Conditional Maximum Entropy ( CME ) classifier with all the selected features , we reached an annotation error rate of 26.0 % in the	USAGE	5	6	P08-2055.8	12	14	P08-2055.9
that we incorporated novel long distance features to address challenges in computing multi-level confidence scores . Using Conditional Maximum Entropy ( CME ) classifier with all the selected features , we reached an annotation error rate of 26.0 % in the	RESULT	17	23	P08-2055.10	33	35	P08-2055.11
New And Unique Noun Phrases Coreference resolution systems usually attempt to find a suitable antecedent for ( almost ) every noun phrase . Recent studies , however , but also acquire some data from the Internet . Combining our classifiers sequentially , we achieve 88.9 % precision and 84.6 % recall for entities . We expect our classifiers to provide a good prefiltering for coreference resolution systems , improving both their speed	USAGE	5	7	P03-2012.1	20	21	P03-2012.2
New And Unique Noun Phrases Coreference resolution systems usually attempt to find a suitable antecedent for ( almost ) every noun phrase . Recent studies , however , but also acquire some data from the Internet . Combining our classifiers sequentially , we achieve 88.9 % precision and 84.6 % recall for entities . We expect our classifiers to provide a good prefiltering for coreference resolution systems , improving both their speed	PART_WHOLE	32	32	P03-2012.8	35	35	P03-2012.9
New And Unique Noun Phrases Coreference resolution systems usually attempt to find a suitable antecedent for ( almost ) every noun phrase . Recent studies , however , but also acquire some data from the Internet . Combining our classifiers sequentially , we achieve 88.9 % precision and 84.6 % recall for entities . We expect our classifiers to provide a good prefiltering for coreference resolution systems , improving both their speed	RESULT	39	39	P03-2012.10	46	46	P03-2012.11
New And Unique Noun Phrases Coreference resolution systems usually attempt to find a suitable antecedent for ( almost ) every noun phrase . Recent studies , however , but also acquire some data from the Internet . Combining our classifiers sequentially , we achieve 88.9 % precision and 84.6 % recall for entities . We expect our classifiers to provide a good prefiltering for coreference resolution systems , improving both their speed	USAGE	57	57	P03-2012.14	64	66	P03-2012.15
algorithm . MBDP-1 is a knowledge-free segmentation algorithm that bootstraps its own lexicon , which starts out empty	USAGE	5	7	P01-1013.3	12	12	P01-1013.4
inspect , and modify any case frame information associated with the words and phrases known to the	MODEL-FEATURE	5	7	C86-1108.2	11	11	C86-1108.3
The number and sizes of parallel corpora keep growing , which makes it necessary to have automatic methods of processing them : combining , checking and improving corpora quality , etc . We here documents , different levels of segmentation of the input corpora , encoding differences and other the first experiment , the Estonian-English part of the JRC-Acquis corpus was combined with another corpus of legislation texts . In the second experiment	MODEL-FEATURE	27	28	L08-1114.2	5	6	L08-1114.1
The number and sizes of parallel corpora keep growing , which makes it necessary to have automatic methods of processing them : combining , checking and improving corpora quality , etc . We here documents , different levels of segmentation of the input corpora , encoding differences and other the first experiment , the Estonian-English part of the JRC-Acquis corpus was combined with another corpus of legislation texts . In the second experiment	USAGE	39	39	L08-1114.10	42	43	L08-1114.11
The number and sizes of parallel corpora keep growing , which makes it necessary to have automatic methods of processing them : combining , checking and improving corpora quality , etc . We here documents , different levels of segmentation of the input corpora , encoding differences and other the first experiment , the Estonian-English part of the JRC-Acquis corpus was combined with another corpus of legislation texts . In the second experiment	PART_WHOLE	54	54	L08-1114.12	58	59	L08-1114.13
The number and sizes of parallel corpora keep growing , which makes it necessary to have automatic methods of processing them : combining , checking and improving corpora quality , etc . We here documents , different levels of segmentation of the input corpora , encoding differences and other the first experiment , the Estonian-English part of the JRC-Acquis corpus was combined with another corpus of legislation texts . In the second experiment	PART_WHOLE	66	67	L08-1114.15	64	64	L08-1114.14
between animated agents . The generation module supports the seamless integration of full grammar rules , templates and canned text	USAGE	13	14	E03-1019.6	5	6	E03-1019.5
Analysis Selection In Inflectional Languages Ambiguity is the fundamental property of natural language . Perhaps , the most burdensome case of ambiguity manifests itself on the syntactic level of analysis . In order to face presented methods are based on language specific features of synthetical languages and they improve the results	MODEL-FEATURE	5	5	C02-1079.1	11	12	C02-1079.2
Analysis Selection In Inflectional Languages Ambiguity is the fundamental property of natural language . Perhaps , the most burdensome case of ambiguity manifests itself on the syntactic level of analysis . In order to face presented methods are based on language specific features of synthetical languages and they improve the results	MODEL-FEATURE	21	21	C02-1079.3	26	29	C02-1079.4
Analysis Selection In Inflectional Languages Ambiguity is the fundamental property of natural language . Perhaps , the most burdensome case of ambiguity manifests itself on the syntactic level of analysis . In order to face presented methods are based on language specific features of synthetical languages and they improve the results	MODEL-FEATURE	40	42	C02-1079.7	44	45	C02-1079.8
reminiscing about photographs . The texts are in English and Czech . We describe	MODEL-FEATURE	5	5	L08-1197.3	8	8	L08-1197.4
This paper presents techniques for multimedia annotation and their application to video summarization and translation . Our tool for annotation identification and recognition . A video scene description consists of semi-automatically detected keyframes of each scene in a in video scenes . The text data in the multimedia annotation are syntactically and semantically structured using linguistic annotation . The proposed multimedia summarization works upon a multimodal document that consists of a video automatically generates several versions of multimedia content in different languages .	USAGE	5	6	C02-1098.2	11	14	C02-1098.3
This paper presents techniques for multimedia annotation and their application to video summarization and translation . Our tool for annotation identification and recognition . A video scene description consists of semi-automatically detected keyframes of each scene in a in video scenes . The text data in the multimedia annotation are syntactically and semantically structured using linguistic annotation . The proposed multimedia summarization works upon a multimodal document that consists of a video automatically generates several versions of multimedia content in different languages .	PART_WHOLE	30	32	C02-1098.12	25	27	C02-1098.11
This paper presents techniques for multimedia annotation and their application to video summarization and translation . Our tool for annotation identification and recognition . A video scene description consists of semi-automatically detected keyframes of each scene in a in video scenes . The text data in the multimedia annotation are syntactically and semantically structured using linguistic annotation . The proposed multimedia summarization works upon a multimodal document that consists of a video automatically generates several versions of multimedia content in different languages .	MODEL-FEATURE	43	44	C02-1098.14	50	53	C02-1098.16
This paper presents techniques for multimedia annotation and their application to video summarization and translation . Our tool for annotation identification and recognition . A video scene description consists of semi-automatically detected keyframes of each scene in a in video scenes . The text data in the multimedia annotation are syntactically and semantically structured using linguistic annotation . The proposed multimedia summarization works upon a multimodal document that consists of a video automatically generates several versions of multimedia content in different languages .	USAGE	60	61	C02-1098.18	65	66	C02-1098.19
This paper presents techniques for multimedia annotation and their application to video summarization and translation . Our tool for annotation identification and recognition . A video scene description consists of semi-automatically detected keyframes of each scene in a in video scenes . The text data in the multimedia annotation are syntactically and semantically structured using linguistic annotation . The proposed multimedia summarization works upon a multimodal document that consists of a video automatically generates several versions of multimedia content in different languages .	MODEL-FEATURE	81	81	C02-1098.26	77	78	C02-1098.25
Knowledge Using Translation Literalness When machine translation ( MT ) knowledge is automatically constructed from bilingual corpora , redundant rules are acquired to translation variety . These rules increase ambiguity or cause incorrect MT results problem , we constrain the sentences used for knowledge extraction to `` the appropriate bilingual sentences for the MT `` . In this paper	USAGE	15	16	E03-1029.2	5	10	E03-1029.1
Knowledge Using Translation Literalness When machine translation ( MT ) knowledge is automatically constructed from bilingual corpora , redundant rules are acquired to translation variety . These rules increase ambiguity or cause incorrect MT results problem , we constrain the sentences used for knowledge extraction to `` the appropriate bilingual sentences for the MT `` . In this paper	RESULT	27	27	E03-1029.4	29	29	E03-1029.5
Knowledge Using Translation Literalness When machine translation ( MT ) knowledge is automatically constructed from bilingual corpora , redundant rules are acquired to translation variety . These rules increase ambiguity or cause incorrect MT results problem , we constrain the sentences used for knowledge extraction to `` the appropriate bilingual sentences for the MT `` . In this paper	USAGE	40	40	E03-1029.7	43	44	E03-1029.8
Knowledge Using Translation Literalness When machine translation ( MT ) knowledge is automatically constructed from bilingual corpora , redundant rules are acquired to translation variety . These rules increase ambiguity or cause incorrect MT results problem , we constrain the sentences used for knowledge extraction to `` the appropriate bilingual sentences for the MT `` . In this paper	USAGE	49	50	E03-1029.9	53	53	E03-1029.10
For the creation of these scholarly digital editions the AAC edition philosophy and edition principles have been applied whereby new	USAGE	9	14	L08-1405.9	5	7	L08-1405.8
The evaluation results show our system can achieve an F measure of 0.9400.967 for different testing	RESULT	5	5	I05-3026.5	9	10	I05-3026.6
paper , we propose a machine learning algorithm for shallow semantic parsing , extending the work of ) and others . Our algorithm is based on Support Vector Machines which we show give an to generalize to a new test set drawn from the AQUAINT corpus .	USAGE	5	7	N04-1030.1	9	11	N04-1030.2
paper , we propose a machine learning algorithm for shallow semantic parsing , extending the work of ) and others . Our algorithm is based on Support Vector Machines which we show give an to generalize to a new test set drawn from the AQUAINT corpus .	USAGE	26	28	N04-1030.4	22	22	N04-1030.3
paper , we propose a machine learning algorithm for shallow semantic parsing , extending the work of ) and others . Our algorithm is based on Support Vector Machines which we show give an to generalize to a new test set drawn from the AQUAINT corpus .	PART_WHOLE	39	40	N04-1030.7	44	45	N04-1030.8
Many of the kinds of language model used in speech understanding suffer from imperfect modeling of be addressed by clustering the sentences in a training corpus automatically into sub corpora on cluster . This kind of clustering offers a way to represent important contextual effects and can therefore significantly improve to develop it : if clustering improves the performance of a model , this proves the existence I present results showing that clustering improves some models but not others for the	USAGE	5	6	A94-1010.1	9	10	A94-1010.2
Many of the kinds of language model used in speech understanding suffer from imperfect modeling of be addressed by clustering the sentences in a training corpus automatically into sub corpora on cluster . This kind of clustering offers a way to represent important contextual effects and can therefore significantly improve to develop it : if clustering improves the performance of a model , this proves the existence I present results showing that clustering improves some models but not others for the	PART_WHOLE	21	21	A94-1010.5	24	25	A94-1010.6
Many of the kinds of language model used in speech understanding suffer from imperfect modeling of be addressed by clustering the sentences in a training corpus automatically into sub corpora on cluster . This kind of clustering offers a way to represent important contextual effects and can therefore significantly improve to develop it : if clustering improves the performance of a model , this proves the existence I present results showing that clustering improves some models but not others for the	MODEL-FEATURE	36	36	A94-1010.11	43	44	A94-1010.12
Many of the kinds of language model used in speech understanding suffer from imperfect modeling of be addressed by clustering the sentences in a training corpus automatically into sub corpora on cluster . This kind of clustering offers a way to represent important contextual effects and can therefore significantly improve to develop it : if clustering improves the performance of a model , this proves the existence I present results showing that clustering improves some models but not others for the	RESULT	55	55	A94-1010.16	61	61	A94-1010.17
Many of the kinds of language model used in speech understanding suffer from imperfect modeling of be addressed by clustering the sentences in a training corpus automatically into sub corpora on cluster . This kind of clustering offers a way to represent important contextual effects and can therefore significantly improve to develop it : if clustering improves the performance of a model , this proves the existence I present results showing that clustering improves some models but not others for the	RESULT	72	72	A94-1010.20	75	75	A94-1010.21
Patterns This paper presents a parsing system for the detection of syntactic errors . It combines a robust main sentence components and a finite-state parser used for the description of syntactic error patterns . The system has been tested on a corpus of real texts , containing both correct and	USAGE	5	6	A00-3005.1	9	12	A00-3005.2
Patterns This paper presents a parsing system for the detection of syntactic errors . It combines a robust main sentence components and a finite-state parser used for the description of syntactic error patterns . The system has been tested on a corpus of real texts , containing both correct and	USAGE	23	24	A00-3005.5	30	32	A00-3005.6
Patterns This paper presents a parsing system for the detection of syntactic errors . It combines a robust main sentence components and a finite-state parser used for the description of syntactic error patterns . The system has been tested on a corpus of real texts , containing both correct and	PART_WHOLE	44	44	A00-3005.9	41	41	A00-3005.8
of the merits of current text analysis techniques , as applied to the performance of realistic text analysis tasks , and to achieve this	USAGE	5	7	H92-1111.1	15	18	H92-1111.3
in arbitrary order , ask questions , etc. , in general spoken English . The system operates according to a plan-based agenda mechanism , rather than a finite	MODEL-FEATURE	10	12	A00-1010.8	5	5	A00-1010.7
in arbitrary order , ask questions , etc. , in general spoken English . The system operates according to a plan-based agenda mechanism , rather than a finite	USAGE	20	22	A00-1010.10	15	15	A00-1010.9
1996 ) , solving the anaphora and extracting the antecedent are key issues in a correct translation . In this paper , . The SS stores the lexical , syntactic , morphologic and semantic information of every constituent of the grammar . The between two languages . This mechanism could be added to a MT system such as an additional module	PART_WHOLE	5	5	W99-0210.3	16	16	W99-0210.5
1996 ) , solving the anaphora and extracting the antecedent are key issues in a correct translation . In this paper , . The SS stores the lexical , syntactic , morphologic and semantic information of every constituent of the grammar . The between two languages . This mechanism could be added to a MT system such as an additional module	MODEL-FEATURE	27	34	W99-0210.10	37	37	W99-0210.11
1996 ) , solving the anaphora and extracting the antecedent are key issues in a correct translation . In this paper , . The SS stores the lexical , syntactic , morphologic and semantic information of every constituent of the grammar . The between two languages . This mechanism could be added to a MT system such as an additional module	USAGE	48	48	W99-0210.23	54	55	W99-0210.24
infrastructure issues by considering whether standard V & V methods are fundamentally different than the evaluation practices commonly used for NLP systems proposes practical approaches for applying V & V in the context of language processing systems . We argue that evaluation	COMPARE	5	9	W01-0906.6	15	16	W01-0906.7
infrastructure issues by considering whether standard V & V methods are fundamentally different than the evaluation practices commonly used for NLP systems proposes practical approaches for applying V & V in the context of language processing systems . We argue that evaluation	USAGE	27	29	W01-0906.9	34	36	W01-0906.10
for extracting the most relevant paragraphs from the original document to form a summary for Thai text . The idea of our is to exploit both the local and global properties of paragraphs . The local property can be considered as clusters of significant words within each paragraph , while	PART_WHOLE	5	5	W03-1102.1	9	9	W03-1102.2
for extracting the most relevant paragraphs from the original document to form a summary for Thai text . The idea of our is to exploit both the local and global properties of paragraphs . The local property can be considered as clusters of significant words within each paragraph , while	MODEL-FEATURE	13	13	W03-1102.3	15	16	W03-1102.4
for extracting the most relevant paragraphs from the original document to form a summary for Thai text . The idea of our is to exploit both the local and global properties of paragraphs . The local property can be considered as clusters of significant words within each paragraph , while	MODEL-FEATURE	27	30	W03-1102.5	32	32	W03-1102.6
for extracting the most relevant paragraphs from the original document to form a summary for Thai text . The idea of our is to exploit both the local and global properties of paragraphs . The local property can be considered as clusters of significant words within each paragraph , while	MODEL-FEATURE	41	41	W03-1102.8	43	44	W03-1102.9
Feature-Rich Grammars in Machine Translation Syntax-based Machine Translation systems have recently become a focus of research with much hope that they will outperform traditional Phrase- Based Statistical Machine Translation ( PBSMT ) . Toward this goal , a method for analyzing the morphosyntactic content of language from an Elicitation Corpus such as the one included this tool that can augment structure-based MT models with these rich features , we believe the discriminative	COMPARE	5	8	W08-0410.1	23	31	W08-0410.2
Feature-Rich Grammars in Machine Translation Syntax-based Machine Translation systems have recently become a focus of research with much hope that they will outperform traditional Phrase- Based Statistical Machine Translation ( PBSMT ) . Toward this goal , a method for analyzing the morphosyntactic content of language from an Elicitation Corpus such as the one included this tool that can augment structure-based MT models with these rich features , we believe the discriminative	PART_WHOLE	42	43	W08-0410.3	48	49	W08-0410.5
Feature-Rich Grammars in Machine Translation Syntax-based Machine Translation systems have recently become a focus of research with much hope that they will outperform traditional Phrase- Based Statistical Machine Translation ( PBSMT ) . Toward this goal , a method for analyzing the morphosyntactic content of language from an Elicitation Corpus such as the one included this tool that can augment structure-based MT models with these rich features , we believe the discriminative	USAGE	65	66	W08-0410.12	60	62	W08-0410.11
? This article outlines a quantitative method for segmenting texts into thematically coherent units . This method relies on a network of lexical collocations to compute the thematic coherence of a text from the lexical cohesiveness of their words . We also present the of an experiment about locating boundaries between a series of concatened texts .	USAGE	5	6	P98-2243.1	9	9	P98-2243.2
? This article outlines a quantitative method for segmenting texts into thematically coherent units . This method relies on a network of lexical collocations to compute the thematic coherence of a text from the lexical cohesiveness of their words . We also present the of an experiment about locating boundaries between a series of concatened texts .	USAGE	20	23	P98-2243.5	16	16	P98-2243.4
? This article outlines a quantitative method for segmenting texts into thematically coherent units . This method relies on a network of lexical collocations to compute the thematic coherence of a text from the lexical cohesiveness of their words . We also present the of an experiment about locating boundaries between a series of concatened texts .	MODEL-FEATURE	34	35	P98-2243.8	38	38	P98-2243.9
? This article outlines a quantitative method for segmenting texts into thematically coherent units . This method relies on a network of lexical collocations to compute the thematic coherence of a text from the lexical cohesiveness of their words . We also present the of an experiment about locating boundaries between a series of concatened texts .	PART_WHOLE	49	49	P98-2243.10	55	55	P98-2243.11
work , we introduce a model for sense assignment which relies on assigning senses to the contexts within which words appear , rather than to	USAGE	5	5	W04-1908.1	7	8	W04-1908.2
work , we introduce a model for sense assignment which relies on assigning senses to the contexts within which words appear , rather than to	MODEL-FEATURE	19	19	W04-1908.5	16	16	W04-1908.4
this paper we describe a morphological analysis method based on a maximum entropy model . This method uses a model that can not only consult a dictionary with a large amount of lexical information but can also identify unknown words by learning certain characteristics . The model has the	USAGE	11	13	W01-0512.2	5	7	W01-0512.1
this paper we describe a morphological analysis method based on a maximum entropy model . This method uses a model that can not only consult a dictionary with a large amount of lexical information but can also identify unknown words by learning certain characteristics . The model has the	USAGE	19	19	W01-0512.4	16	16	W01-0512.3
this paper we describe a morphological analysis method based on a maximum entropy model . This method uses a model that can not only consult a dictionary with a large amount of lexical information but can also identify unknown words by learning certain characteristics . The model has the	PART_WHOLE	32	33	W01-0512.6	26	26	W01-0512.5
this paper we describe a morphological analysis method based on a maximum entropy model . This method uses a model that can not only consult a dictionary with a large amount of lexical information but can also identify unknown words by learning certain characteristics . The model has the	MODEL-FEATURE	43	43	W01-0512.8	38	39	W01-0512.7
which was designed for collecting corpus from RSS feeds .	PART_WHOLE	5	5	W06-1707.10	7	8	W06-1707.11
a query-focused summary . Several SVMs are trained using information from pyramids of summary content units . Their performance is compared with the best performing systems in DUC-2005 , using both ROUGE and autoPan , an automatic scoring method for pyramid evaluation .	USAGE	13	15	P07-2015.4	5	5	P07-2015.3
a query-focused summary . Several SVMs are trained using information from pyramids of summary content units . Their performance is compared with the best performing systems in DUC-2005 , using both ROUGE and autoPan , an automatic scoring method for pyramid evaluation .	COMPARE	18	18	P07-2015.5	27	27	P07-2015.6
a query-focused summary . Several SVMs are trained using information from pyramids of summary content units . Their performance is compared with the best performing systems in DUC-2005 , using both ROUGE and autoPan , an automatic scoring method for pyramid evaluation .	USAGE	36	38	P07-2015.9	40	41	P07-2015.10
Compression We present a novel unsupervised method for sentence compression which relies on a dependency that the choice of the parser affects the performance of the system . We also apply the method to German and report the results of	USAGE	5	6	W08-1105.1	8	9	W08-1105.2
Compression We present a novel unsupervised method for sentence compression which relies on a dependency that the choice of the parser affects the performance of the system . We also apply the method to German and report the results of	RESULT	20	20	W08-1105.8	23	23	W08-1105.9
Compression We present a novel unsupervised method for sentence compression which relies on a dependency that the choice of the parser affects the performance of the system . We also apply the method to German and report the results of	USAGE	32	32	W08-1105.11	34	34	W08-1105.12
the hand coded system on NER in Spanish , and it achieved high	USAGE	5	5	P05-2005.5	7	7	P05-2005.6
A karaka based approach to parsing of Indian languages is described . It has been used for building a parser of Hindi for a prototype Machine Translation	USAGE	5	5	C90-3005.2	7	8	C90-3005.3
A karaka based approach to parsing of Indian languages is described . It has been used for building a parser of Hindi for a prototype Machine Translation	USAGE	19	19	C90-3005.4	21	21	C90-3005.5
presents our work on the detection of temporal information in web pages . The pages examined within the scope of this study were taken from the tourism sector and the temporal information in question is thus particular The differences that exist between extraction from plain textual data and extraction from the web information . We adopt a symbolic approach relying on patterns and rules for the detection , extraction and annotation of temporal expressions ; our method is based	USAGE	5	5	L08-1559.1	10	11	L08-1559.3
presents our work on the detection of temporal information in web pages . The pages examined within the scope of this study were taken from the tourism sector and the temporal information in question is thus particular The differences that exist between extraction from plain textual data and extraction from the web information . We adopt a symbolic approach relying on patterns and rules for the detection , extraction and annotation of temporal expressions ; our method is based	PART_WHOLE	30	31	L08-1559.5	14	14	L08-1559.4
presents our work on the detection of temporal information in web pages . The pages examined within the scope of this study were taken from the tourism sector and the temporal information in question is thus particular The differences that exist between extraction from plain textual data and extraction from the web information . We adopt a symbolic approach relying on patterns and rules for the detection , extraction and annotation of temporal expressions ; our method is based	USAGE	42	42	L08-1559.6	44	46	L08-1559.7
presents our work on the detection of temporal information in web pages . The pages examined within the scope of this study were taken from the tourism sector and the temporal information in question is thus particular The differences that exist between extraction from plain textual data and extraction from the web information . We adopt a symbolic approach relying on patterns and rules for the detection , extraction and annotation of temporal expressions ; our method is based	USAGE	61	61	L08-1559.16	57	58	L08-1559.15
presents our work on the detection of temporal information in web pages . The pages examined within the scope of this study were taken from the tourism sector and the temporal information in question is thus particular The differences that exist between extraction from plain textual data and extraction from the web information . We adopt a symbolic approach relying on patterns and rules for the detection , extraction and annotation of temporal expressions ; our method is based	USAGE	63	63	L08-1559.17	66	66	L08-1559.18
presents our work on the detection of temporal information in web pages . The pages examined within the scope of this study were taken from the tourism sector and the temporal information in question is thus particular The differences that exist between extraction from plain textual data and extraction from the web information . We adopt a symbolic approach relying on patterns and rules for the detection , extraction and annotation of temporal expressions ; our method is based	USAGE	70	70	L08-1559.20	72	73	L08-1559.21
The first release of the German Ph @ ttSessionz speech database contains read and spontaneous speech from 864 adolescent speakers and paper , we present a cross-sectional study of f0 measurements on this database . The is little difference in the relative f0 variability for male and female speakers . A closer analysis reveals The study provides statistically reliable voice parameters of adolescent speakers for German . The results systems more robust by restricting user input to utterances with low f0 variability .	PART_WHOLE	12	15	L08-1196.2	5	10	L08-1196.1
The first release of the German Ph @ ttSessionz speech database contains read and spontaneous speech from 864 adolescent speakers and paper , we present a cross-sectional study of f0 measurements on this database . The is little difference in the relative f0 variability for male and female speakers . A closer analysis reveals The study provides statistically reliable voice parameters of adolescent speakers for German . The results systems more robust by restricting user input to utterances with low f0 variability .	TOPIC	26	27	L08-1196.7	29	30	L08-1196.8
The first release of the German Ph @ ttSessionz speech database contains read and spontaneous speech from 864 adolescent speakers and paper , we present a cross-sectional study of f0 measurements on this database . The is little difference in the relative f0 variability for male and female speakers . A closer analysis reveals The study provides statistically reliable voice parameters of adolescent speakers for German . The results systems more robust by restricting user input to utterances with low f0 variability .	MODEL-FEATURE	41	43	L08-1196.11	45	48	L08-1196.12
The first release of the German Ph @ ttSessionz speech database contains read and spontaneous speech from 864 adolescent speakers and paper , we present a cross-sectional study of f0 measurements on this database . The is little difference in the relative f0 variability for male and female speakers . A closer analysis reveals The study provides statistically reliable voice parameters of adolescent speakers for German . The results systems more robust by restricting user input to utterances with low f0 variability .	MODEL-FEATURE	59	60	L08-1196.17	62	63	L08-1196.18
The first release of the German Ph @ ttSessionz speech database contains read and spontaneous speech from 864 adolescent speakers and paper , we present a cross-sectional study of f0 measurements on this database . The is little difference in the relative f0 variability for male and female speakers . A closer analysis reveals The study provides statistically reliable voice parameters of adolescent speakers for German . The results systems more robust by restricting user input to utterances with low f0 variability .	PART_WHOLE	77	77	L08-1196.22	74	75	L08-1196.21
and information communities . The platform will support researchers and engineers with well-developed and standardized resources and application tools thereby avoiding	USAGE	14	15	C96-2185.9	5	5	C96-2185.8
, as a part of aspectual operation system , a generation system of iterative expressions using a especially in consideration of the durative / non-durative character of the denoted events and also in consideration of	PART_WHOLE	10	11	E83-1003.2	5	7	E83-1003.1
, as a part of aspectual operation system , a generation system of iterative expressions using a especially in consideration of the durative / non-durative character of the denoted events and also in consideration of	MODEL-FEATURE	22	25	E83-1003.11	29	29	E83-1003.12
paper , we show that time-synchronous one-pass decoding using cross-word triphones and a trigram language model can be implemented using a dynamically built tree-structured network . This approach avoids the It was included in the HTK large vocabulary speech recognition system used for the 1993 ARPA WSJ evaluation and experimental results are presented	USAGE	9	10	H94-1080.16	5	7	H94-1080.15
paper , we show that time-synchronous one-pass decoding using cross-word triphones and a trigram language model can be implemented using a dynamically built tree-structured network . This approach avoids the It was included in the HTK large vocabulary speech recognition system used for the 1993 ARPA WSJ evaluation and experimental results are presented	USAGE	23	24	H94-1080.18	13	15	H94-1080.17
paper , we show that time-synchronous one-pass decoding using cross-word triphones and a trigram language model can be implemented using a dynamically built tree-structured network . This approach avoids the It was included in the HTK large vocabulary speech recognition system used for the 1993 ARPA WSJ evaluation and experimental results are presented	USAGE	35	40	H94-1080.20	44	47	H94-1080.21
using Comparable Corpora Traditionally , statistical machine translation systems have relied on parallel bi-lingual data to train a translation model . While bi-lingual parallel data are expensive to generate , monolingual data are relatively common . Yet monolingual data have been under-utilized , having been used primarily for training a language model in the target language . a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories . The target language is searched for documents that might be comparable to the source documents . These documents are then used to adapt the MT system to increase the probability of obtained by adapting both the language and translation models show substantial gains over the baseline system .	USAGE	12	14	D08-1090.2	5	8	D08-1090.1
using Comparable Corpora Traditionally , statistical machine translation systems have relied on parallel bi-lingual data to train a translation model . While bi-lingual parallel data are expensive to generate , monolingual data are relatively common . Yet monolingual data have been under-utilized , having been used primarily for training a language model in the target language . a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories . The target language is searched for documents that might be comparable to the source documents . These documents are then used to adapt the MT system to increase the probability of obtained by adapting both the language and translation models show substantial gains over the baseline system .	COMPARE	22	24	D08-1090.4	30	31	D08-1090.5
using Comparable Corpora Traditionally , statistical machine translation systems have relied on parallel bi-lingual data to train a translation model . While bi-lingual parallel data are expensive to generate , monolingual data are relatively common . Yet monolingual data have been under-utilized , having been used primarily for training a language model in the target language . a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories . The target language is searched for documents that might be comparable to the source documents . These documents are then used to adapt the MT system to increase the probability of obtained by adapting both the language and translation models show substantial gains over the baseline system .	USAGE	37	38	D08-1090.6	50	51	D08-1090.7
using Comparable Corpora Traditionally , statistical machine translation systems have relied on parallel bi-lingual data to train a translation model . While bi-lingual parallel data are expensive to generate , monolingual data are relatively common . Yet monolingual data have been under-utilized , having been used primarily for training a language model in the target language . a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories . The target language is searched for documents that might be comparable to the source documents . These documents are then used to adapt the MT system to increase the probability of obtained by adapting both the language and translation models show substantial gains over the baseline system .	USAGE	62	64	D08-1090.9	71	74	D08-1090.10
using Comparable Corpora Traditionally , statistical machine translation systems have relied on parallel bi-lingual data to train a translation model . While bi-lingual parallel data are expensive to generate , monolingual data are relatively common . Yet monolingual data have been under-utilized , having been used primarily for training a language model in the target language . a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories . The target language is searched for documents that might be comparable to the source documents . These documents are then used to adapt the MT system to increase the probability of obtained by adapting both the language and translation models show substantial gains over the baseline system .	COMPARE	85	85	D08-1090.18	92	93	D08-1090.19
using Comparable Corpora Traditionally , statistical machine translation systems have relied on parallel bi-lingual data to train a translation model . While bi-lingual parallel data are expensive to generate , monolingual data are relatively common . Yet monolingual data have been under-utilized , having been used primarily for training a language model in the target language . a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories . The target language is searched for documents that might be comparable to the source documents . These documents are then used to adapt the MT system to increase the probability of obtained by adapting both the language and translation models show substantial gains over the baseline system .	USAGE	96	96	D08-1090.20	103	104	D08-1090.21
using Comparable Corpora Traditionally , statistical machine translation systems have relied on parallel bi-lingual data to train a translation model . While bi-lingual parallel data are expensive to generate , monolingual data are relatively common . Yet monolingual data have been under-utilized , having been used primarily for training a language model in the target language . a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories . The target language is searched for documents that might be comparable to the source documents . These documents are then used to adapt the MT system to increase the probability of obtained by adapting both the language and translation models show substantial gains over the baseline system .	COMPARE	115	118	D08-1090.23	124	125	D08-1090.24
of senses in which an ambiguous word is used in a large corpus . It is based on	PART_WHOLE	5	6	E06-2007.3	12	12	E06-2007.4
text understanding system , a system based upon a three-tiered approach to text processing in which this precluded the integration of Pundit into the prototype .	USAGE	9	10	M91-1032.3	5	5	M91-1032.2
text understanding system , a system based upon a three-tiered approach to text processing in which this precluded the integration of Pundit into the prototype .	PART_WHOLE	21	21	M91-1032.23	24	24	M91-1032.24
program that extracts assertions about macromolecular binding relationships from biomedical text . We describe the domain discussing a formal evaluation of ARBITER , we report on its application to 491,000 MEDLINE abstracts , during which almost 25,000 suitable for entry into a database of macro-molecular function were extracted .	PART_WHOLE	5	7	A00-1026.3	9	10	A00-1026.4
program that extracts assertions about macromolecular binding relationships from biomedical text . We describe the domain discussing a formal evaluation of ARBITER , we report on its application to 491,000 MEDLINE abstracts , during which almost 25,000 suitable for entry into a database of macro-molecular function were extracted .	USAGE	21	21	A00-1026.8	30	31	A00-1026.9
program that extracts assertions about macromolecular binding relationships from biomedical text . We describe the domain discussing a formal evaluation of ARBITER , we report on its application to 491,000 MEDLINE abstracts , during which almost 25,000 suitable for entry into a database of macro-molecular function were extracted .	PART_WHOLE	44	45	A00-1026.12	42	42	A00-1026.11
Simulated Annealing The resolution of lexical ambiguity is important for most natural language processing tasks , and a range of we describe a method for lexical disambiguation of text using the definitions in a machine-readable dictionary together fully automatic method requires no hand coding of lexical entries , or hand tagging of text .	PART_WHOLE	5	6	H92-1046.2	11	14	H92-1046.3
Simulated Annealing The resolution of lexical ambiguity is important for most natural language processing tasks , and a range of we describe a method for lexical disambiguation of text using the definitions in a machine-readable dictionary together fully automatic method requires no hand coding of lexical entries , or hand tagging of text .	USAGE	31	31	H92-1046.7	25	26	H92-1046.5
Simulated Annealing The resolution of lexical ambiguity is important for most natural language processing tasks , and a range of we describe a method for lexical disambiguation of text using the definitions in a machine-readable dictionary together fully automatic method requires no hand coding of lexical entries , or hand tagging of text .	USAGE	42	43	H92-1046.23	45	46	H92-1046.24
Simulated Annealing The resolution of lexical ambiguity is important for most natural language processing tasks , and a range of we describe a method for lexical disambiguation of text using the definitions in a machine-readable dictionary together fully automatic method requires no hand coding of lexical entries , or hand tagging of text .	USAGE	49	50	H92-1046.25	52	52	H92-1046.26
date , this array of formal and natural language processing technologies has been used to perform mass changes to legacy textual databases and to facilitate user interfacing	USAGE	5	10	W97-0909.3	19	21	W97-0909.4
work aimed at constructing a parallel corpus of Rhetorical Structure trees for a collection of Japanese	PART_WHOLE	8	10	W00-1403.3	5	6	W00-1403.2
Dialogue Systems The approach to knowledge representation taken in a multi-modal multi-domain dialogue system - SmartKom - is presented . We focus	USAGE	5	6	W03-0903.1	10	16	W03-0903.2
reasoning , focusing on solving logic puzzles drawn from sources such as the Law School Admission Test ( LSAT ) and the analytic section of and discuss the representations and performance of the prototype system .	PART_WHOLE	5	6	W04-0902.5	13	19	W04-0902.6
reasoning , focusing on solving logic puzzles drawn from sources such as the Law School Admission Test ( LSAT ) and the analytic section of and discuss the representations and performance of the prototype system .	MODEL-FEATURE	30	30	W04-0902.9	33	34	W04-0902.10
this paper , a new parsing model is proposed to formulate the complete chunking problem as a series of boundary detection subtasks . By applying SVM algorithm to these subtasks , we have achieved the best F-Score of 76.56 % and 82.26	MODEL-FEATURE	13	14	W06-0113.11	5	6	W06-0113.10
this paper , a new parsing model is proposed to formulate the complete chunking problem as a series of boundary detection subtasks . By applying SVM algorithm to these subtasks , we have achieved the best F-Score of 76.56 % and 82.26	RESULT	25	26	W06-0113.17	36	36	W06-0113.18
and content of WordNet with co-occurrence information derived from raw text . We use the co-occurrence the WordNet definitions to build gloss vectors corresponding to each concept in WordNet . Numeric scores of relatedness are assigned to a pair of concepts by measuring the cosine of well when used in a word sense disambiguation algorithm that relies on semantic relatedness . This measure is flexible different domains , since any plain text corpus can be used to derive the co–occurrence information .	PART_WHOLE	5	6	W06-2501.4	9	10	W06-2501.5
and content of WordNet with co-occurrence information derived from raw text . We use the co-occurrence the WordNet definitions to build gloss vectors corresponding to each concept in WordNet . Numeric scores of relatedness are assigned to a pair of concepts by measuring the cosine of well when used in a word sense disambiguation algorithm that relies on semantic relatedness . This measure is flexible different domains , since any plain text corpus can be used to derive the co–occurrence information .	MODEL-FEATURE	21	22	W06-2501.8	26	26	W06-2501.9
and content of WordNet with co-occurrence information derived from raw text . We use the co-occurrence the WordNet definitions to build gloss vectors corresponding to each concept in WordNet . Numeric scores of relatedness are assigned to a pair of concepts by measuring the cosine of well when used in a word sense disambiguation algorithm that relies on semantic relatedness . This measure is flexible different domains , since any plain text corpus can be used to derive the co–occurrence information .	MODEL-FEATURE	30	33	W06-2501.11	40	40	W06-2501.12
and content of WordNet with co-occurrence information derived from raw text . We use the co-occurrence the WordNet definitions to build gloss vectors corresponding to each concept in WordNet . Numeric scores of relatedness are assigned to a pair of concepts by measuring the cosine of well when used in a word sense disambiguation algorithm that relies on semantic relatedness . This measure is flexible different domains , since any plain text corpus can be used to derive the co–occurrence information .	USAGE	58	59	W06-2501.18	51	54	W06-2501.17
and content of WordNet with co-occurrence information derived from raw text . We use the co-occurrence the WordNet definitions to build gloss vectors corresponding to each concept in WordNet . Numeric scores of relatedness are assigned to a pair of concepts by measuring the cosine of well when used in a word sense disambiguation algorithm that relies on semantic relatedness . This measure is flexible different domains , since any plain text corpus can be used to derive the co–occurrence information .	PART_WHOLE	79	80	W06-2501.23	70	72	W06-2501.22
Inference This paper describes our system as used in the RTE3 task . The system maps premise and hypothesis pairs into an abstract knowledge representation ( AKR ) and then performs entailment and AKRs . Two versions of ECD were used in RTE3 , one with strict ECD	USAGE	5	5	W07-1403.1	10	11	W07-1403.2
Inference This paper describes our system as used in the RTE3 task . The system maps premise and hypothesis pairs into an abstract knowledge representation ( AKR ) and then performs entailment and AKRs . Two versions of ECD were used in RTE3 , one with strict ECD	MODEL-FEATURE	22	27	W07-1403.5	16	19	W07-1403.4
Inference This paper describes our system as used in the RTE3 task . The system maps premise and hypothesis pairs into an abstract knowledge representation ( AKR ) and then performs entailment and AKRs . Two versions of ECD were used in RTE3 , one with strict ECD	USAGE	38	38	W07-1403.8	42	42	W07-1403.9
from a small number of natural language strings annotated with their semantics , along with basic assumptions	MODEL-FEATURE	5	7	P07-1105.3	11	11	P07-1105.4
, we propose a novel graph based sentence ranking algorithm , namely PNR2 , for update summarization . Inspired by the intuition	USAGE	5	9	C08-1062.7	15	16	C08-1062.9
discusses the application of the Expectation-Maximization ( EM ) clustering algorithm to the task of Chinese verb sense discrimination . The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs . A semantic taxonomy for Chinese nouns , which was built semi-automatically , was used to provide semantic features for the model . Purity and normalized mutual . We further enhanced the model with certain fine-grained semantic categories called lexical sets . Our results indicate that these lexical sets improve the model 's performance for the three	USAGE	5	10	P04-1038.1	15	18	P04-1038.2
discusses the application of the Expectation-Maximization ( EM ) clustering algorithm to the task of Chinese verb sense discrimination . The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs . A semantic taxonomy for Chinese nouns , which was built semi-automatically , was used to provide semantic features for the model . Purity and normalized mutual . We further enhanced the model with certain fine-grained semantic categories called lexical sets . Our results indicate that these lexical sets improve the model 's performance for the three	USAGE	23	25	P04-1038.4	21	21	P04-1038.3
discusses the application of the Expectation-Maximization ( EM ) clustering algorithm to the task of Chinese verb sense discrimination . The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs . A semantic taxonomy for Chinese nouns , which was built semi-automatically , was used to provide semantic features for the model . Purity and normalized mutual . We further enhanced the model with certain fine-grained semantic categories called lexical sets . Our results indicate that these lexical sets improve the model 's performance for the three	MODEL-FEATURE	28	30	P04-1038.5	33	34	P04-1038.6
discusses the application of the Expectation-Maximization ( EM ) clustering algorithm to the task of Chinese verb sense discrimination . The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs . A semantic taxonomy for Chinese nouns , which was built semi-automatically , was used to provide semantic features for the model . Purity and normalized mutual . We further enhanced the model with certain fine-grained semantic categories called lexical sets . Our results indicate that these lexical sets improve the model 's performance for the three	MODEL-FEATURE	37	38	P04-1038.7	40	41	P04-1038.8
discusses the application of the Expectation-Maximization ( EM ) clustering algorithm to the task of Chinese verb sense discrimination . The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs . A semantic taxonomy for Chinese nouns , which was built semi-automatically , was used to provide semantic features for the model . Purity and normalized mutual . We further enhanced the model with certain fine-grained semantic categories called lexical sets . Our results indicate that these lexical sets improve the model 's performance for the three	USAGE	52	53	P04-1038.10	56	56	P04-1038.11
discusses the application of the Expectation-Maximization ( EM ) clustering algorithm to the task of Chinese verb sense discrimination . The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs . A semantic taxonomy for Chinese nouns , which was built semi-automatically , was used to provide semantic features for the model . Purity and normalized mutual . We further enhanced the model with certain fine-grained semantic categories called lexical sets . Our results indicate that these lexical sets improve the model 's performance for the three	USAGE	70	72	P04-1038.20	67	67	P04-1038.19
discusses the application of the Expectation-Maximization ( EM ) clustering algorithm to the task of Chinese verb sense discrimination . The model utilized rich linguistic features that capture predicate-argument structure information of the target verbs . A semantic taxonomy for Chinese nouns , which was built semi-automatically , was used to provide semantic features for the model . Purity and normalized mutual . We further enhanced the model with certain fine-grained semantic categories called lexical sets . Our results indicate that these lexical sets improve the model 's performance for the three	RESULT	82	83	P04-1038.22	86	86	P04-1038.23
efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar . The strategy includes parsing . After speech processing and phrase recognition based on phoneme recognition , the parser extracts the dependency relationships . A fast parsing algorithm using breadth-first search is also proposed . The predictor pre-selects the phrase candidates using transition rules combined with a dependency structure the breadth-first parsing algorithm and predictor increase processing speed .	USAGE	11	13	C88-1082.3	5	8	C88-1082.2
efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar . The strategy includes parsing . After speech processing and phrase recognition based on phoneme recognition , the parser extracts the dependency relationships . A fast parsing algorithm using breadth-first search is also proposed . The predictor pre-selects the phrase candidates using transition rules combined with a dependency structure the breadth-first parsing algorithm and predictor increase processing speed .	USAGE	28	29	C88-1082.9	24	25	C88-1082.8
efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar . The strategy includes parsing . After speech processing and phrase recognition based on phoneme recognition , the parser extracts the dependency relationships . A fast parsing algorithm using breadth-first search is also proposed . The predictor pre-selects the phrase candidates using transition rules combined with a dependency structure the breadth-first parsing algorithm and predictor increase processing speed .	USAGE	43	44	C88-1082.18	40	41	C88-1082.17
efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar . The strategy includes parsing . After speech processing and phrase recognition based on phoneme recognition , the parser extracts the dependency relationships . A fast parsing algorithm using breadth-first search is also proposed . The predictor pre-selects the phrase candidates using transition rules combined with a dependency structure the breadth-first parsing algorithm and predictor increase processing speed .	USAGE	56	57	C88-1082.21	50	50	C88-1082.19
efficient linguistic processing strategy for speech recognition and understanding using a dependency structure grammar . The strategy includes parsing . After speech processing and phrase recognition based on phoneme recognition , the parser extracts the dependency relationships . A fast parsing algorithm using breadth-first search is also proposed . The predictor pre-selects the phrase candidates using transition rules combined with a dependency structure the breadth-first parsing algorithm and predictor increase processing speed .	RESULT	68	68	C88-1082.29	70	71	C88-1082.30
project , QALL-ME , a domain-specific ontology was developed and applied for question answering in the domain of tourism the paper , and a semi-automatic alignment procedure is described with some alignment results given as well . Furthermore used to semantically annotate original data obtained from the tourism web sites and natural language questions . The storage schema of the annotated data and the data access method for retrieving answers from the annotated data are also reported in the	USAGE	5	6	L08-1178.6	12	13	L08-1178.7
project , QALL-ME , a domain-specific ontology was developed and applied for question answering in the domain of tourism the paper , and a semi-automatic alignment procedure is described with some alignment results given as well . Furthermore used to semantically annotate original data obtained from the tourism web sites and natural language questions . The storage schema of the annotated data and the data access method for retrieving answers from the annotated data are also reported in the	RESULT	24	26	L08-1178.14	31	32	L08-1178.15
project , QALL-ME , a domain-specific ontology was developed and applied for question answering in the domain of tourism the paper , and a semi-automatic alignment procedure is described with some alignment results given as well . Furthermore used to semantically annotate original data obtained from the tourism web sites and natural language questions . The storage schema of the annotated data and the data access method for retrieving answers from the annotated data are also reported in the	PART_WHOLE	51	53	L08-1178.18	43	43	L08-1178.17
project , QALL-ME , a domain-specific ontology was developed and applied for question answering in the domain of tourism the paper , and a semi-automatic alignment procedure is described with some alignment results given as well . Furthermore used to semantically annotate original data obtained from the tourism web sites and natural language questions . The storage schema of the annotated data and the data access method for retrieving answers from the annotated data are also reported in the	USAGE	64	66	L08-1178.21	72	73	L08-1178.22
In particular we discuss a natural language generation system that is composed of SPoT , a trainable sentence planner ease , and that such NLG components can be integrated in a real-time dialog system .	PART_WHOLE	13	13	C02-1138.9	5	8	C02-1138.8
In particular we discuss a natural language generation system that is composed of SPoT , a trainable sentence planner ease , and that such NLG components can be integrated in a real-time dialog system .	PART_WHOLE	24	25	C02-1138.13	31	33	C02-1138.14
of laughter in a large corpus of interactive multi-party seminars , which promises to be	PART_WHOLE	7	9	L08-1016.10	5	5	L08-1016.9
PCFG This paper presents an extended GLR parsing algorithm with grammar PCFG* that is based on Tomita We also define a new grammar PCFG* that is based on PCFG and assigns not only probability but also frequency associated with each rule . So our syntactic parsing system is implemented based on rule-based approach and statistics approach . Furthermore	USAGE	10	11	C02-2028.2	5	8	C02-2028.1
PCFG This paper presents an extended GLR parsing algorithm with grammar PCFG* that is based on Tomita We also define a new grammar PCFG* that is based on PCFG and assigns not only probability but also frequency associated with each rule . So our syntactic parsing system is implemented based on rule-based approach and statistics approach . Furthermore	USAGE	28	28	C02-2028.5	22	23	C02-2028.4
PCFG This paper presents an extended GLR parsing algorithm with grammar PCFG* that is based on Tomita We also define a new grammar PCFG* that is based on PCFG and assigns not only probability but also frequency associated with each rule . So our syntactic parsing system is implemented based on rule-based approach and statistics approach . Furthermore	MODEL-FEATURE	36	36	C02-2028.7	40	40	C02-2028.8
PCFG This paper presents an extended GLR parsing algorithm with grammar PCFG* that is based on Tomita We also define a new grammar PCFG* that is based on PCFG and assigns not only probability but also frequency associated with each rule . So our syntactic parsing system is implemented based on rule-based approach and statistics approach . Furthermore	USAGE	51	52	C02-2028.10	44	46	C02-2028.9
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	USAGE	5	6	L08-1535.1	8	10	L08-1535.2
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	PART_WHOLE	26	26	L08-1535.8	21	21	L08-1535.6
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	MODEL-FEATURE	37	38	L08-1535.9	43	43	L08-1535.10
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	MODEL-FEATURE	48	49	L08-1535.11	55	55	L08-1535.12
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	TOPIC	66	67	L08-1535.17	69	69	L08-1535.18
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	USAGE	76	76	L08-1535.19	78	78	L08-1535.20
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	MODEL-FEATURE	93	93	L08-1535.28	89	89	L08-1535.27
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	PART_WHOLE	100	100	L08-1535.29	103	104	L08-1535.30
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	PART_WHOLE	114	114	L08-1535.32	117	117	L08-1535.33
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	USAGE	126	126	L08-1535.35	122	123	L08-1535.34
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	RESULT	137	138	L08-1535.38	142	142	L08-1535.39
this paper , we discuss lemma identification in Japanese morphological analysis , which is crucial for variation in orthography and the vocabulary of Japanese consists of words of several different origins , happens that more than one writing form corresponds to the same lemma and that a single writing form corresponds to two or more lemmas with different readings and/or meanings a lemma is important in linguistic analysis of corpora . The current study focuses on disambiguation of heteronyms , words with the same information , the classification of words based on their origin . Founded on the fact that words of some goshu classes are more likely to combine into compound words than words of other classes , we employ a statistical model based on CRFs using goshu information . Experimental show that the use of goshu information considerably improves the performance of heteronym disambiguation and lemma identification , suggesting that goshu information solves the lemma identification task very effectively .	USAGE	153	153	L08-1535.42	156	158	L08-1535.43
associations over time . An event detection algorithm identifies the collocations that may cause an event a specific timestamp . An event summarization algorithm retrieves a set of collocations which describe an event .	USAGE	5	7	L08-1003.6	10	10	L08-1003.7
associations over time . An event detection algorithm identifies the collocations that may cause an event a specific timestamp . An event summarization algorithm retrieves a set of collocations which describe an event .	USAGE	21	23	L08-1003.8	28	28	L08-1003.9
two approaches to analyzing and tagging team discourse using Latent Semantic Analysis ( LSA ) to predict team performance .	USAGE	9	14	N04-4025.2	5	5	N04-4025.1
. A huge amount of translation work needs to be done when creating and updating technical documentation . In response to these	USAGE	5	6	A94-1044.3	15	16	A94-1044.4
of this project is a pilot study of several new ideas for the automatic adaptation and improvement of natural language particularly on automatically inferring the meaning of new words in context and on developing corporate takeover bids . The NLP system uses large annotated corpora , such as those being , to adapt by acquiring syntactic and semantic information from the annotated examples . Statistical language modeling , based on probability estimates derived from the large corpora	TOPIC	5	6	H91-1079.1	13	14	H91-1079.2
of this project is a pilot study of several new ideas for the automatic adaptation and improvement of natural language particularly on automatically inferring the meaning of new words in context and on developing corporate takeover bids . The NLP system uses large annotated corpora , such as those being , to adapt by acquiring syntactic and semantic information from the annotated examples . Statistical language modeling , based on probability estimates derived from the large corpora	MODEL-FEATURE	25	25	H91-1079.5	28	28	H91-1079.6
of this project is a pilot study of several new ideas for the automatic adaptation and improvement of natural language particularly on automatically inferring the meaning of new words in context and on developing corporate takeover bids . The NLP system uses large annotated corpora , such as those being , to adapt by acquiring syntactic and semantic information from the annotated examples . Statistical language modeling , based on probability estimates derived from the large corpora	USAGE	42	44	H91-1079.13	39	40	H91-1079.12
of this project is a pilot study of several new ideas for the automatic adaptation and improvement of natural language particularly on automatically inferring the meaning of new words in context and on developing corporate takeover bids . The NLP system uses large annotated corpora , such as those being , to adapt by acquiring syntactic and semantic information from the annotated examples . Statistical language modeling , based on probability estimates derived from the large corpora	PART_WHOLE	55	58	H91-1079.15	61	62	H91-1079.16
of this project is a pilot study of several new ideas for the automatic adaptation and improvement of natural language particularly on automatically inferring the meaning of new words in context and on developing corporate takeover bids . The NLP system uses large annotated corpora , such as those being , to adapt by acquiring syntactic and semantic information from the annotated examples . Statistical language modeling , based on probability estimates derived from the large corpora	USAGE	70	71	H91-1079.18	64	66	H91-1079.17
with current psycholinguistic theories . Lexicalized concepts are organized by semantic relations ( synonymy , antonymy , intended to extend and upgrade WordNet , to make it generally available , and to develop it as a tool for use in practical applications . In order to make the same text augmented by syntactic and semantic anotations that disambiguate all of the substantive words . Initially , the semantic ( 2 ) create a database of correctly tagged text for use in testing proposals	MODEL-FEATURE	10	11	H92-1116.6	5	6	H92-1116.5
with current psycholinguistic theories . Lexicalized concepts are organized by semantic relations ( synonymy , antonymy , intended to extend and upgrade WordNet , to make it generally available , and to develop it as a tool for use in practical applications . In order to make the same text augmented by syntactic and semantic anotations that disambiguate all of the substantive words . Initially , the semantic ( 2 ) create a database of correctly tagged text for use in testing proposals	USAGE	22	22	H92-1116.14	41	41	H92-1116.15
with current psycholinguistic theories . Lexicalized concepts are organized by semantic relations ( synonymy , antonymy , intended to extend and upgrade WordNet , to make it generally available , and to develop it as a tool for use in practical applications . In order to make the same text augmented by syntactic and semantic anotations that disambiguate all of the substantive words . Initially , the semantic ( 2 ) create a database of correctly tagged text for use in testing proposals	MODEL-FEATURE	52	55	H92-1116.20	61	62	H92-1116.21
with current psycholinguistic theories . Lexicalized concepts are organized by semantic relations ( synonymy , antonymy , intended to extend and upgrade WordNet , to make it generally available , and to develop it as a tool for use in practical applications . In order to make the same text augmented by syntactic and semantic anotations that disambiguate all of the substantive words . Initially , the semantic ( 2 ) create a database of correctly tagged text for use in testing proposals	PART_WHOLE	77	77	H92-1116.25	73	73	H92-1116.24
you design process.Determine if your application can benefit from upgrading to advanced TIPSTER technology that has been developed since	USAGE	12	13	X96-1060.8	5	5	X96-1060.7
Context-Aware Lemmatizer For German Accurate lemmatization of German nouns mandates the use of a maintain . We present a self-learning lemmatizer capable of automatically creating a full-form lexicon by processing German documents .	USAGE	5	5	H05-1080.1	7	8	H05-1080.2
Context-Aware Lemmatizer For German Accurate lemmatization of German nouns mandates the use of a maintain . We present a self-learning lemmatizer capable of automatically creating a full-form lexicon by processing German documents .	USAGE	19	20	H05-1080.5	30	31	H05-1080.7
this paper we describe how Why-Atlas creates and utilizes a proof-based representation of student essays . We derive additional benefits from a proof-based approach for tutoring applications .	USAGE	10	11	W02-0211.6	5	5	W02-0211.5
this paper we describe how Why-Atlas creates and utilizes a proof-based representation of student essays . We derive additional benefits from a proof-based approach for tutoring applications .	USAGE	22	23	W02-0211.10	25	26	W02-0211.11
been built . Compared with syntactic knowledge , semantic knowledge is more difficult to annotate , we will compare our corpus with other well-known corpora .	COMPARE	5	6	W03-1712.13	8	9	W03-1712.14
been built . Compared with syntactic knowledge , semantic knowledge is more difficult to annotate , we will compare our corpus with other well-known corpora .	COMPARE	20	20	W03-1712.17	24	24	W03-1712.18
Systems are discussed . These techniques , developed within the Augmented Transition Network ( ATN ) model , are shown to be	USAGE	5	5	J81-2002.7	10	16	J81-2002.8
thus enabling the application of CT over the entire discourse . We describe the processes discourse structure trees and how CT can be applied to global discourse by using these chains . We also define a discourse smoothness index which can be used to compare different discourse structures and interpretations , and show how VT	USAGE	5	5	P98-1044.13	9	9	P98-1044.14
thus enabling the application of CT over the entire discourse . We describe the processes discourse structure trees and how CT can be applied to global discourse by using these chains . We also define a discourse smoothness index which can be used to compare different discourse structures and interpretations , and show how VT	USAGE	20	20	P98-1044.17	25	26	P98-1044.18
thus enabling the application of CT over the entire discourse . We describe the processes discourse structure trees and how CT can be applied to global discourse by using these chains . We also define a discourse smoothness index which can be used to compare different discourse structures and interpretations , and show how VT	USAGE	36	38	P98-1044.20	46	49	P98-1044.21
allow analysts to pose complex exploratory questions in natural language and obtain relevant information units a given scenario . The system uses novel data-driven semantics to conduct a clarification dialogue	MODEL-FEATURE	8	9	W04-2507.7	5	6	W04-2507.6
allow analysts to pose complex exploratory questions in natural language and obtain relevant information units a given scenario . The system uses novel data-driven semantics to conduct a clarification dialogue	USAGE	23	24	W04-2507.12	20	20	W04-2507.11
in the first freely distributable corpus of fully anonymized clinical text . This resource is permanently task is that it required categorization with respect to a large and commercially significant set of labels . The number of participants inter-coder agreement , suggesting that human-like performance on this task is within the reach of currently available technologies .	PART_WHOLE	7	10	W07-1013.4	5	5	W07-1013.3
in the first freely distributable corpus of fully anonymized clinical text . This resource is permanently task is that it required categorization with respect to a large and commercially significant set of labels . The number of participants inter-coder agreement , suggesting that human-like performance on this task is within the reach of currently available technologies .	USAGE	30	32	W07-1013.7	21	21	W07-1013.6
in the first freely distributable corpus of fully anonymized clinical text . This resource is permanently task is that it required categorization with respect to a large and commercially significant set of labels . The number of participants inter-coder agreement , suggesting that human-like performance on this task is within the reach of currently available technologies .	COMPARE	43	44	W07-1013.12	53	55	W07-1013.13
In this paper we describe automatic information nuggetization and its application to text comparison . More specifically , we a close look at how machine-generated nuggets can be used to create evaluation material . A semiautomatic annotation scheme is designed to produce gold-standard data with exceptionally high inter-human agreement	USAGE	5	7	N07-2055.1	12	13	N07-2055.2
In this paper we describe automatic information nuggetization and its application to text comparison . More specifically , we a close look at how machine-generated nuggets can be used to create evaluation material . A semiautomatic annotation scheme is designed to produce gold-standard data with exceptionally high inter-human agreement	USAGE	24	25	N07-2055.3	31	32	N07-2055.4
In this paper we describe automatic information nuggetization and its application to text comparison . More specifically , we a close look at how machine-generated nuggets can be used to create evaluation material . A semiautomatic annotation scheme is designed to produce gold-standard data with exceptionally high inter-human agreement	USAGE	35	37	N07-2055.5	42	43	N07-2055.6
we tested different kinds of features for retrieval of Chinese opinionated texts . assume that the task of retrieval of opinionated texts ( OIR ) can be regarded as a subtask of general IR , but with some distinct	USAGE	5	5	P07-3007.1	7	7	P07-3007.2
we tested different kinds of features for retrieval of Chinese opinionated texts . assume that the task of retrieval of opinionated texts ( OIR ) can be regarded as a subtask of general IR , but with some distinct	PART_WHOLE	18	18	P07-3007.4	33	33	P07-3007.6
Transducers This paper discusses the supervised learning of morphology using stochastic transducers , trained using the Expectation-Maximization are evaluated and compared on data sets from English , German , Slovene and	USAGE	10	11	P02-1065.3	5	6	P02-1065.1
Transducers This paper discusses the supervised learning of morphology using stochastic transducers , trained using the Expectation-Maximization are evaluated and compared on data sets from English , German , Slovene and	PART_WHOLE	22	23	P02-1065.9	25	25	P02-1065.10
Problems In Spoken Tutoring Dialogues Speech recognition problems are a reality in current spoken dialogue systems . In order to better and correctness . We apply Chi Square ( % 2 ) analysis to a corpus of speech-based computer tutoring dialogues to discover these dependencies both	PART_WHOLE	5	7	P06-1025.1	13	15	P06-1025.2
Problems In Spoken Tutoring Dialogues Speech recognition problems are a reality in current spoken dialogue systems . In order to better and correctness . We apply Chi Square ( % 2 ) analysis to a corpus of speech-based computer tutoring dialogues to discover these dependencies both	USAGE	26	32	P06-1025.5	35	40	P06-1025.6
analyzer produces more than one interlingua expression for a source sentence . This can have a these methods on a large corpus of test sentences , in order to illustrate how the different disambiguation methods reduce the average number of parses per sentence .	MODEL-FEATURE	5	6	C94-1012.4	9	10	C94-1012.5
analyzer produces more than one interlingua expression for a source sentence . This can have a these methods on a large corpus of test sentences , in order to illustrate how the different disambiguation methods reduce the average number of parses per sentence .	PART_WHOLE	23	24	C94-1012.12	21	21	C94-1012.11
analyzer produces more than one interlingua expression for a source sentence . This can have a these methods on a large corpus of test sentences , in order to illustrate how the different disambiguation methods reduce the average number of parses per sentence .	RESULT	33	34	C94-1012.13	40	40	C94-1012.14
language models results in huge dynamic programs for machine translation decoding . We propose a multipass approaches , we focus on encoding-based methods , which use a clustered encoding of the target language . . Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram-to-trigram decoder .	USAGE	5	6	D08-1012.3	8	10	D08-1012.4
language models results in huge dynamic programs for machine translation decoding . We propose a multipass approaches , we focus on encoding-based methods , which use a clustered encoding of the target language . . Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram-to-trigram decoder .	USAGE	27	28	D08-1012.10	21	22	D08-1012.9
language models results in huge dynamic programs for machine translation decoding . We propose a multipass approaches , we focus on encoding-based methods , which use a clustered encoding of the target language . . Moreover , our entire decoding cascade for trigram language models is faster than the corresponding bigram pass alone of a bigram-to-trigram decoder .	COMPARE	39	44	D08-1012.16	55	56	D08-1012.18
on the feasibility of doing pronoun resolution for biomedical texts , in comparison with conducting pronoun resolution for the newswire domain . In our experiments ,	USAGE	5	6	L08-1071.1	8	9	L08-1071.2
on the feasibility of doing pronoun resolution for biomedical texts , in comparison with conducting pronoun resolution for the newswire domain . In our experiments ,	USAGE	15	16	L08-1071.3	19	20	L08-1071.4
Of Slavic Sharing portions of grammars across languages greatly reduces the costs of multilingual grammar engineering . Related languages share a are particularly interested in designing linguistically motivated grammatical resources for Slavic languages to be used in applied and theoretical computational linguistics . In order to gain , we show how a domain ontology conceptualising morpho-syntactic `` building blocks '' can serve as a basis of a shared grammar of Slavic .	RESULT	5	5	C00-1005.1	13	15	C00-1005.3
Of Slavic Sharing portions of grammars across languages greatly reduces the costs of multilingual grammar engineering . Related languages share a are particularly interested in designing linguistically motivated grammatical resources for Slavic languages to be used in applied and theoretical computational linguistics . In order to gain , we show how a domain ontology conceptualising morpho-syntactic `` building blocks '' can serve as a basis of a shared grammar of Slavic .	USAGE	26	29	C00-1005.8	37	41	C00-1005.10
Of Slavic Sharing portions of grammars across languages greatly reduces the costs of multilingual grammar engineering . Related languages share a are particularly interested in designing linguistically motivated grammatical resources for Slavic languages to be used in applied and theoretical computational linguistics . In order to gain , we show how a domain ontology conceptualising morpho-syntactic `` building blocks '' can serve as a basis of a shared grammar of Slavic .	USAGE	52	53	C00-1005.18	67	70	C00-1005.20
spatiotemporal annotation system to handle temporal and/or geospatial information directly and indirectly expressed in texts . In the end , . A first version of MiniSTEx was originally developed for Dutch , keeping in mind that	PART_WHOLE	5	8	L08-1561.6	14	14	L08-1561.7
spatiotemporal annotation system to handle temporal and/or geospatial information directly and indirectly expressed in texts . In the end , . A first version of MiniSTEx was originally developed for Dutch , keeping in mind that	USAGE	25	25	L08-1561.11	30	30	L08-1561.12
improving the performance of an information extraction system for speech data by explicitly modeling the errors	USAGE	5	7	H01-1034.4	9	10	H01-1034.5
paper , we report a QA system which can answer how type questions based on the confirmed knowledge base which was developed by using mails posted to a mailing list a problem of developing a knowledge base by using natural language documents : wrong information in natural language documents . Then , we describe a method of detecting wrong information in mails posted to a mailing list and developing a knowledge base by using these mails . Finally , we show can be used as a knowledge base for a QA system .	USAGE	5	6	I05-2006.1	11	12	I05-2006.2
paper , we report a QA system which can answer how type questions based on the confirmed knowledge base which was developed by using mails posted to a mailing list a problem of developing a knowledge base by using natural language documents : wrong information in natural language documents . Then , we describe a method of detecting wrong information in mails posted to a mailing list and developing a knowledge base by using these mails . Finally , we show can be used as a knowledge base for a QA system .	PART_WHOLE	16	18	I05-2006.3	24	24	I05-2006.4
paper , we report a QA system which can answer how type questions based on the confirmed knowledge base which was developed by using mails posted to a mailing list a problem of developing a knowledge base by using natural language documents : wrong information in natural language documents . Then , we describe a method of detecting wrong information in mails posted to a mailing list and developing a knowledge base by using these mails . Finally , we show can be used as a knowledge base for a QA system .	PART_WHOLE	35	36	I05-2006.6	39	41	I05-2006.7
paper , we report a QA system which can answer how type questions based on the confirmed knowledge base which was developed by using mails posted to a mailing list a problem of developing a knowledge base by using natural language documents : wrong information in natural language documents . Then , we describe a method of detecting wrong information in mails posted to a mailing list and developing a knowledge base by using these mails . Finally , we show can be used as a knowledge base for a QA system .	PART_WHOLE	43	44	I05-2006.8	46	48	I05-2006.9
paper , we report a QA system which can answer how type questions based on the confirmed knowledge base which was developed by using mails posted to a mailing list a problem of developing a knowledge base by using natural language documents : wrong information in natural language documents . Then , we describe a method of detecting wrong information in mails posted to a mailing list and developing a knowledge base by using these mails . Finally , we show can be used as a knowledge base for a QA system .	PART_WHOLE	58	59	I05-2006.10	61	61	I05-2006.11
paper , we report a QA system which can answer how type questions based on the confirmed knowledge base which was developed by using mails posted to a mailing list a problem of developing a knowledge base by using natural language documents : wrong information in natural language documents . Then , we describe a method of detecting wrong information in mails posted to a mailing list and developing a knowledge base by using these mails . Finally , we show can be used as a knowledge base for a QA system .	PART_WHOLE	70	71	I05-2006.13	75	75	I05-2006.14
paper , we report a QA system which can answer how type questions based on the confirmed knowledge base which was developed by using mails posted to a mailing list a problem of developing a knowledge base by using natural language documents : wrong information in natural language documents . Then , we describe a method of detecting wrong information in mails posted to a mailing list and developing a knowledge base by using these mails . Finally , we show can be used as a knowledge base for a QA system .	USAGE	86	87	I05-2006.17	90	91	I05-2006.18
the problem of predicting the reading difficulty of a text passage , by recasting readability in terms of statistical language modeling . We derive a measure based on an extension of multinomial naive Bayes classification that combines multiple language models to estimate the most likely compare our performance to widely-used semantic variables from traditional readability measures . We show that with test passages , while our language modeling approach gave better accuracy for Web documents and very short passages (	MODEL-FEATURE	5	6	N04-1025.1	9	10	N04-1025.2
the problem of predicting the reading difficulty of a text passage , by recasting readability in terms of statistical language modeling . We derive a measure based on an extension of multinomial naive Bayes classification that combines multiple language models to estimate the most likely compare our performance to widely-used semantic variables from traditional readability measures . We show that with test passages , while our language modeling approach gave better accuracy for Web documents and very short passages (	MODEL-FEATURE	18	20	N04-1025.4	14	14	N04-1025.3
the problem of predicting the reading difficulty of a text passage , by recasting readability in terms of statistical language modeling . We derive a measure based on an extension of multinomial naive Bayes classification that combines multiple language models to estimate the most likely compare our performance to widely-used semantic variables from traditional readability measures . We show that with test passages , while our language modeling approach gave better accuracy for Web documents and very short passages (	USAGE	38	39	N04-1025.6	31	34	N04-1025.5
the problem of predicting the reading difficulty of a text passage , by recasting readability in terms of statistical language modeling . We derive a measure based on an extension of multinomial naive Bayes classification that combines multiple language models to estimate the most likely compare our performance to widely-used semantic variables from traditional readability measures . We show that with test passages , while our language modeling approach gave better accuracy for Web documents and very short passages (	PART_WHOLE	50	51	N04-1025.10	54	55	N04-1025.11
the problem of predicting the reading difficulty of a text passage , by recasting readability in terms of statistical language modeling . We derive a measure based on an extension of multinomial naive Bayes classification that combines multiple language models to estimate the most likely compare our performance to widely-used semantic variables from traditional readability measures . We show that with test passages , while our language modeling approach gave better accuracy for Web documents and very short passages (	USAGE	66	68	N04-1025.17	73	74	N04-1025.18
in a single step . Syntactic and semantic information are both represented in the grammar in a uniform manner , Sag , 1987 ) . LINK has been used in several information extraction applications . In a project with General Motors , LINK was used to process terse free-form descriptions of symptoms displayed by malfunctioning	MODEL-FEATURE	14	14	M93-1024.7	5	8	M93-1024.6
in a single step . Syntactic and semantic information are both represented in the grammar in a uniform manner , Sag , 1987 ) . LINK has been used in several information extraction applications . In a project with General Motors , LINK was used to process terse free-form descriptions of symptoms displayed by malfunctioning	USAGE	25	25	M93-1024.9	31	33	M93-1024.10
in a single step . Syntactic and semantic information are both represented in the grammar in a uniform manner , Sag , 1987 ) . LINK has been used in several information extraction applications . In a project with General Motors , LINK was used to process terse free-form descriptions of symptoms displayed by malfunctioning	USAGE	42	42	M93-1024.11	48	49	M93-1024.12
Reduplication In One-Level Prosodic Morphology Reduplication , a central instance of prosodic morphology , is particularly challenging for this paper I advocate a finite-state method that combines enriched lexical representations via intersection to implement the . The proposal includes a resource-conscious variant of automata and can benefit from the existence of lazy algorithms . Finally , the implementation	PART_WHOLE	5	5	A00-2039.1	11	12	A00-2039.2
Reduplication In One-Level Prosodic Morphology Reduplication , a central instance of prosodic morphology , is particularly challenging for this paper I advocate a finite-state method that combines enriched lexical representations via intersection to implement the . The proposal includes a resource-conscious variant of automata and can benefit from the existence of lazy algorithms . Finally , the implementation	USAGE	27	29	A00-2039.6	23	24	A00-2039.5
Reduplication In One-Level Prosodic Morphology Reduplication , a central instance of prosodic morphology , is particularly challenging for this paper I advocate a finite-state method that combines enriched lexical representations via intersection to implement the . The proposal includes a resource-conscious variant of automata and can benefit from the existence of lazy algorithms . Finally , the implementation	USAGE	51	52	A00-2039.8	40	43	A00-2039.7
( 1 ) recognizing an expression that is highly relevant to the given domain , e.g . `` were in this process by deriving reliable relevancy cues from a corpus of training texts and using these cues to	MODEL-FEATURE	5	5	H92-1094.3	12	13	H92-1094.4
( 1 ) recognizing an expression that is highly relevant to the given domain , e.g . `` were in this process by deriving reliable relevancy cues from a corpus of training texts and using these cues to	PART_WHOLE	24	26	H92-1094.12	29	32	H92-1094.13
as query , and retrieves relevant Chinese broadcast news stories ( audio ) from the document collection . Hence this is a Chinese by means of a dictionary-based approach , where we have integrated phrase-based translation with word-by-word translation . Untranslatable named entities are transliterated by a novel subword translation technique . The multi-scale approach can gave performance gains , and multi-scale retrieval outperforms word-based retrieval .	PART_WHOLE	5	12	H01-1050.6	15	16	H01-1050.7
as query , and retrieves relevant Chinese broadcast news stories ( audio ) from the document collection . Hence this is a Chinese by means of a dictionary-based approach , where we have integrated phrase-based translation with word-by-word translation . Untranslatable named entities are transliterated by a novel subword translation technique . The multi-scale approach can gave performance gains , and multi-scale retrieval outperforms word-based retrieval .	USAGE	34	35	H01-1050.16	27	28	H01-1050.15
as query , and retrieves relevant Chinese broadcast news stories ( audio ) from the document collection . Hence this is a Chinese by means of a dictionary-based approach , where we have integrated phrase-based translation with word-by-word translation . Untranslatable named entities are transliterated by a novel subword translation technique . The multi-scale approach can gave performance gains , and multi-scale retrieval outperforms word-based retrieval .	USAGE	47	50	H01-1050.19	40	42	H01-1050.18
as query , and retrieves relevant Chinese broadcast news stories ( audio ) from the document collection . Hence this is a Chinese by means of a dictionary-based approach , where we have integrated phrase-based translation with word-by-word translation . Untranslatable named entities are transliterated by a novel subword translation technique . The multi-scale approach can gave performance gains , and multi-scale retrieval outperforms word-based retrieval .	COMPARE	61	62	H01-1050.26	64	65	H01-1050.27
'' . But while the English past tense has some interesting features in its combination of regular system - reflecting the generally vestigal nature of inflectional morphology within modern English .	MODEL-FEATURE	11	11	W98-1240.10	5	7	W98-1240.9
'' . But while the English past tense has some interesting features in its combination of regular system - reflecting the generally vestigal nature of inflectional morphology within modern English .	MODEL-FEATURE	22	23	W98-1240.14	25	26	W98-1240.15
evaluate a novel model for statistical machine translation , which is based on shallow syntactic analysis ( part-of-speech tagging and phrase	USAGE	13	15	W03-1002.2	5	7	W03-1002.1
analyzes the translation quality of machine translation systems for 10 language pairs translating between Czech , English sentence-level . We validate our manual evaluation methodology by measuring intra- and inter-annotator agreement , and collecting timing information	USAGE	5	7	W08-0309.2	10	11	W08-0309.3
analyzes the translation quality of machine translation systems for 10 language pairs translating between Czech , English sentence-level . We validate our manual evaluation methodology by measuring intra- and inter-annotator agreement , and collecting timing information	USAGE	27	30	W08-0309.18	22	24	W08-0309.17
we describe issues in the translation of proper names from English to Chinese which	USAGE	5	5	P98-2220.1	7	8	P98-2220.2
closed testing track . Our CWS is based on backward maximum matching with word support model (	USAGE	9	11	W06-0119.6	5	5	W06-0119.5
English Statistical Machine Translation The Arabic language has far richer systems of inflection and derivation than English which has very given parallel training corpus . Segmentation of inflected Arabic words is a way to smooth paper , we describe some statistically and linguistically motivated methods for Arabic word segmentation . Then , we show the efficiency of proposed methods on the Arabic-English BTEC and NIST tasks .	MODEL-FEATURE	10	14	W06-3103.2	5	6	W06-3103.1
English Statistical Machine Translation The Arabic language has far richer systems of inflection and derivation than English which has very given parallel training corpus . Segmentation of inflected Arabic words is a way to smooth paper , we describe some statistically and linguistically motivated methods for Arabic word segmentation . Then , we show the efficiency of proposed methods on the Arabic-English BTEC and NIST tasks .	USAGE	25	25	W06-3103.8	27	29	W06-3103.9
English Statistical Machine Translation The Arabic language has far richer systems of inflection and derivation than English which has very given parallel training corpus . Segmentation of inflected Arabic words is a way to smooth paper , we describe some statistically and linguistically motivated methods for Arabic word segmentation . Then , we show the efficiency of proposed methods on the Arabic-English BTEC and NIST tasks .	USAGE	40	44	W06-3103.11	46	48	W06-3103.12
English Statistical Machine Translation The Arabic language has far richer systems of inflection and derivation than English which has very given parallel training corpus . Segmentation of inflected Arabic words is a way to smooth paper , we describe some statistically and linguistically motivated methods for Arabic word segmentation . Then , we show the efficiency of proposed methods on the Arabic-English BTEC and NIST tasks .	USAGE	57	58	W06-3103.13	61	65	W06-3103.14
dialectal Arabic . Developing a high-quality lexicon is often the first step towards building a POS tagger , which is in turn on three transductive algorithms : Transductive SVMs , Spectral Graph Transducers , and a novel Transductive	USAGE	5	6	W06-1647.4	15	16	W06-1647.5
dialectal Arabic . Developing a high-quality lexicon is often the first step towards building a POS tagger , which is in turn on three transductive algorithms : Transductive SVMs , Spectral Graph Transducers , and a novel Transductive	COMPARE	27	28	W06-1647.10	30	32	W06-1647.11
in Wikipedia We present an API for computing the semantic relatedness of words in Wikipedia .	USAGE	5	5	P07-2013.1	9	10	P07-2013.2
a general platform , namely synchronous tree sequence substitution grammar ( STSSG ) , for the grammar comparison study in Translational Equivalence Modeling ( Experimental results show that the STSSG is able to better explain the data in parallel corpora than other grammars . Our study further finds that the complexity of structure divergence is much higher than suggested in literature , which imposes a big challenge to syntactic transformation-based SMT .	USAGE	5	12	C08-1138.1	16	18	C08-1138.2
a general platform , namely synchronous tree sequence substitution grammar ( STSSG ) , for the grammar comparison study in Translational Equivalence Modeling ( Experimental results show that the STSSG is able to better explain the data in parallel corpora than other grammars . Our study further finds that the complexity of structure divergence is much higher than suggested in literature , which imposes a big challenge to syntactic transformation-based SMT .	COMPARE	29	29	C08-1138.11	41	42	C08-1138.13
a general platform , namely synchronous tree sequence substitution grammar ( STSSG ) , for the grammar comparison study in Translational Equivalence Modeling ( Experimental results show that the STSSG is able to better explain the data in parallel corpora than other grammars . Our study further finds that the complexity of structure divergence is much higher than suggested in literature , which imposes a big challenge to syntactic transformation-based SMT .	RESULT	52	53	C08-1138.14	68	70	C08-1138.15
This paper presents an innovative unsupervised method for automatic sentence extraction using graph-based ranking algorithms . We evaluate the method in the context of a text summarization task , and show that the	USAGE	5	6	P04-3020.1	8	10	P04-3020.2
This paper presents an innovative unsupervised method for automatic sentence extraction using graph-based ranking algorithms . We evaluate the method in the context of a text summarization task , and show that the	USAGE	19	19	P04-3020.4	25	27	P04-3020.5
of compatibility and recency . Preferred antecedents are a subset of the possible antecedents , selected by the application	PART_WHOLE	5	6	C90-2017.7	12	13	C90-2017.8
Translation This paper presents a syntactic description of a fragment of German that has been worked out Eurotra . It represents the syntactic part of the German module of this multilingual translation system	MODEL-FEATURE	5	6	C88-2123.1	11	11	C88-2123.2
Translation This paper presents a syntactic description of a fragment of German that has been worked out Eurotra . It represents the syntactic part of the German module of this multilingual translation system	PART_WHOLE	22	23	C88-2123.4	26	27	C88-2123.5
approach for querying collections of heterogeneous linguistic corpora that are annotated on multiple layers using arbitrary XML-based markup languages . An OWL ontology provides a homogenising view on the conceptually different markup languages so that a common querying framework can be established using the method of ontology-based query expansion . In addition , we can also be used for ontology-based querying of multiple corpora simultaneously .	MODEL-FEATURE	12	13	L08-1190.2	5	7	L08-1190.1
approach for querying collections of heterogeneous linguistic corpora that are annotated on multiple layers using arbitrary XML-based markup languages . An OWL ontology provides a homogenising view on the conceptually different markup languages so that a common querying framework can be established using the method of ontology-based query expansion . In addition , we can also be used for ontology-based querying of multiple corpora simultaneously .	USAGE	21	22	L08-1190.4	31	32	L08-1190.5
approach for querying collections of heterogeneous linguistic corpora that are annotated on multiple layers using arbitrary XML-based markup languages . An OWL ontology provides a homogenising view on the conceptually different markup languages so that a common querying framework can be established using the method of ontology-based query expansion . In addition , we can also be used for ontology-based querying of multiple corpora simultaneously .	USAGE	46	48	L08-1190.7	37	38	L08-1190.6
approach for querying collections of heterogeneous linguistic corpora that are annotated on multiple layers using arbitrary XML-based markup languages . An OWL ontology provides a homogenising view on the conceptually different markup languages so that a common querying framework can be established using the method of ontology-based query expansion . In addition , we can also be used for ontology-based querying of multiple corpora simultaneously .	USAGE	59	60	L08-1190.12	63	63	L08-1190.13
. We also evaluate our model on the related role-labelling task , and compare it with a standard role labeller . For both tasks , our model benefits from class-based smoothing , which allows it to sparse data problem . The standard labeller suffers from sparse data and a strong reliance on syntactic cues , especially in the prediction task .	COMPARE	5	5	E06-1044.5	17	19	E06-1044.7
. We also evaluate our model on the related role-labelling task , and compare it with a standard role labeller . For both tasks , our model benefits from class-based smoothing , which allows it to sparse data problem . The standard labeller suffers from sparse data and a strong reliance on syntactic cues , especially in the prediction task .	RESULT	29	30	E06-1044.10	26	26	E06-1044.9
. We also evaluate our model on the related role-labelling task , and compare it with a standard role labeller . For both tasks , our model benefits from class-based smoothing , which allows it to sparse data problem . The standard labeller suffers from sparse data and a strong reliance on syntactic cues , especially in the prediction task .	RESULT	45	46	E06-1044.14	41	42	E06-1044.13
. We also evaluate our model on the related role-labelling task , and compare it with a standard role labeller . For both tasks , our model benefits from class-based smoothing , which allows it to sparse data problem . The standard labeller suffers from sparse data and a strong reliance on syntactic cues , especially in the prediction task .	USAGE	52	53	E06-1044.15	58	59	E06-1044.16
bootstrapping fashion , the so-called 'Pendulum Algorithm ' operates on word sets obtained by co-occurrence statistics on a large un-annotated corpus and keeps error propagation low	USAGE	5	7	C04-1178.6	10	11	C04-1178.7
bootstrapping fashion , the so-called 'Pendulum Algorithm ' operates on word sets obtained by co-occurrence statistics on a large un-annotated corpus and keeps error propagation low	PART_WHOLE	14	15	C04-1178.8	18	20	C04-1178.9
. The first algorithm , phone-dependent cepstral compensation , is similar in concept to the previously-described MFCDCN method , except that cepstral compensation . Use of the various compensation algorithms in consort produces a reduction of error rates for SPHINX-II by as much	COMPARE	5	7	H94-1066.4	16	17	H94-1066.5
. The first algorithm , phone-dependent cepstral compensation , is similar in concept to the previously-described MFCDCN method , except that cepstral compensation . Use of the various compensation algorithms in consort produces a reduction of error rates for SPHINX-II by as much	RESULT	28	29	H94-1066.12	34	37	H94-1066.13
the child 's progress during oral reading and to provide sufficient information to detect reading miscues . In this paper , work by examining a novel labeling of children 's oral reading audio data in order to better understand consider the problem of detecting miscues during oral reading . Using features derived from	PART_WHOLE	14	15	C04-1182.7	5	6	C04-1182.6
the child 's progress during oral reading and to provide sufficient information to detect reading miscues . In this paper , work by examining a novel labeling of children 's oral reading audio data in order to better understand consider the problem of detecting miscues during oral reading . Using features derived from	MODEL-FEATURE	26	26	C04-1182.8	30	33	C04-1182.9
the child 's progress during oral reading and to provide sufficient information to detect reading miscues . In this paper , work by examining a novel labeling of children 's oral reading audio data in order to better understand consider the problem of detecting miscues during oral reading . Using features derived from	PART_WHOLE	44	44	C04-1182.14	46	47	C04-1182.15
